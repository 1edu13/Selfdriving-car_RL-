{
  "model": "model_2000k",
  "evaluation_date": "2026-01-14T11:38:34.364541",
  "num_episodes": 30,
  "seed": 100,
  "device": "cuda",
  "statistics": {
    "mean_reward": 802.5763436673377,
    "std_reward": 235.33972341843815,
    "min_reward": 93.92458471760895,
    "max_reward": 934.7999999999884,
    "median_reward": 919.3499999999896,
    "mean_length": 699.0333333333333,
    "std_length": 157.53020521650936,
    "win_rate": 70.0,
    "success_rate": 100.0,
    "steering_mean": -0.08395347039525708,
    "throttle_mean": -0.32078979002932706,
    "brake_mean": -1.3542089939117432
  },
  "episodes": [
    {
      "episode_num": 0,
      "total_reward": 788.9962962962878,
      "episode_length": 665,
      "avg_reward_per_step": 1.1864605959342673,
      "max_reward_step": 7.307407407407408,
      "min_reward_step": -0.9000000000000228,
      "steering_mean": -0.05191260203719139,
      "steering_std": 1.2039759159088135,
      "throttle_mean": -0.46242374181747437,
      "brake_mean": -1.2414835691452026
    },
    {
      "episode_num": 1,
      "total_reward": 913.8999999999925,
      "episode_length": 773,
      "avg_reward_per_step": 1.182276843467002,
      "max_reward_step": 6.500660066006601,
      "min_reward_step": -0.9000000000000228,
      "steering_mean": -0.17265233397483826,
      "steering_std": 1.4585943222045898,
      "throttle_mean": -0.3215395510196686,
      "brake_mean": -1.3404030799865723
    },
    {
      "episode_num": 2,
      "total_reward": 122.85376344086046,
      "episode_length": 290,
      "avg_reward_per_step": 0.42363366703744987,
      "max_reward_step": 7.068458781362008,
      "min_reward_step": -0.8999999999999944,
      "steering_mean": -0.15222801268100739,
      "steering_std": 1.1268424987792969,
      "throttle_mean": -0.1539696455001831,
      "brake_mean": -1.1133557558059692
    },
    {
      "episode_num": 3,
      "total_reward": 928.3999999999872,
      "episode_length": 668,
      "avg_reward_per_step": 1.389820359281418,
      "max_reward_step": 7.094244604316547,
      "min_reward_step": -0.9000000000000228,
      "steering_mean": -0.16783283650875092,
      "steering_std": 1.4278796911239624,
      "throttle_mean": -0.5915276408195496,
      "brake_mean": -1.3611139059066772
    },
    {
      "episode_num": 4,
      "total_reward": 920.2999999999861,
      "episode_length": 741,
      "avg_reward_per_step": 1.2419703103913442,
      "max_reward_step": 6.611409395973155,
      "min_reward_step": -0.9000000000000228,
      "steering_mean": -0.04753536358475685,
      "steering_std": 1.1610418558120728,
      "throttle_mean": -0.3842586576938629,
      "brake_mean": -1.466176152229309
    },
    {
      "episode_num": 5,
      "total_reward": 923.9999999999878,
      "episode_length": 704,
      "avg_reward_per_step": 1.3124999999999827,
      "max_reward_step": 7.042857142857144,
      "min_reward_step": -0.9000000000000015,
      "steering_mean": -0.11479344964027405,
      "steering_std": 1.2651638984680176,
      "throttle_mean": -0.47407540678977966,
      "brake_mean": -1.3556114435195923
    },
    {
      "episode_num": 6,
      "total_reward": 929.2999999999869,
      "episode_length": 627,
      "avg_reward_per_step": 1.4821371610845087,
      "max_reward_step": 8.09672131147541,
      "min_reward_step": -0.9000000000000228,
      "steering_mean": -0.10252820700407028,
      "steering_std": 1.53542959690094,
      "throttle_mean": 0.09357985109090805,
      "brake_mean": -1.4022072553634644
    },
    {
      "episode_num": 7,
      "total_reward": 910.9999999999799,
      "episode_length": 866,
      "avg_reward_per_step": 1.051963048498822,
      "max_reward_step": 5.765102639296202,
      "min_reward_step": -0.8999999999999944,
      "steering_mean": -0.05535906180739403,
      "steering_std": 1.3642297983169556,
      "throttle_mean": -0.2140139490365982,
      "brake_mean": -1.3384513854980469
    },
    {
      "episode_num": 8,
      "total_reward": 932.899999999996,
      "episode_length": 671,
      "avg_reward_per_step": 1.3903129657227957,
      "max_reward_step": 7.120216606498195,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.03573324531316757,
      "steering_std": 1.322938084602356,
      "throttle_mean": -0.31556636095046997,
      "brake_mean": -1.3573857545852661
    },
    {
      "episode_num": 9,
      "total_reward": 910.0999999999894,
      "episode_length": 787,
      "avg_reward_per_step": 1.1564167725539891,
      "max_reward_step": 6.457377049180328,
      "min_reward_step": -0.9000000000000228,
      "steering_mean": -0.19035299122333527,
      "steering_std": 1.4380059242248535,
      "throttle_mean": -0.3038422763347626,
      "brake_mean": -1.4089398384094238
    },
    {
      "episode_num": 10,
      "total_reward": 931.29999999999,
      "episode_length": 687,
      "avg_reward_per_step": 1.3556040756913974,
      "max_reward_step": 7.068458781362008,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.13051193952560425,
      "steering_std": 1.6423124074935913,
      "throttle_mean": -0.4895660877227783,
      "brake_mean": -1.4051557779312134
    },
    {
      "episode_num": 11,
      "total_reward": 304.25747126436585,
      "episode_length": 400,
      "avg_reward_per_step": 0.7606436781609146,
      "max_reward_step": 5.647126436781609,
      "min_reward_step": -0.9000000000000228,
      "steering_mean": 0.013332012109458447,
      "steering_std": 1.4305896759033203,
      "throttle_mean": 0.12010753899812698,
      "brake_mean": -1.3365509510040283
    },
    {
      "episode_num": 12,
      "total_reward": 934.7999999999884,
      "episode_length": 652,
      "avg_reward_per_step": 1.4337423312883257,
      "max_reward_step": 7.172727272727273,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.054606541991233826,
      "steering_std": 1.3744094371795654,
      "throttle_mean": -0.3939407467842102,
      "brake_mean": -1.4458057880401611
    },
    {
      "episode_num": 13,
      "total_reward": 774.4562300319409,
      "episode_length": 1000,
      "avg_reward_per_step": 0.7744562300319409,
      "max_reward_step": 6.289776357827492,
      "min_reward_step": -0.9000000000000228,
      "steering_mean": 0.06636744737625122,
      "steering_std": 1.2001522779464722,
      "throttle_mean": -0.2762298583984375,
      "brake_mean": -1.316402554512024
    },
    {
      "episode_num": 14,
      "total_reward": 928.6999999999849,
      "episode_length": 713,
      "avg_reward_per_step": 1.302524544179502,
      "max_reward_step": 6.942253521126761,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.13626064360141754,
      "steering_std": 1.4526455402374268,
      "throttle_mean": -0.32572364807128906,
      "brake_mean": -1.4149885177612305
    },
    {
      "episode_num": 15,
      "total_reward": 929.9999999999894,
      "episode_length": 700,
      "avg_reward_per_step": 1.3285714285714134,
      "max_reward_step": 6.868641114982578,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.046406619250774384,
      "steering_std": 1.4737118482589722,
      "throttle_mean": -0.47989633679389954,
      "brake_mean": -1.4627903699874878
    },
    {
      "episode_num": 16,
      "total_reward": 917.3999999999937,
      "episode_length": 738,
      "avg_reward_per_step": 1.2430894308943004,
      "max_reward_step": 6.500660066006601,
      "min_reward_step": -0.9000000000000228,
      "steering_mean": -0.13982655107975006,
      "steering_std": 1.4279690980911255,
      "throttle_mean": -0.41629189252853394,
      "brake_mean": -1.3358131647109985
    },
    {
      "episode_num": 17,
      "total_reward": 925.9999999999953,
      "episode_length": 652,
      "avg_reward_per_step": 1.420245398772999,
      "max_reward_step": 7.805138339920949,
      "min_reward_step": -0.9000000000000228,
      "steering_mean": -0.15248923003673553,
      "steering_std": 1.1098382472991943,
      "throttle_mean": -0.15302808582782745,
      "brake_mean": -1.3457167148590088
    },
    {
      "episode_num": 18,
      "total_reward": 666.0457912457823,
      "episode_length": 700,
      "avg_reward_per_step": 0.9514939874939747,
      "max_reward_step": 6.634006734006735,
      "min_reward_step": -0.9000000000000228,
      "steering_mean": 0.064939945936203,
      "steering_std": 1.3618930578231812,
      "throttle_mean": -0.35323894023895264,
      "brake_mean": -1.3952977657318115
    },
    {
      "episode_num": 19,
      "total_reward": 93.92458471760895,
      "episode_length": 339,
      "avg_reward_per_step": 0.2770636717333597,
      "max_reward_step": 6.5445182724252495,
      "min_reward_step": -0.8999999999999944,
      "steering_mean": -0.037381771951913834,
      "steering_std": 1.1645886898040771,
      "throttle_mean": -0.40359750390052795,
      "brake_mean": -1.1469091176986694
    },
    {
      "episode_num": 20,
      "total_reward": 933.0999999999887,
      "episode_length": 669,
      "avg_reward_per_step": 1.3947683109117917,
      "max_reward_step": 7.307407407407408,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.25521203875541687,
      "steering_std": 1.5080289840698242,
      "throttle_mean": -0.1941218376159668,
      "brake_mean": -1.3823049068450928
    },
    {
      "episode_num": 21,
      "total_reward": 918.3999999999941,
      "episode_length": 736,
      "avg_reward_per_step": 1.2478260869565136,
      "max_reward_step": 6.8204152249134955,
      "min_reward_step": -0.9000000000000228,
      "steering_mean": -0.1439746618270874,
      "steering_std": 1.4459850788116455,
      "throttle_mean": -0.0572313629090786,
      "brake_mean": -1.4943931102752686
    },
    {
      "episode_num": 22,
      "total_reward": 507.72260061917996,
      "episode_length": 1000,
      "avg_reward_per_step": 0.50772260061918,
      "max_reward_step": 6.091950464396291,
      "min_reward_step": -0.9000000000000228,
      "steering_mean": 0.03957647085189819,
      "steering_std": 1.3678374290466309,
      "throttle_mean": -0.42163732647895813,
      "brake_mean": -1.339508056640625
    },
    {
      "episode_num": 23,
      "total_reward": 912.4999999999841,
      "episode_length": 835,
      "avg_reward_per_step": 1.092814371257466,
      "max_reward_step": 6.111180124223603,
      "min_reward_step": -0.9000000000000228,
      "steering_mean": -0.1945294588804245,
      "steering_std": 1.6308168172836304,
      "throttle_mean": -0.28281155228614807,
      "brake_mean": -1.3642867803573608
    },
    {
      "episode_num": 24,
      "total_reward": 769.3062499999941,
      "episode_length": 632,
      "avg_reward_per_step": 1.2172567246835349,
      "max_reward_step": 7.7125,
      "min_reward_step": -0.9000000000000228,
      "steering_mean": -0.08301789313554764,
      "steering_std": 1.3453303575515747,
      "throttle_mean": -0.42985591292381287,
      "brake_mean": -1.2020957469940186
    },
    {
      "episode_num": 25,
      "total_reward": 635.4273224043549,
      "episode_length": 1000,
      "avg_reward_per_step": 0.6354273224043548,
      "max_reward_step": 5.364480874316968,
      "min_reward_step": -0.9000000000000228,
      "steering_mean": -0.024828532710671425,
      "steering_std": 1.3448268175125122,
      "throttle_mean": -0.24445217847824097,
      "brake_mean": -1.3648457527160645
    },
    {
      "episode_num": 26,
      "total_reward": 920.2999999999851,
      "episode_length": 725,
      "avg_reward_per_step": 1.269379310344807,
      "max_reward_step": 6.749315068493151,
      "min_reward_step": -0.9000000000000228,
      "steering_mean": -0.04302847385406494,
      "steering_std": 1.4955843687057495,
      "throttle_mean": -0.42608338594436646,
      "brake_mean": -1.3258795738220215
    },
    {
      "episode_num": 27,
      "total_reward": 929.5999999999875,
      "episode_length": 672,
      "avg_reward_per_step": 1.3833333333333147,
      "max_reward_step": 7.042857142857144,
      "min_reward_step": -0.9000000000000228,
      "steering_mean": -0.028714565560221672,
      "steering_std": 1.2259544134140015,
      "throttle_mean": -0.3172016739845276,
      "brake_mean": -1.419632911682129
    },
    {
      "episode_num": 28,
      "total_reward": 934.1999999999863,
      "episode_length": 658,
      "avg_reward_per_step": 1.4197568389057542,
      "max_reward_step": 7.418796992481203,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.03630455583333969,
      "steering_std": 1.4965766668319702,
      "throttle_mean": -0.43399521708488464,
      "brake_mean": -1.417787790298462
    },
    {
      "episode_num": 29,
      "total_reward": 928.0999999999872,
      "episode_length": 671,
      "avg_reward_per_step": 1.3831594634873132,
      "max_reward_step": 7.094244604316547,
      "min_reward_step": -0.9000000000000228,
      "steering_mean": -0.10479840636253357,
      "steering_std": 1.4638890027999878,
      "throttle_mean": -0.5172603130340576,
      "brake_mean": -1.3249763250350952
    }
  ]
}