{
  "model": "model_2500k",
  "evaluation_date": "2026-01-12T22:46:34.997495",
  "num_episodes": 30,
  "seed": 42,
  "device": "cuda",
  "statistics": {
    "mean_reward": 788.3831578864223,
    "std_reward": 195.8145064714643,
    "min_reward": 195.93333333332168,
    "max_reward": 932.4999999999858,
    "median_reward": 872.017033110261,
    "mean_length": 942.9333333333333,
    "std_length": 100.708137153305,
    "win_rate": 26.666666666666668,
    "success_rate": 100.0,
    "steering_mean": -0.07911381389324863,
    "throttle_mean": 0.38548716381192205,
    "brake_mean": -0.5274295707543691
  },
  "episodes": [
    {
      "episode_num": 0,
      "total_reward": 921.5999999999858,
      "episode_length": 784,
      "avg_reward_per_step": 1.1755102040816146,
      "max_reward_step": 6.967137809187279,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.08377770334482193,
      "steering_std": 1.0538668632507324,
      "throttle_mean": 0.3833092153072357,
      "brake_mean": -0.5252261757850647
    },
    {
      "episode_num": 1,
      "total_reward": 890.0990099009773,
      "episode_length": 1000,
      "avg_reward_per_step": 0.8900990099009773,
      "max_reward_step": 6.500660066006617,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.08684022724628448,
      "steering_std": 0.9664179086685181,
      "throttle_mean": 0.4151322543621063,
      "brake_mean": -0.5364068746566772
    },
    {
      "episode_num": 2,
      "total_reward": 607.7363896847969,
      "episode_length": 1000,
      "avg_reward_per_step": 0.6077363896847969,
      "max_reward_step": 5.630659025787966,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.09199456125497818,
      "steering_std": 0.8995836973190308,
      "throttle_mean": 0.3535970449447632,
      "brake_mean": -0.44074302911758423
    },
    {
      "episode_num": 3,
      "total_reward": 868.1528662420155,
      "episode_length": 1000,
      "avg_reward_per_step": 0.8681528662420155,
      "max_reward_step": 6.269426751592357,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.10046246647834778,
      "steering_std": 1.0258499383926392,
      "throttle_mean": 0.33377256989479065,
      "brake_mean": -0.471121609210968
    },
    {
      "episode_num": 4,
      "total_reward": 854.2483660130491,
      "episode_length": 1000,
      "avg_reward_per_step": 0.8542483660130491,
      "max_reward_step": 6.435947712418304,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.09312695264816284,
      "steering_std": 0.9688569903373718,
      "throttle_mean": 0.42269593477249146,
      "brake_mean": -0.555523693561554
    },
    {
      "episode_num": 5,
      "total_reward": 925.4999999999844,
      "episode_length": 745,
      "avg_reward_per_step": 1.24228187919461,
      "max_reward_step": 6.725938566552902,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.04611428454518318,
      "steering_std": 1.1480355262756348,
      "throttle_mean": 0.5615505576133728,
      "brake_mean": -0.5659632086753845
    },
    {
      "episode_num": 6,
      "total_reward": 892.7007299269861,
      "episode_length": 1000,
      "avg_reward_per_step": 0.8927007299269861,
      "max_reward_step": 7.199270072992701,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.05950119346380234,
      "steering_std": 0.9023240804672241,
      "throttle_mean": 0.3601042628288269,
      "brake_mean": -0.520523190498352
    },
    {
      "episode_num": 7,
      "total_reward": 279.2048929663451,
      "episode_length": 1000,
      "avg_reward_per_step": 0.2792048929663451,
      "max_reward_step": 6.016207951070337,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.1945519745349884,
      "steering_std": 0.6573063731193542,
      "throttle_mean": 0.03249296545982361,
      "brake_mean": -0.43387317657470703
    },
    {
      "episode_num": 8,
      "total_reward": 932.4999999999858,
      "episode_length": 675,
      "avg_reward_per_step": 1.3814814814814604,
      "max_reward_step": 6.772852233676976,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.0469864159822464,
      "steering_std": 1.033880591392517,
      "throttle_mean": 0.45414406061172485,
      "brake_mean": -0.5452260375022888
    },
    {
      "episode_num": 9,
      "total_reward": 896.6329966329764,
      "episode_length": 1000,
      "avg_reward_per_step": 0.8966329966329765,
      "max_reward_step": 6.634006734006735,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.12238878011703491,
      "steering_std": 1.0214345455169678,
      "throttle_mean": 0.3420710563659668,
      "brake_mean": -0.5256068110466003
    },
    {
      "episode_num": 10,
      "total_reward": 195.93333333332168,
      "episode_length": 775,
      "avg_reward_per_step": 0.25281720430106025,
      "max_reward_step": 6.566666666666667,
      "min_reward_step": -100.0,
      "steering_mean": -0.06009947881102562,
      "steering_std": 0.9366564154624939,
      "throttle_mean": 0.21753229200839996,
      "brake_mean": -0.552422285079956
    },
    {
      "episode_num": 11,
      "total_reward": 919.1999999999854,
      "episode_length": 808,
      "avg_reward_per_step": 1.1376237623762195,
      "max_reward_step": 7.042857142857173,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.08911310136318207,
      "steering_std": 0.9494887590408325,
      "throttle_mean": 0.40309980511665344,
      "brake_mean": -0.49473467469215393
    },
    {
      "episode_num": 12,
      "total_reward": 872.9729729729513,
      "episode_length": 1000,
      "avg_reward_per_step": 0.8729729729729513,
      "max_reward_step": 6.656756756756757,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.11276477575302124,
      "steering_std": 1.0305577516555786,
      "throttle_mean": 0.3423076272010803,
      "brake_mean": -0.5812183618545532
    },
    {
      "episode_num": 13,
      "total_reward": 871.0610932475706,
      "episode_length": 1000,
      "avg_reward_per_step": 0.8710610932475706,
      "max_reward_step": 6.330868167202572,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.08562543988227844,
      "steering_std": 1.1065832376480103,
      "throttle_mean": 0.4842722415924072,
      "brake_mean": -0.5142874717712402
    },
    {
      "episode_num": 14,
      "total_reward": 822.1183800622831,
      "episode_length": 1000,
      "avg_reward_per_step": 0.8221183800622831,
      "max_reward_step": 6.1305295950155765,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.046698201447725296,
      "steering_std": 1.013026475906372,
      "throttle_mean": 0.43634721636772156,
      "brake_mean": -0.5138006806373596
    },
    {
      "episode_num": 15,
      "total_reward": 886.2068965517047,
      "episode_length": 1000,
      "avg_reward_per_step": 0.8862068965517047,
      "max_reward_step": 6.7965517241379345,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.08932346850633621,
      "steering_std": 1.0330041646957397,
      "throttle_mean": 0.4399413466453552,
      "brake_mean": -0.5109457969665527
    },
    {
      "episode_num": 16,
      "total_reward": 494.5017182130433,
      "episode_length": 1000,
      "avg_reward_per_step": 0.49450171821304334,
      "max_reward_step": 6.772852233676976,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.07102540880441666,
      "steering_std": 0.8443856239318848,
      "throttle_mean": 0.21149715781211853,
      "brake_mean": -0.5126685500144958
    },
    {
      "episode_num": 17,
      "total_reward": 909.0999999999801,
      "episode_length": 909,
      "avg_reward_per_step": 1.0001100110010783,
      "max_reward_step": 6.725938566552902,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.04583361744880676,
      "steering_std": 0.9718409776687622,
      "throttle_mean": 0.4957541525363922,
      "brake_mean": -0.5466516613960266
    },
    {
      "episode_num": 18,
      "total_reward": 457.3770491803115,
      "episode_length": 1000,
      "avg_reward_per_step": 0.45737704918031147,
      "max_reward_step": 6.457377049180328,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.09276745468378067,
      "steering_std": 0.832707941532135,
      "throttle_mean": 0.5200642347335815,
      "brake_mean": -0.5171390175819397
    },
    {
      "episode_num": 19,
      "total_reward": 870.9677419354716,
      "episode_length": 1000,
      "avg_reward_per_step": 0.8709677419354717,
      "max_reward_step": 6.351612903225806,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.038881491869688034,
      "steering_std": 0.9651921391487122,
      "throttle_mean": 0.4331337511539459,
      "brake_mean": -0.5543381571769714
    },
    {
      "episode_num": 20,
      "total_reward": 889.0510948904906,
      "episode_length": 1000,
      "avg_reward_per_step": 0.8890510948904906,
      "max_reward_step": 7.199270072992701,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.08163714408874512,
      "steering_std": 0.9287211298942566,
      "throttle_mean": 0.4676389694213867,
      "brake_mean": -0.5458387732505798
    },
    {
      "episode_num": 21,
      "total_reward": 888.8475836431055,
      "episode_length": 1000,
      "avg_reward_per_step": 0.8888475836431055,
      "max_reward_step": 7.334944237918216,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.07768429070711136,
      "steering_std": 0.9433750510215759,
      "throttle_mean": 0.2783726751804352,
      "brake_mean": -0.5266257524490356
    },
    {
      "episode_num": 22,
      "total_reward": 928.0999999999902,
      "episode_length": 719,
      "avg_reward_per_step": 1.2908205841446319,
      "max_reward_step": 7.017437722419935,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.03890569135546684,
      "steering_std": 1.0529308319091797,
      "throttle_mean": 0.5258225202560425,
      "brake_mean": -0.5799514055252075
    },
    {
      "episode_num": 23,
      "total_reward": 903.2999999999895,
      "episode_length": 967,
      "avg_reward_per_step": 0.934126163391923,
      "max_reward_step": 7.120216606498195,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.1206170991063118,
      "steering_std": 1.056317925453186,
      "throttle_mean": 0.35429733991622925,
      "brake_mean": -0.5198758840560913
    },
    {
      "episode_num": 24,
      "total_reward": 803.9145907473148,
      "episode_length": 1000,
      "avg_reward_per_step": 0.8039145907473149,
      "max_reward_step": 7.017437722419929,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": 0.052356258034706116,
      "steering_std": 0.8960623145103455,
      "throttle_mean": 0.3207262456417084,
      "brake_mean": -0.5473338961601257
    },
    {
      "episode_num": 25,
      "total_reward": 858.3333333333157,
      "episode_length": 1000,
      "avg_reward_per_step": 0.8583333333333157,
      "max_reward_step": 6.310256410256411,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.09389603137969971,
      "steering_std": 0.9926015138626099,
      "throttle_mean": 0.5079978108406067,
      "brake_mean": -0.5902507305145264
    },
    {
      "episode_num": 26,
      "total_reward": 698.0769230769066,
      "episode_length": 1000,
      "avg_reward_per_step": 0.6980769230769066,
      "max_reward_step": 6.310256410256411,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.015018687583506107,
      "steering_std": 1.0092730522155762,
      "throttle_mean": 0.427255243062973,
      "brake_mean": -0.5436803102493286
    },
    {
      "episode_num": 27,
      "total_reward": 862.9629629629429,
      "episode_length": 1000,
      "avg_reward_per_step": 0.862962962962943,
      "max_reward_step": 6.634006734006735,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.05204698443412781,
      "steering_std": 1.0477451086044312,
      "throttle_mean": 0.4777700901031494,
      "brake_mean": -0.629281222820282
    },
    {
      "episode_num": 28,
      "total_reward": 909.3999999999884,
      "episode_length": 906,
      "avg_reward_per_step": 1.0037527593818856,
      "max_reward_step": 8.164462809917355,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.08522582799196243,
      "steering_std": 0.9095246195793152,
      "throttle_mean": 0.4519457519054413,
      "brake_mean": -0.46286293864250183
    },
    {
      "episode_num": 29,
      "total_reward": 541.6938110749014,
      "episode_length": 1000,
      "avg_reward_per_step": 0.5416938110749014,
      "max_reward_step": 6.414657980456027,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.20286191999912262,
      "steering_std": 0.7731968760490417,
      "throttle_mean": 0.10996852070093155,
      "brake_mean": -0.45876574516296387
    }
  ]
}