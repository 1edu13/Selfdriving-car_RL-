{
  "model": "model_0200k",
  "evaluation_date": "2026-01-12T22:10:21.988207",
  "num_episodes": 30,
  "seed": 42,
  "device": "cuda",
  "statistics": {
    "mean_reward": 220.0764352150512,
    "std_reward": 115.67430176525401,
    "min_reward": 4.729729729730687,
    "max_reward": 449.83922829580314,
    "median_reward": 251.9630352427813,
    "mean_length": 1000.0,
    "std_length": 0.0,
    "win_rate": 0.0,
    "success_rate": 100.0,
    "steering_mean": -0.33018610449507835,
    "throttle_mean": 0.5289258827765783,
    "brake_mean": -0.6407951096693675
  },
  "episodes": [
    {
      "episode_num": 0,
      "total_reward": 41.34275618374887,
      "episode_length": 1000,
      "avg_reward_per_step": 0.04134275618374887,
      "max_reward_step": 6.967137809187279,
      "min_reward_step": -0.10000000000000142,
      "steering_mean": 0.22079750895500183,
      "steering_std": 0.4931461215019226,
      "throttle_mean": 0.6564330458641052,
      "brake_mean": -0.42797693610191345
    },
    {
      "episode_num": 1,
      "total_reward": 375.24752475245987,
      "episode_length": 1000,
      "avg_reward_per_step": 0.37524752475245987,
      "max_reward_step": 6.500660066006601,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.2232152372598648,
      "steering_std": 0.6712380647659302,
      "throttle_mean": 0.5288363695144653,
      "brake_mean": -0.6568581461906433
    },
    {
      "episode_num": 2,
      "total_reward": 152.14899713467577,
      "episode_length": 1000,
      "avg_reward_per_step": 0.15214899713467578,
      "max_reward_step": 5.630659025787966,
      "min_reward_step": -0.10000000000000142,
      "steering_mean": -0.5979018807411194,
      "steering_std": 0.7706907391548157,
      "throttle_mean": 0.38441017270088196,
      "brake_mean": -0.6648459434509277
    },
    {
      "episode_num": 3,
      "total_reward": 247.13375796176925,
      "episode_length": 1000,
      "avg_reward_per_step": 0.24713375796176926,
      "max_reward_step": 6.269426751592357,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": 0.20709435641765594,
      "steering_std": 0.4331364035606384,
      "throttle_mean": 0.6930288672447205,
      "brake_mean": -0.5689576268196106
    },
    {
      "episode_num": 4,
      "total_reward": 256.2091503267817,
      "episode_length": 1000,
      "avg_reward_per_step": 0.2562091503267817,
      "max_reward_step": 6.435947712418301,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.87778639793396,
      "steering_std": 0.7090051174163818,
      "throttle_mean": 0.49112939834594727,
      "brake_mean": -0.761950671672821
    },
    {
      "episode_num": 5,
      "total_reward": 53.58361774744463,
      "episode_length": 1000,
      "avg_reward_per_step": 0.05358361774744463,
      "max_reward_step": 6.725938566552902,
      "min_reward_step": -0.10000000000000142,
      "steering_mean": 0.14151965081691742,
      "steering_std": 0.6151672005653381,
      "throttle_mean": 0.6743415594100952,
      "brake_mean": -0.516368567943573
    },
    {
      "episode_num": 6,
      "total_reward": 254.01459854013058,
      "episode_length": 1000,
      "avg_reward_per_step": 0.2540145985401306,
      "max_reward_step": 7.199270072992701,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.6122965216636658,
      "steering_std": 0.742607831954956,
      "throttle_mean": 0.49643877148628235,
      "brake_mean": -0.680696427822113
    },
    {
      "episode_num": 7,
      "total_reward": 242.50764525992807,
      "episode_length": 1000,
      "avg_reward_per_step": 0.24250764525992807,
      "max_reward_step": 6.016207951070337,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.1840822696685791,
      "steering_std": 0.7658267021179199,
      "throttle_mean": 0.4734286665916443,
      "brake_mean": -0.5923306345939636
    },
    {
      "episode_num": 8,
      "total_reward": 288.31615120273284,
      "episode_length": 1000,
      "avg_reward_per_step": 0.28831615120273285,
      "max_reward_step": 6.772852233676976,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": 0.026517441496253014,
      "steering_std": 0.6529168486595154,
      "throttle_mean": 0.6130802035331726,
      "brake_mean": -0.5387327671051025
    },
    {
      "episode_num": 9,
      "total_reward": 280.47138047136394,
      "episode_length": 1000,
      "avg_reward_per_step": 0.28047138047136394,
      "max_reward_step": 6.634006734006735,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.549081027507782,
      "steering_std": 0.7406876683235168,
      "throttle_mean": 0.4143542945384979,
      "brake_mean": -0.6975208520889282
    },
    {
      "episode_num": 10,
      "total_reward": 406.66666666665054,
      "episode_length": 1000,
      "avg_reward_per_step": 0.4066666666666505,
      "max_reward_step": 6.566666666666667,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.01372251845896244,
      "steering_std": 0.6250104904174805,
      "throttle_mean": 0.4665617048740387,
      "brake_mean": -0.6229979395866394
    },
    {
      "episode_num": 11,
      "total_reward": 67.85714285714798,
      "episode_length": 1000,
      "avg_reward_per_step": 0.06785714285714797,
      "max_reward_step": 7.042857142857144,
      "min_reward_step": -0.10000000000000142,
      "steering_mean": -0.5468763113021851,
      "steering_std": 0.7598407864570618,
      "throttle_mean": 0.4204276204109192,
      "brake_mean": -0.6753805875778198
    },
    {
      "episode_num": 12,
      "total_reward": 4.729729729730687,
      "episode_length": 1000,
      "avg_reward_per_step": 0.0047297297297306876,
      "max_reward_step": 6.656756756756757,
      "min_reward_step": -0.10000000000000142,
      "steering_mean": 0.3016408085823059,
      "steering_std": 0.49678686261177063,
      "throttle_mean": 0.724641740322113,
      "brake_mean": -0.4323021471500397
    },
    {
      "episode_num": 13,
      "total_reward": 449.83922829580314,
      "episode_length": 1000,
      "avg_reward_per_step": 0.44983922829580314,
      "max_reward_step": 6.330868167202572,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.16331566870212555,
      "steering_std": 0.6794406771659851,
      "throttle_mean": 0.4375138580799103,
      "brake_mean": -0.6908596158027649
    },
    {
      "episode_num": 14,
      "total_reward": 177.25856697819833,
      "episode_length": 1000,
      "avg_reward_per_step": 0.17725856697819833,
      "max_reward_step": 6.130529595015588,
      "min_reward_step": -0.10000000000000142,
      "steering_mean": -0.6737908720970154,
      "steering_std": 0.6391667723655701,
      "throttle_mean": 0.4155785143375397,
      "brake_mean": -0.7570326924324036
    },
    {
      "episode_num": 15,
      "total_reward": 17.24137931034509,
      "episode_length": 1000,
      "avg_reward_per_step": 0.017241379310345088,
      "max_reward_step": 6.796551724137931,
      "min_reward_step": -0.10000000000000142,
      "steering_mean": 0.2708437740802765,
      "steering_std": 0.5524888634681702,
      "throttle_mean": 0.5621675848960876,
      "brake_mean": -0.4408777356147766
    },
    {
      "episode_num": 16,
      "total_reward": 61.51202749141384,
      "episode_length": 1000,
      "avg_reward_per_step": 0.06151202749141384,
      "max_reward_step": 6.772852233676976,
      "min_reward_step": -0.10000000000000142,
      "steering_mean": -0.9236299991607666,
      "steering_std": 0.47044092416763306,
      "throttle_mean": 0.44603002071380615,
      "brake_mean": -0.7488106489181519
    },
    {
      "episode_num": 17,
      "total_reward": 237.8839590443572,
      "episode_length": 1000,
      "avg_reward_per_step": 0.2378839590443572,
      "max_reward_step": 6.725938566552902,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.41162189841270447,
      "steering_std": 0.7666946053504944,
      "throttle_mean": 0.504967212677002,
      "brake_mean": -0.6972765922546387
    },
    {
      "episode_num": 18,
      "total_reward": 286.8852459016232,
      "episode_length": 1000,
      "avg_reward_per_step": 0.2868852459016232,
      "max_reward_step": 6.457377049180328,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.7994914650917053,
      "steering_std": 0.6123679280281067,
      "throttle_mean": 0.4414938986301422,
      "brake_mean": -0.8174902200698853
    },
    {
      "episode_num": 19,
      "total_reward": 251.6129032257915,
      "episode_length": 1000,
      "avg_reward_per_step": 0.2516129032257915,
      "max_reward_step": 6.351612903225806,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.13106249272823334,
      "steering_std": 0.7349717020988464,
      "throttle_mean": 0.6160857677459717,
      "brake_mean": -0.5469982624053955
    },
    {
      "episode_num": 20,
      "total_reward": 56.934306569347605,
      "episode_length": 1000,
      "avg_reward_per_step": 0.05693430656934761,
      "max_reward_step": 7.199270072992701,
      "min_reward_step": -0.10000000000000142,
      "steering_mean": -0.8308157920837402,
      "steering_std": 0.5381981730461121,
      "throttle_mean": 0.5266623497009277,
      "brake_mean": -0.7181538343429565
    },
    {
      "episode_num": 21,
      "total_reward": 360.9665427509126,
      "episode_length": 1000,
      "avg_reward_per_step": 0.3609665427509126,
      "max_reward_step": 7.334944237918216,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.7651423215866089,
      "steering_std": 0.6468451619148254,
      "throttle_mean": 0.4386495053768158,
      "brake_mean": -0.8061522245407104
    },
    {
      "episode_num": 22,
      "total_reward": 302.1352313167097,
      "episode_length": 1000,
      "avg_reward_per_step": 0.30213523131670966,
      "max_reward_step": 7.017437722419929,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.8197972178459167,
      "steering_std": 0.6644023060798645,
      "throttle_mean": 0.4542847275733948,
      "brake_mean": -0.7879314422607422
    },
    {
      "episode_num": 23,
      "total_reward": 257.40072202164356,
      "episode_length": 1000,
      "avg_reward_per_step": 0.25740072202164355,
      "max_reward_step": 7.120216606498195,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.7884301543235779,
      "steering_std": 0.6250101327896118,
      "throttle_mean": 0.5394647121429443,
      "brake_mean": -0.7318904995918274
    },
    {
      "episode_num": 24,
      "total_reward": 252.31316725977106,
      "episode_length": 1000,
      "avg_reward_per_step": 0.25231316725977104,
      "max_reward_step": 7.017437722419929,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": 0.01186277810484171,
      "steering_std": 0.6727157831192017,
      "throttle_mean": 0.5670872926712036,
      "brake_mean": -0.520078718662262
    },
    {
      "episode_num": 25,
      "total_reward": 255.76923076921523,
      "episode_length": 1000,
      "avg_reward_per_step": 0.2557692307692152,
      "max_reward_step": 6.310256410256443,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": 0.18766780197620392,
      "steering_std": 0.5742135047912598,
      "throttle_mean": 0.6337884068489075,
      "brake_mean": -0.48631733655929565
    },
    {
      "episode_num": 26,
      "total_reward": 223.71794871794182,
      "episode_length": 1000,
      "avg_reward_per_step": 0.22371794871794182,
      "max_reward_step": 6.310256410256411,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.6441267728805542,
      "steering_std": 0.7152799367904663,
      "throttle_mean": 0.4320809543132782,
      "brake_mean": -0.7659918665885925
    },
    {
      "episode_num": 27,
      "total_reward": 260.269360269344,
      "episode_length": 1000,
      "avg_reward_per_step": 0.260269360269344,
      "max_reward_step": 6.634006734006735,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.032177384942770004,
      "steering_std": 0.7756373882293701,
      "throttle_mean": 0.5436806082725525,
      "brake_mean": -0.5818173885345459
    },
    {
      "episode_num": 28,
      "total_reward": 313.22314049585106,
      "episode_length": 1000,
      "avg_reward_per_step": 0.31322314049585104,
      "max_reward_step": 8.164462809917355,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.7904856204986572,
      "steering_std": 0.6142228245735168,
      "throttle_mean": 0.5984991192817688,
      "brake_mean": -0.7091612219810486
    },
    {
      "episode_num": 29,
      "total_reward": 167.10097719870237,
      "episode_length": 1000,
      "avg_reward_per_step": 0.16710097719870237,
      "max_reward_step": 6.414657980456042,
      "min_reward_step": -0.10000000000000142,
      "steering_mean": 0.10532256960868835,
      "steering_std": 0.578689455986023,
      "throttle_mean": 0.6726295351982117,
      "brake_mean": -0.5800937414169312
    }
  ]
}