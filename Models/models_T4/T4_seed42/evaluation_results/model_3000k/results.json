{
  "model": "model_3000k",
  "evaluation_date": "2026-01-12T22:54:04.404748",
  "num_episodes": 30,
  "seed": 42,
  "device": "cuda",
  "statistics": {
    "mean_reward": 776.247799085986,
    "std_reward": 181.56660398021253,
    "min_reward": 292.1568627450814,
    "max_reward": 933.2999999999913,
    "median_reward": 871.8852459016244,
    "mean_length": 958.5,
    "std_length": 99.00833298263333,
    "win_rate": 20.0,
    "success_rate": 100.0,
    "steering_mean": -0.0826407124598821,
    "throttle_mean": 0.423567774395148,
    "brake_mean": -0.5277460197607676
  },
  "episodes": [
    {
      "episode_num": 0,
      "total_reward": 338.16254416960544,
      "episode_length": 1000,
      "avg_reward_per_step": 0.33816254416960545,
      "max_reward_step": 6.967137809187279,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.05991889163851738,
      "steering_std": 0.886104166507721,
      "throttle_mean": 0.5495944023132324,
      "brake_mean": -0.5238431692123413
    },
    {
      "episode_num": 1,
      "total_reward": 886.7986798679739,
      "episode_length": 1000,
      "avg_reward_per_step": 0.8867986798679739,
      "max_reward_step": 6.500660066006601,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.04943826049566269,
      "steering_std": 1.0696848630905151,
      "throttle_mean": 0.2916382849216461,
      "brake_mean": -0.5282170176506042
    },
    {
      "episode_num": 2,
      "total_reward": 687.9656160458268,
      "episode_length": 1000,
      "avg_reward_per_step": 0.6879656160458267,
      "max_reward_step": 5.630659025787966,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.06315214186906815,
      "steering_std": 0.8965398669242859,
      "throttle_mean": 0.24326398968696594,
      "brake_mean": -0.5623629689216614
    },
    {
      "episode_num": 3,
      "total_reward": 896.8152866241808,
      "episode_length": 1000,
      "avg_reward_per_step": 0.8968152866241808,
      "max_reward_step": 6.269426751592357,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.07611832767724991,
      "steering_std": 1.0818780660629272,
      "throttle_mean": 0.35273247957229614,
      "brake_mean": -0.5333235859870911
    },
    {
      "episode_num": 4,
      "total_reward": 292.1568627450814,
      "episode_length": 1000,
      "avg_reward_per_step": 0.2921568627450814,
      "max_reward_step": 6.435947712418301,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.193327397108078,
      "steering_std": 0.7919251322746277,
      "throttle_mean": 0.259310245513916,
      "brake_mean": -0.46588271856307983
    },
    {
      "episode_num": 5,
      "total_reward": 780.5460750853039,
      "episode_length": 1000,
      "avg_reward_per_step": 0.7805460750853038,
      "max_reward_step": 6.725938566552912,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.13076725602149963,
      "steering_std": 0.948858916759491,
      "throttle_mean": 0.399091511964798,
      "brake_mean": -0.433681458234787
    },
    {
      "episode_num": 6,
      "total_reward": 856.204379562023,
      "episode_length": 1000,
      "avg_reward_per_step": 0.856204379562023,
      "max_reward_step": 7.199270072992701,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.0504550002515316,
      "steering_std": 0.9603767395019531,
      "throttle_mean": 0.2817683815956116,
      "brake_mean": -0.5137688517570496
    },
    {
      "episode_num": 7,
      "total_reward": 637.0030581039581,
      "episode_length": 1000,
      "avg_reward_per_step": 0.6370030581039581,
      "max_reward_step": 9.074311926605503,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.09035781770944595,
      "steering_std": 0.8575825691223145,
      "throttle_mean": 0.24912215769290924,
      "brake_mean": -0.499389111995697
    },
    {
      "episode_num": 8,
      "total_reward": 862.1993127147554,
      "episode_length": 1000,
      "avg_reward_per_step": 0.8621993127147554,
      "max_reward_step": 6.772852233676976,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.0436987467110157,
      "steering_std": 0.9695441126823425,
      "throttle_mean": 0.3637549579143524,
      "brake_mean": -0.5414899587631226
    },
    {
      "episode_num": 9,
      "total_reward": 900.3999999999797,
      "episode_length": 996,
      "avg_reward_per_step": 0.9040160642570078,
      "max_reward_step": 6.634006734006735,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.07290441542863846,
      "steering_std": 1.1163389682769775,
      "throttle_mean": 0.5329538583755493,
      "brake_mean": -0.5030956864356995
    },
    {
      "episode_num": 10,
      "total_reward": 869.9999999999867,
      "episode_length": 1000,
      "avg_reward_per_step": 0.8699999999999867,
      "max_reward_step": 6.566666666666667,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.06933139264583588,
      "steering_std": 0.9703686833381653,
      "throttle_mean": 0.4464508593082428,
      "brake_mean": -0.4741084575653076
    },
    {
      "episode_num": 11,
      "total_reward": 892.8571428571232,
      "episode_length": 1000,
      "avg_reward_per_step": 0.8928571428571233,
      "max_reward_step": 7.042857142857144,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.08504138141870499,
      "steering_std": 0.9834375977516174,
      "throttle_mean": 0.3176424205303192,
      "brake_mean": -0.4806288480758667
    },
    {
      "episode_num": 12,
      "total_reward": 931.1999999999842,
      "episode_length": 688,
      "avg_reward_per_step": 1.3534883720930004,
      "max_reward_step": 6.656756756756757,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.08112281560897827,
      "steering_std": 1.1488621234893799,
      "throttle_mean": 0.5960297584533691,
      "brake_mean": -0.5464332699775696
    },
    {
      "episode_num": 13,
      "total_reward": 923.4999999999874,
      "episode_length": 765,
      "avg_reward_per_step": 1.2071895424836436,
      "max_reward_step": 6.330868167202572,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.11363346874713898,
      "steering_std": 1.255745530128479,
      "throttle_mean": 0.6629920601844788,
      "brake_mean": -0.5670564770698547
    },
    {
      "episode_num": 14,
      "total_reward": 638.3177570093264,
      "episode_length": 1000,
      "avg_reward_per_step": 0.6383177570093265,
      "max_reward_step": 9.24579439252318,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.1258784681558609,
      "steering_std": 0.9933406114578247,
      "throttle_mean": 0.2135675847530365,
      "brake_mean": -0.4988924562931061
    },
    {
      "episode_num": 15,
      "total_reward": 896.5517241379112,
      "episode_length": 1000,
      "avg_reward_per_step": 0.8965517241379112,
      "max_reward_step": 6.7965517241379345,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.045009683817625046,
      "steering_std": 1.0347915887832642,
      "throttle_mean": 0.4143611490726471,
      "brake_mean": -0.4734181761741638
    },
    {
      "episode_num": 16,
      "total_reward": 893.1271477663031,
      "episode_length": 1000,
      "avg_reward_per_step": 0.8931271477663031,
      "max_reward_step": 6.772852233676986,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.11468423902988434,
      "steering_std": 0.9627947807312012,
      "throttle_mean": 0.37287306785583496,
      "brake_mean": -0.5479022264480591
    },
    {
      "episode_num": 17,
      "total_reward": 749.829351535815,
      "episode_length": 1000,
      "avg_reward_per_step": 0.749829351535815,
      "max_reward_step": 6.725938566552902,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.04897548630833626,
      "steering_std": 0.9710085391998291,
      "throttle_mean": 0.5204360485076904,
      "brake_mean": -0.5044774413108826
    },
    {
      "episode_num": 18,
      "total_reward": 873.7704918032622,
      "episode_length": 1000,
      "avg_reward_per_step": 0.8737704918032622,
      "max_reward_step": 6.457377049180328,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.06866395473480225,
      "steering_std": 0.9902025461196899,
      "throttle_mean": 0.5403596758842468,
      "brake_mean": -0.5257897973060608
    },
    {
      "episode_num": 19,
      "total_reward": 927.299999999994,
      "episode_length": 727,
      "avg_reward_per_step": 1.2755158184319038,
      "max_reward_step": 6.351612903225806,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.12347334623336792,
      "steering_std": 1.1529208421707153,
      "throttle_mean": 0.469819575548172,
      "brake_mean": -0.6005213260650635
    },
    {
      "episode_num": 20,
      "total_reward": 896.3503649634831,
      "episode_length": 1000,
      "avg_reward_per_step": 0.8963503649634831,
      "max_reward_step": 7.199270072992732,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.10004040598869324,
      "steering_std": 0.9713937044143677,
      "throttle_mean": 0.5201606154441833,
      "brake_mean": -0.5493837594985962
    },
    {
      "episode_num": 21,
      "total_reward": 524.5353159851127,
      "episode_length": 1000,
      "avg_reward_per_step": 0.5245353159851127,
      "max_reward_step": 7.334944237918216,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.09968116879463196,
      "steering_std": 0.8800862431526184,
      "throttle_mean": 0.3906182646751404,
      "brake_mean": -0.5827863812446594
    },
    {
      "episode_num": 22,
      "total_reward": 933.2999999999913,
      "episode_length": 667,
      "avg_reward_per_step": 1.3992503748125806,
      "max_reward_step": 7.017437722419929,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.1201944500207901,
      "steering_std": 1.149434208869934,
      "throttle_mean": 0.5159088373184204,
      "brake_mean": -0.5483388304710388
    },
    {
      "episode_num": 23,
      "total_reward": 881.9494584837428,
      "episode_length": 1000,
      "avg_reward_per_step": 0.8819494584837427,
      "max_reward_step": 7.120216606498275,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.12186489254236221,
      "steering_std": 1.1355668306350708,
      "throttle_mean": 0.5119606256484985,
      "brake_mean": -0.499193012714386
    },
    {
      "episode_num": 24,
      "total_reward": 875.0889679715139,
      "episode_length": 1000,
      "avg_reward_per_step": 0.8750889679715138,
      "max_reward_step": 7.017437722419929,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.09343664348125458,
      "steering_std": 1.0270795822143555,
      "throttle_mean": 0.4984826445579529,
      "brake_mean": -0.5586451888084412
    },
    {
      "episode_num": 25,
      "total_reward": 412.820512820498,
      "episode_length": 1000,
      "avg_reward_per_step": 0.412820512820498,
      "max_reward_step": 6.310256410256443,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.1088186502456665,
      "steering_std": 0.8986782431602478,
      "throttle_mean": 0.31590735912323,
      "brake_mean": -0.5445163249969482
    },
    {
      "episode_num": 26,
      "total_reward": 867.9487179486998,
      "episode_length": 1000,
      "avg_reward_per_step": 0.8679487179486999,
      "max_reward_step": 6.310256410256411,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.016986509785056114,
      "steering_std": 1.0140132904052734,
      "throttle_mean": 0.58876633644104,
      "brake_mean": -0.5461717247962952
    },
    {
      "episode_num": 27,
      "total_reward": 674.4107744107553,
      "episode_length": 1000,
      "avg_reward_per_step": 0.6744107744107553,
      "max_reward_step": 6.634006734006735,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.015143943950533867,
      "steering_std": 0.9449331760406494,
      "throttle_mean": 0.3049708604812622,
      "brake_mean": -0.5991325974464417
    },
    {
      "episode_num": 28,
      "total_reward": 908.7999999999881,
      "episode_length": 912,
      "avg_reward_per_step": 0.9964912280701624,
      "max_reward_step": 8.164462809917381,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.06609973311424255,
      "steering_std": 0.9546658396720886,
      "throttle_mean": 0.532173752784729,
      "brake_mean": -0.5288648009300232
    },
    {
      "episode_num": 29,
      "total_reward": 577.5244299674094,
      "episode_length": 1000,
      "avg_reward_per_step": 0.5775244299674095,
      "max_reward_step": 6.414657980456027,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.031002484261989594,
      "steering_std": 0.9273888468742371,
      "throttle_mean": 0.4503214657306671,
      "brake_mean": -0.5510649681091309
    }
  ]
}