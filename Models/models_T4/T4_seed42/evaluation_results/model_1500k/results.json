{
  "model": "model_1500k",
  "evaluation_date": "2026-01-12T22:32:04.964070",
  "num_episodes": 30,
  "seed": 42,
  "device": "cuda",
  "statistics": {
    "mean_reward": 733.2662885528887,
    "std_reward": 258.3355397180706,
    "min_reward": 94.5392491467629,
    "max_reward": 938.9999999999953,
    "median_reward": 883.1649831649634,
    "mean_length": 897.7,
    "std_length": 137.563355101083,
    "win_rate": 36.666666666666664,
    "success_rate": 100.0,
    "steering_mean": -0.05920285372218738,
    "throttle_mean": 0.5613714635372162,
    "brake_mean": -0.4205997586250305
  },
  "episodes": [
    {
      "episode_num": 0,
      "total_reward": 104.94699646643605,
      "episode_length": 1000,
      "avg_reward_per_step": 0.10494699646643604,
      "max_reward_step": 6.967137809187279,
      "min_reward_step": -0.10000000000000142,
      "steering_mean": -0.06706409901380539,
      "steering_std": 0.6147171258926392,
      "throttle_mean": 0.4624572694301605,
      "brake_mean": -0.3896431624889374
    },
    {
      "episode_num": 1,
      "total_reward": 523.7623762376088,
      "episode_length": 1000,
      "avg_reward_per_step": 0.5237623762376088,
      "max_reward_step": 6.500660066006601,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.07228595018386841,
      "steering_std": 0.8060485124588013,
      "throttle_mean": 0.5527920126914978,
      "brake_mean": -0.49926289916038513
    },
    {
      "episode_num": 2,
      "total_reward": 435.81661891116045,
      "episode_length": 1000,
      "avg_reward_per_step": 0.43581661891116047,
      "max_reward_step": 5.630659025787966,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.05619517341256142,
      "steering_std": 0.7784673571586609,
      "throttle_mean": 0.5783572196960449,
      "brake_mean": -0.3798547387123108
    },
    {
      "episode_num": 3,
      "total_reward": 877.7070063694043,
      "episode_length": 1000,
      "avg_reward_per_step": 0.8777070063694044,
      "max_reward_step": 6.269426751592357,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.03634870797395706,
      "steering_std": 0.9625669121742249,
      "throttle_mean": 0.6903837323188782,
      "brake_mean": -0.4198814332485199
    },
    {
      "episode_num": 4,
      "total_reward": 530.7189542483491,
      "episode_length": 1000,
      "avg_reward_per_step": 0.530718954248349,
      "max_reward_step": 6.435947712418301,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.03719888627529144,
      "steering_std": 0.8882266879081726,
      "throttle_mean": 0.5346962809562683,
      "brake_mean": -0.4881480634212494
    },
    {
      "episode_num": 5,
      "total_reward": 94.5392491467629,
      "episode_length": 1000,
      "avg_reward_per_step": 0.0945392491467629,
      "max_reward_step": 6.725938566552912,
      "min_reward_step": -0.10000000000000142,
      "steering_mean": -0.06686539202928543,
      "steering_std": 0.7419136166572571,
      "throttle_mean": 0.6199610829353333,
      "brake_mean": -0.39500635862350464
    },
    {
      "episode_num": 6,
      "total_reward": 896.3503649634825,
      "episode_length": 1000,
      "avg_reward_per_step": 0.8963503649634825,
      "max_reward_step": 7.199270072992701,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.07258645445108414,
      "steering_std": 0.9183834791183472,
      "throttle_mean": 0.7680699229240417,
      "brake_mean": -0.3662838935852051
    },
    {
      "episode_num": 7,
      "total_reward": 318.9602446483027,
      "episode_length": 1000,
      "avg_reward_per_step": 0.3189602446483027,
      "max_reward_step": 6.016207951070337,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.05117399990558624,
      "steering_std": 0.7499180436134338,
      "throttle_mean": 0.3734571039676666,
      "brake_mean": -0.4501221179962158
    },
    {
      "episode_num": 8,
      "total_reward": 927.299999999985,
      "episode_length": 727,
      "avg_reward_per_step": 1.2755158184318913,
      "max_reward_step": 6.772852233676976,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.05342498794198036,
      "steering_std": 0.9806437492370605,
      "throttle_mean": 0.5205512046813965,
      "brake_mean": -0.44546690583229065
    },
    {
      "episode_num": 9,
      "total_reward": 883.1649831649632,
      "episode_length": 1000,
      "avg_reward_per_step": 0.8831649831649633,
      "max_reward_step": 6.634006734006739,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.027345791459083557,
      "steering_std": 0.8855721354484558,
      "throttle_mean": 0.5710996389389038,
      "brake_mean": -0.38219672441482544
    },
    {
      "episode_num": 10,
      "total_reward": 359.99999999999613,
      "episode_length": 1000,
      "avg_reward_per_step": 0.35999999999999616,
      "max_reward_step": 6.566666666666667,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.10540978610515594,
      "steering_std": 0.8253148198127747,
      "throttle_mean": 0.5042797327041626,
      "brake_mean": -0.4441104233264923
    },
    {
      "episode_num": 11,
      "total_reward": 917.2999999999852,
      "episode_length": 827,
      "avg_reward_per_step": 1.1091898428053024,
      "max_reward_step": 7.042857142857173,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.05897590145468712,
      "steering_std": 0.8326563239097595,
      "throttle_mean": 0.5710080862045288,
      "brake_mean": -0.401726096868515
    },
    {
      "episode_num": 12,
      "total_reward": 902.1999999999782,
      "episode_length": 978,
      "avg_reward_per_step": 0.9224948875255401,
      "max_reward_step": 6.656756756756757,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.03459842875599861,
      "steering_std": 0.8757255673408508,
      "throttle_mean": 0.4599076807498932,
      "brake_mean": -0.4655710458755493
    },
    {
      "episode_num": 13,
      "total_reward": 922.399999999987,
      "episode_length": 776,
      "avg_reward_per_step": 1.1886597938144163,
      "max_reward_step": 6.330868167202572,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.06276962161064148,
      "steering_std": 1.0483684539794922,
      "throttle_mean": 0.6587964296340942,
      "brake_mean": -0.4368131458759308
    },
    {
      "episode_num": 14,
      "total_reward": 424.6003115264708,
      "episode_length": 674,
      "avg_reward_per_step": 0.6299707886149418,
      "max_reward_step": 6.1305295950155765,
      "min_reward_step": -100.0,
      "steering_mean": -0.0665317103266716,
      "steering_std": 0.945554256439209,
      "throttle_mean": 0.2577839195728302,
      "brake_mean": -0.5064716935157776
    },
    {
      "episode_num": 15,
      "total_reward": 926.3999999999863,
      "episode_length": 736,
      "avg_reward_per_step": 1.2586956521738946,
      "max_reward_step": 6.796551724137931,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.10431716591119766,
      "steering_std": 1.0050208568572998,
      "throttle_mean": 0.4864237308502197,
      "brake_mean": -0.41155368089675903
    },
    {
      "episode_num": 16,
      "total_reward": 848.4536082474054,
      "episode_length": 1000,
      "avg_reward_per_step": 0.8484536082474055,
      "max_reward_step": 6.772852233676986,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.047491561621427536,
      "steering_std": 0.9120544195175171,
      "throttle_mean": 0.6194389462471008,
      "brake_mean": -0.37704986333847046
    },
    {
      "episode_num": 17,
      "total_reward": 715.6996587030513,
      "episode_length": 1000,
      "avg_reward_per_step": 0.7156996587030513,
      "max_reward_step": 6.725938566552912,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.09095574170351028,
      "steering_std": 0.8811505436897278,
      "throttle_mean": 0.4263502061367035,
      "brake_mean": -0.4210043251514435
    },
    {
      "episode_num": 18,
      "total_reward": 880.3278688524431,
      "episode_length": 1000,
      "avg_reward_per_step": 0.8803278688524431,
      "max_reward_step": 6.457377049180328,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.1077335998415947,
      "steering_std": 0.9156709909439087,
      "throttle_mean": 0.7076475620269775,
      "brake_mean": -0.34664735198020935
    },
    {
      "episode_num": 19,
      "total_reward": 920.3999999999929,
      "episode_length": 796,
      "avg_reward_per_step": 1.156281407035167,
      "max_reward_step": 6.351612903225806,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.08760759234428406,
      "steering_std": 1.0540319681167603,
      "throttle_mean": 0.6079845428466797,
      "brake_mean": -0.4336877465248108
    },
    {
      "episode_num": 20,
      "total_reward": 928.0999999999867,
      "episode_length": 719,
      "avg_reward_per_step": 1.290820584144627,
      "max_reward_step": 7.199270072992701,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.038994792848825455,
      "steering_std": 0.7990267276763916,
      "throttle_mean": 0.5517680644989014,
      "brake_mean": -0.39967629313468933
    },
    {
      "episode_num": 21,
      "total_reward": 932.2999999999902,
      "episode_length": 677,
      "avg_reward_per_step": 1.3771048744460712,
      "max_reward_step": 7.334944237918216,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.0437130481004715,
      "steering_std": 0.9673941135406494,
      "throttle_mean": 0.6441887021064758,
      "brake_mean": -0.4443279206752777
    },
    {
      "episode_num": 22,
      "total_reward": 930.1999999999907,
      "episode_length": 698,
      "avg_reward_per_step": 1.332664756446978,
      "max_reward_step": 7.017437722419929,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.0219963937997818,
      "steering_std": 0.9288831353187561,
      "throttle_mean": 0.45537105202674866,
      "brake_mean": -0.45771515369415283
    },
    {
      "episode_num": 23,
      "total_reward": 892.7797833934903,
      "episode_length": 1000,
      "avg_reward_per_step": 0.8927797833934903,
      "max_reward_step": 7.120216606498195,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.11257318407297134,
      "steering_std": 0.9666188955307007,
      "throttle_mean": 0.5533661246299744,
      "brake_mean": -0.35162293910980225
    },
    {
      "episode_num": 24,
      "total_reward": 928.6999999999904,
      "episode_length": 713,
      "avg_reward_per_step": 1.3025245441795097,
      "max_reward_step": 7.017437722419929,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.04206492751836777,
      "steering_std": 1.0189350843429565,
      "throttle_mean": 0.6000902652740479,
      "brake_mean": -0.4276025593280792
    },
    {
      "episode_num": 25,
      "total_reward": 896.7948717948537,
      "episode_length": 1000,
      "avg_reward_per_step": 0.8967948717948537,
      "max_reward_step": 6.310256410256411,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.09186903387308121,
      "steering_std": 0.9856945276260376,
      "throttle_mean": 0.5971158742904663,
      "brake_mean": -0.38817131519317627
    },
    {
      "episode_num": 26,
      "total_reward": 707.6923076922916,
      "episode_length": 1000,
      "avg_reward_per_step": 0.7076923076922916,
      "max_reward_step": 6.310256410256411,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.06876301020383835,
      "steering_std": 0.9475716948509216,
      "throttle_mean": 0.6414691805839539,
      "brake_mean": -0.4353218376636505
    },
    {
      "episode_num": 27,
      "total_reward": 883.1649831649634,
      "episode_length": 1000,
      "avg_reward_per_step": 0.8831649831649634,
      "max_reward_step": 6.634006734006735,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.0787988230586052,
      "steering_std": 0.958210825920105,
      "throttle_mean": 0.6955797076225281,
      "brake_mean": -0.41704699397087097
    },
    {
      "episode_num": 28,
      "total_reward": 938.9999999999953,
      "episode_length": 610,
      "avg_reward_per_step": 1.5393442622950744,
      "max_reward_step": 8.164462809917355,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": 0.0036044714506715536,
      "steering_std": 1.047068476676941,
      "throttle_mean": 0.6880865693092346,
      "brake_mean": -0.3381009101867676
    },
    {
      "episode_num": 29,
      "total_reward": 548.2084690553584,
      "episode_length": 1000,
      "avg_reward_per_step": 0.5482084690553584,
      "max_reward_step": 6.414657980456027,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": 0.025963682681322098,
      "steering_std": 0.8122872114181519,
      "throttle_mean": 0.4426620602607727,
      "brake_mean": -0.4979051649570465
    }
  ]
}