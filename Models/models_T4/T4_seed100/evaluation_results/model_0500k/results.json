{
  "model": "model_0500k",
  "evaluation_date": "2026-01-12T19:34:11.475317",
  "num_episodes": 30,
  "seed": 100,
  "device": "cuda",
  "statistics": {
    "mean_reward": 316.67973530860166,
    "std_reward": 183.92207167991577,
    "min_reward": -16.281818181813264,
    "max_reward": 834.5454545454356,
    "median_reward": 323.1645739309015,
    "mean_length": 999.4,
    "std_length": 3.231098884280702,
    "win_rate": 0.0,
    "success_rate": 96.66666666666667,
    "steering_mean": -0.08547713002189994,
    "throttle_mean": 0.8232966847717762,
    "brake_mean": -0.4613839042062561
  },
  "episodes": [
    {
      "episode_num": 0,
      "total_reward": 381.4814814814645,
      "episode_length": 1000,
      "avg_reward_per_step": 0.38148148148146455,
      "max_reward_step": 7.307407407407408,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.006488845683634281,
      "steering_std": 0.8985616564750671,
      "throttle_mean": 0.9872515201568604,
      "brake_mean": -0.40574413537979126
    },
    {
      "episode_num": 1,
      "total_reward": 378.54785478546404,
      "episode_length": 1000,
      "avg_reward_per_step": 0.37854785478546404,
      "max_reward_step": 6.500660066006601,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.08171118050813675,
      "steering_std": 1.1579570770263672,
      "throttle_mean": 0.7959657311439514,
      "brake_mean": -0.4745873510837555
    },
    {
      "episode_num": 2,
      "total_reward": 75.62724014337422,
      "episode_length": 1000,
      "avg_reward_per_step": 0.07562724014337423,
      "max_reward_step": 7.068458781362008,
      "min_reward_step": -0.10000000000000142,
      "steering_mean": -0.057458069175481796,
      "steering_std": 0.9256543517112732,
      "throttle_mean": 0.9392896294593811,
      "brake_mean": -0.3147428035736084
    },
    {
      "episode_num": 3,
      "total_reward": 320.8633093525004,
      "episode_length": 1000,
      "avg_reward_per_step": 0.3208633093525004,
      "max_reward_step": 7.094244604316547,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": 0.08126319944858551,
      "steering_std": 1.0375057458877563,
      "throttle_mean": 0.9411961436271667,
      "brake_mean": -0.49678704142570496
    },
    {
      "episode_num": 4,
      "total_reward": 222.14765100671607,
      "episode_length": 1000,
      "avg_reward_per_step": 0.22214765100671607,
      "max_reward_step": 6.611409395973155,
      "min_reward_step": -0.10000000000000142,
      "steering_mean": -0.05671228840947151,
      "steering_std": 1.2680797576904297,
      "throttle_mean": 0.8660178184509277,
      "brake_mean": -0.5069699883460999
    },
    {
      "episode_num": 5,
      "total_reward": 114.28571428571962,
      "episode_length": 1000,
      "avg_reward_per_step": 0.11428571428571963,
      "max_reward_step": 7.042857142857144,
      "min_reward_step": -0.10000000000000142,
      "steering_mean": -0.03324947878718376,
      "steering_std": 1.0751523971557617,
      "throttle_mean": 0.8839494585990906,
      "brake_mean": -0.5156369805335999
    },
    {
      "episode_num": 6,
      "total_reward": 654.0983606557173,
      "episode_length": 1000,
      "avg_reward_per_step": 0.6540983606557174,
      "max_reward_step": 8.09672131147541,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": 0.16251352429389954,
      "steering_std": 1.2398877143859863,
      "throttle_mean": 0.80322265625,
      "brake_mean": -0.6266754269599915
    },
    {
      "episode_num": 7,
      "total_reward": 193.25513196481256,
      "episode_length": 1000,
      "avg_reward_per_step": 0.19325513196481256,
      "max_reward_step": 5.765102639296188,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": 0.08681782335042953,
      "steering_std": 0.8914456367492676,
      "throttle_mean": 0.4521939158439636,
      "brake_mean": 0.004088958725333214
    },
    {
      "episode_num": 8,
      "total_reward": 329.6028880866252,
      "episode_length": 1000,
      "avg_reward_per_step": 0.32960288808662525,
      "max_reward_step": 7.120216606498195,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.4770601689815521,
      "steering_std": 1.3512499332427979,
      "throttle_mean": 0.9141655564308167,
      "brake_mean": -0.5890693068504333
    },
    {
      "episode_num": 9,
      "total_reward": 309.8360655737539,
      "episode_length": 1000,
      "avg_reward_per_step": 0.30983606557375387,
      "max_reward_step": 6.457377049180328,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.44170644879341125,
      "steering_std": 0.9899044036865234,
      "throttle_mean": 0.8380428552627563,
      "brake_mean": -0.48129865527153015
    },
    {
      "episode_num": 10,
      "total_reward": 215.41218637992267,
      "episode_length": 1000,
      "avg_reward_per_step": 0.21541218637992268,
      "max_reward_step": 7.068458781362008,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": 0.18154363334178925,
      "steering_std": 0.7702077627182007,
      "throttle_mean": 0.7715486884117126,
      "brake_mean": -0.34290605783462524
    },
    {
      "episode_num": 11,
      "total_reward": 175.86206896552258,
      "episode_length": 1000,
      "avg_reward_per_step": 0.1758620689655226,
      "max_reward_step": 5.647126436781609,
      "min_reward_step": -0.10000000000000142,
      "steering_mean": -0.4050807058811188,
      "steering_std": 1.2446081638336182,
      "throttle_mean": 0.9202333688735962,
      "brake_mean": -0.6335629224777222
    },
    {
      "episode_num": 12,
      "total_reward": 834.5454545454356,
      "episode_length": 1000,
      "avg_reward_per_step": 0.8345454545454356,
      "max_reward_step": 7.172727272727273,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.037305451929569244,
      "steering_std": 0.9743120670318604,
      "throttle_mean": 0.8429518938064575,
      "brake_mean": -0.6324900984764099
    },
    {
      "episode_num": 13,
      "total_reward": 50.159744408949884,
      "episode_length": 1000,
      "avg_reward_per_step": 0.05015974440894989,
      "max_reward_step": 6.289776357827477,
      "min_reward_step": -0.10000000000000142,
      "steering_mean": 0.028489386662840843,
      "steering_std": 0.7815922498703003,
      "throttle_mean": 0.8679645657539368,
      "brake_mean": -0.3154542148113251
    },
    {
      "episode_num": 14,
      "total_reward": 368.3098591549135,
      "episode_length": 1000,
      "avg_reward_per_step": 0.3683098591549135,
      "max_reward_step": 6.942253521126761,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": 0.058080848306417465,
      "steering_std": 0.8747466206550598,
      "throttle_mean": 0.7770156264305115,
      "brake_mean": -0.5183507800102234
    },
    {
      "episode_num": 15,
      "total_reward": 380.8362369337808,
      "episode_length": 1000,
      "avg_reward_per_step": 0.3808362369337808,
      "max_reward_step": 6.868641114982578,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.15533596277236938,
      "steering_std": 1.065781593322754,
      "throttle_mean": 0.5964145064353943,
      "brake_mean": -0.5745000243186951
    },
    {
      "episode_num": 16,
      "total_reward": 249.83498349833485,
      "episode_length": 1000,
      "avg_reward_per_step": 0.24983498349833486,
      "max_reward_step": 6.500660066006617,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": 0.2687359154224396,
      "steering_std": 0.7945256233215332,
      "throttle_mean": 0.7766098380088806,
      "brake_mean": -0.4006171226501465
    },
    {
      "episode_num": 17,
      "total_reward": -16.281818181813264,
      "episode_length": 982,
      "avg_reward_per_step": -0.016580262914270127,
      "max_reward_step": 7.805138339920949,
      "min_reward_step": -100.0,
      "steering_mean": 0.2803822457790375,
      "steering_std": 1.107183575630188,
      "throttle_mean": 1.042502999305725,
      "brake_mean": -0.495096355676651
    },
    {
      "episode_num": 18,
      "total_reward": 364.64646464644755,
      "episode_length": 1000,
      "avg_reward_per_step": 0.36464646464644757,
      "max_reward_step": 6.634006734006735,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": 0.28960758447647095,
      "steering_std": 0.9434517621994019,
      "throttle_mean": 0.8288444876670837,
      "brake_mean": -0.44168591499328613
    },
    {
      "episode_num": 19,
      "total_reward": 292.0265780730819,
      "episode_length": 1000,
      "avg_reward_per_step": 0.2920265780730819,
      "max_reward_step": 6.5445182724252495,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": 0.17121939361095428,
      "steering_std": 1.0539324283599854,
      "throttle_mean": 0.8901664018630981,
      "brake_mean": -0.49901488423347473
    },
    {
      "episode_num": 20,
      "total_reward": 474.0740740740561,
      "episode_length": 1000,
      "avg_reward_per_step": 0.4740740740740561,
      "max_reward_step": 7.307407407407408,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": 0.01217254064977169,
      "steering_std": 1.1403366327285767,
      "throttle_mean": 0.9116864204406738,
      "brake_mean": -0.5523462891578674
    },
    {
      "episode_num": 21,
      "total_reward": 415.57093425604,
      "episode_length": 1000,
      "avg_reward_per_step": 0.41557093425604,
      "max_reward_step": 6.820415224913518,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.12283666431903839,
      "steering_std": 1.2103992700576782,
      "throttle_mean": 0.9009308815002441,
      "brake_mean": -0.5532029867172241
    },
    {
      "episode_num": 22,
      "total_reward": 726.6253869968907,
      "episode_length": 1000,
      "avg_reward_per_step": 0.7266253869968907,
      "max_reward_step": 6.091950464396286,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.20768389105796814,
      "steering_std": 1.3385056257247925,
      "throttle_mean": 0.9639660120010376,
      "brake_mean": -0.6832950115203857
    },
    {
      "episode_num": 23,
      "total_reward": 325.46583850930256,
      "episode_length": 1000,
      "avg_reward_per_step": 0.32546583850930255,
      "max_reward_step": 6.111180124223603,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": 0.06059134006500244,
      "steering_std": 0.9942597150802612,
      "throttle_mean": 0.8515594601631165,
      "brake_mean": -0.4711992144584656
    },
    {
      "episode_num": 24,
      "total_reward": 67.96875000000512,
      "episode_length": 1000,
      "avg_reward_per_step": 0.06796875000000512,
      "max_reward_step": 7.7125,
      "min_reward_step": -0.10000000000000142,
      "steering_mean": -0.47243213653564453,
      "steering_std": 0.837716817855835,
      "throttle_mean": 0.7757745385169983,
      "brake_mean": -0.5067626237869263
    },
    {
      "episode_num": 25,
      "total_reward": 285.2459016393292,
      "episode_length": 1000,
      "avg_reward_per_step": 0.28524590163932917,
      "max_reward_step": 5.36448087431694,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": 0.0943884402513504,
      "steering_std": 1.0687589645385742,
      "throttle_mean": 0.9320243000984192,
      "brake_mean": -0.5986828804016113
    },
    {
      "episode_num": 26,
      "total_reward": 252.73972602738118,
      "episode_length": 1000,
      "avg_reward_per_step": 0.2527397260273812,
      "max_reward_step": 6.749315068493151,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": 0.12968072295188904,
      "steering_std": 0.7909881472587585,
      "throttle_mean": 0.6718236804008484,
      "brake_mean": -0.26343879103660583
    },
    {
      "episode_num": 27,
      "total_reward": 332.1428571428398,
      "episode_length": 1000,
      "avg_reward_per_step": 0.33214285714283975,
      "max_reward_step": 7.042857142857144,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -1.5798753499984741,
      "steering_std": 1.3259713649749756,
      "throttle_mean": 0.10498138517141342,
      "brake_mean": 0.0258103646337986
    },
    {
      "episode_num": 28,
      "total_reward": 339.8496240601324,
      "episode_length": 1000,
      "avg_reward_per_step": 0.33984962406013236,
      "max_reward_step": 7.418796992481203,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": 0.12978412210941315,
      "steering_std": 0.8128835558891296,
      "throttle_mean": 0.9252097010612488,
      "brake_mean": -0.42314550280570984
    },
    {
      "episode_num": 29,
      "total_reward": 385.61151079134913,
      "episode_length": 1000,
      "avg_reward_per_step": 0.38561151079134914,
      "max_reward_step": 7.094244604316547,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.46464797854423523,
      "steering_std": 0.7992838025093079,
      "throttle_mean": 0.9253965020179749,
      "brake_mean": -0.5541530847549438
    }
  ]
}