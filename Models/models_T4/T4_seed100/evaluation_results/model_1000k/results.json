{
  "model": "model_1000k",
  "evaluation_date": "2026-01-12T19:41:33.034745",
  "num_episodes": 30,
  "seed": 100,
  "device": "cuda",
  "statistics": {
    "mean_reward": 298.02110920682725,
    "std_reward": 192.3826615742672,
    "min_reward": -11.97183098591531,
    "max_reward": 737.0370370370181,
    "median_reward": 303.4637476212811,
    "mean_length": 978.5,
    "std_length": 115.78104335339184,
    "win_rate": 0.0,
    "success_rate": 96.66666666666667,
    "steering_mean": -0.07740270652187367,
    "throttle_mean": 0.5235601435105006,
    "brake_mean": -0.3455466564744711
  },
  "episodes": [
    {
      "episode_num": 0,
      "total_reward": 70.37037037037555,
      "episode_length": 1000,
      "avg_reward_per_step": 0.07037037037037555,
      "max_reward_step": 11.011111111111134,
      "min_reward_step": -0.10000000000000142,
      "steering_mean": -0.41384056210517883,
      "steering_std": 1.0428202152252197,
      "throttle_mean": 0.6311720013618469,
      "brake_mean": -0.47277796268463135
    },
    {
      "episode_num": 1,
      "total_reward": 464.35643564354865,
      "episode_length": 1000,
      "avg_reward_per_step": 0.46435643564354867,
      "max_reward_step": 9.800990099009937,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.1595400720834732,
      "steering_std": 0.9184232354164124,
      "throttle_mean": 0.5561404824256897,
      "brake_mean": -0.47782018780708313
    },
    {
      "episode_num": 2,
      "total_reward": 118.63799283154631,
      "episode_length": 1000,
      "avg_reward_per_step": 0.11863799283154632,
      "max_reward_step": 7.068458781362011,
      "min_reward_step": -0.10000000000000142,
      "steering_mean": -0.10314799845218658,
      "steering_std": 0.6267431974411011,
      "throttle_mean": -0.14260300993919373,
      "brake_mean": 0.3066696226596832
    },
    {
      "episode_num": 3,
      "total_reward": 328.0575539568168,
      "episode_length": 1000,
      "avg_reward_per_step": 0.3280575539568168,
      "max_reward_step": 7.094244604316547,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": 0.007768318057060242,
      "steering_std": 0.8146898150444031,
      "throttle_mean": 0.5774029493331909,
      "brake_mean": -0.3943493366241455
    },
    {
      "episode_num": 4,
      "total_reward": 64.42953020134588,
      "episode_length": 1000,
      "avg_reward_per_step": 0.06442953020134588,
      "max_reward_step": 9.96711409395975,
      "min_reward_step": -0.10000000000000142,
      "steering_mean": 0.12445484101772308,
      "steering_std": 0.6743684411048889,
      "throttle_mean": 0.49283158779144287,
      "brake_mean": -0.3200279474258423
    },
    {
      "episode_num": 5,
      "total_reward": 0.3142857142870952,
      "episode_length": 355,
      "avg_reward_per_step": 0.000885311871231254,
      "max_reward_step": 7.0428571428571445,
      "min_reward_step": -100.0,
      "steering_mean": -0.2621055841445923,
      "steering_std": 1.0379846096038818,
      "throttle_mean": 0.5144780278205872,
      "brake_mean": -0.4832737147808075
    },
    {
      "episode_num": 6,
      "total_reward": 609.0163934426027,
      "episode_length": 1000,
      "avg_reward_per_step": 0.6090163934426027,
      "max_reward_step": 8.09672131147541,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": 0.008308563381433487,
      "steering_std": 0.8404219746589661,
      "throttle_mean": 0.5566210150718689,
      "brake_mean": -0.3256126046180725
    },
    {
      "episode_num": 7,
      "total_reward": 451.31964809382566,
      "episode_length": 1000,
      "avg_reward_per_step": 0.4513196480938257,
      "max_reward_step": 5.765102639296188,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": 0.027484416961669922,
      "steering_std": 0.9134141802787781,
      "throttle_mean": 0.6071407198905945,
      "brake_mean": -0.47860562801361084
    },
    {
      "episode_num": 8,
      "total_reward": 347.6534296028703,
      "episode_length": 1000,
      "avg_reward_per_step": 0.34765342960287027,
      "max_reward_step": 7.120216606498195,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.13722427189350128,
      "steering_std": 0.803922712802887,
      "throttle_mean": -0.20418627560138702,
      "brake_mean": -0.06235517933964729
    },
    {
      "episode_num": 9,
      "total_reward": 332.7868852458849,
      "episode_length": 1000,
      "avg_reward_per_step": 0.3327868852458849,
      "max_reward_step": 6.45737704918033,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": 0.14047515392303467,
      "steering_std": 0.7314478158950806,
      "throttle_mean": 0.5272753238677979,
      "brake_mean": -0.3371585011482239
    },
    {
      "episode_num": 10,
      "total_reward": 308.6021505376172,
      "episode_length": 1000,
      "avg_reward_per_step": 0.3086021505376172,
      "max_reward_step": 7.068458781362008,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.16208024322986603,
      "steering_std": 0.8559123873710632,
      "throttle_mean": 0.6671122908592224,
      "brake_mean": -0.3893616795539856
    },
    {
      "episode_num": 11,
      "total_reward": 207.47126436781875,
      "episode_length": 1000,
      "avg_reward_per_step": 0.20747126436781874,
      "max_reward_step": 5.647126436781609,
      "min_reward_step": -0.10000000000000142,
      "steering_mean": 0.11538051813840866,
      "steering_std": 0.7569481730461121,
      "throttle_mean": 0.6522297263145447,
      "brake_mean": -0.3156982660293579
    },
    {
      "episode_num": 12,
      "total_reward": 354.5454545454364,
      "episode_length": 1000,
      "avg_reward_per_step": 0.3545454545454364,
      "max_reward_step": 7.172727272727273,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": 0.08668225258588791,
      "steering_std": 0.69098299741745,
      "throttle_mean": 0.6343954801559448,
      "brake_mean": -0.2897721827030182
    },
    {
      "episode_num": 13,
      "total_reward": 302.5559105431217,
      "episode_length": 1000,
      "avg_reward_per_step": 0.3025559105431217,
      "max_reward_step": 6.289776357827477,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.08224142342805862,
      "steering_std": 0.7455698251724243,
      "throttle_mean": 0.5478367209434509,
      "brake_mean": -0.412382572889328
    },
    {
      "episode_num": 14,
      "total_reward": -11.97183098591531,
      "episode_length": 1000,
      "avg_reward_per_step": -0.011971830985915309,
      "max_reward_step": 6.942253521126761,
      "min_reward_step": -0.10000000000000142,
      "steering_mean": -0.16337506473064423,
      "steering_std": 0.6490783095359802,
      "throttle_mean": 0.5318669080734253,
      "brake_mean": -0.3427784740924835
    },
    {
      "episode_num": 15,
      "total_reward": 286.7595818815157,
      "episode_length": 1000,
      "avg_reward_per_step": 0.28675958188151573,
      "max_reward_step": 6.868641114982578,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": 0.07013409584760666,
      "steering_std": 0.7220063209533691,
      "throttle_mean": 0.5668891668319702,
      "brake_mean": -0.3025132119655609
    },
    {
      "episode_num": 16,
      "total_reward": 25.41254125412476,
      "episode_length": 1000,
      "avg_reward_per_step": 0.02541254125412476,
      "max_reward_step": 6.500660066006601,
      "min_reward_step": -0.10000000000000142,
      "steering_mean": 0.07778435200452805,
      "steering_std": 0.800166130065918,
      "throttle_mean": 0.5173423886299133,
      "brake_mean": -0.45249083638191223
    },
    {
      "episode_num": 17,
      "total_reward": 66.00790513834491,
      "episode_length": 1000,
      "avg_reward_per_step": 0.06600790513834491,
      "max_reward_step": 7.805138339920949,
      "min_reward_step": -0.10000000000000142,
      "steering_mean": -0.7036645412445068,
      "steering_std": 0.602899968624115,
      "throttle_mean": -0.24420969188213348,
      "brake_mean": 0.2056744396686554
    },
    {
      "episode_num": 18,
      "total_reward": 526.2626262626078,
      "episode_length": 1000,
      "avg_reward_per_step": 0.5262626262626078,
      "max_reward_step": 6.634006734006735,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": 0.02599826082587242,
      "steering_std": 0.8633862733840942,
      "throttle_mean": 0.6960635185241699,
      "brake_mean": -0.4320571720600128
    },
    {
      "episode_num": 19,
      "total_reward": 401.6611295680911,
      "episode_length": 1000,
      "avg_reward_per_step": 0.4016611295680911,
      "max_reward_step": 6.5445182724252495,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.046295810490846634,
      "steering_std": 0.8722164034843445,
      "throttle_mean": 0.6687282919883728,
      "brake_mean": -0.41863781213760376
    },
    {
      "episode_num": 20,
      "total_reward": 737.0370370370181,
      "episode_length": 1000,
      "avg_reward_per_step": 0.7370370370370181,
      "max_reward_step": 7.307407407407408,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.11925238370895386,
      "steering_std": 0.9205678701400757,
      "throttle_mean": 0.628052830696106,
      "brake_mean": -0.4684431850910187
    },
    {
      "episode_num": 21,
      "total_reward": 280.62283737022534,
      "episode_length": 1000,
      "avg_reward_per_step": 0.28062283737022536,
      "max_reward_step": 6.8204152249134955,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.007787405047565699,
      "steering_std": 0.8864811062812805,
      "throttle_mean": 0.5345911979675293,
      "brake_mean": -0.4034518599510193
    },
    {
      "episode_num": 22,
      "total_reward": 290.09287925695617,
      "episode_length": 1000,
      "avg_reward_per_step": 0.29009287925695615,
      "max_reward_step": 6.091950464396291,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.10954685509204865,
      "steering_std": 0.9478818774223328,
      "throttle_mean": 0.6365479826927185,
      "brake_mean": -0.4368375241756439
    },
    {
      "episode_num": 23,
      "total_reward": 173.2919254658433,
      "episode_length": 1000,
      "avg_reward_per_step": 0.1732919254658433,
      "max_reward_step": 6.111180124223603,
      "min_reward_step": -0.10000000000000142,
      "steering_mean": -0.15717504918575287,
      "steering_std": 0.9232835173606873,
      "throttle_mean": 0.601369321346283,
      "brake_mean": -0.43362292647361755
    },
    {
      "episode_num": 24,
      "total_reward": 153.90625000000514,
      "episode_length": 1000,
      "avg_reward_per_step": 0.15390625000000516,
      "max_reward_step": 7.712500000000006,
      "min_reward_step": -0.10000000000000142,
      "steering_mean": -0.18664652109146118,
      "steering_std": 1.009200096130371,
      "throttle_mean": 0.7337201833724976,
      "brake_mean": -0.5210742354393005
    },
    {
      "episode_num": 25,
      "total_reward": 304.3715846994405,
      "episode_length": 1000,
      "avg_reward_per_step": 0.30437158469944053,
      "max_reward_step": 8.096721311475449,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.17197385430335999,
      "steering_std": 1.112945556640625,
      "throttle_mean": 0.7952765822410583,
      "brake_mean": -0.4535241723060608
    },
    {
      "episode_num": 26,
      "total_reward": 245.89041095889002,
      "episode_length": 1000,
      "avg_reward_per_step": 0.24589041095889003,
      "max_reward_step": 6.749315068493151,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": 0.07708018273115158,
      "steering_std": 0.8111262917518616,
      "throttle_mean": 0.7223737239837646,
      "brake_mean": -0.2839672565460205
    },
    {
      "episode_num": 27,
      "total_reward": 721.428571428552,
      "episode_length": 1000,
      "avg_reward_per_step": 0.721428571428552,
      "max_reward_step": 7.042857142857144,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.12415864318609238,
      "steering_std": 0.9440140128135681,
      "throttle_mean": 0.5440351963043213,
      "brake_mean": -0.5450856685638428
    },
    {
      "episode_num": 28,
      "total_reward": 347.3684210526134,
      "episode_length": 1000,
      "avg_reward_per_step": 0.34736842105261345,
      "max_reward_step": 7.418796992481212,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.034448929131031036,
      "steering_std": 0.7474504113197327,
      "throttle_mean": 0.5718104243278503,
      "brake_mean": -0.31445401906967163
    },
    {
      "episode_num": 29,
      "total_reward": 432.374100719406,
      "episode_length": 1000,
      "avg_reward_per_step": 0.43237410071940596,
      "max_reward_step": 10.691366906474833,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": 0.060873061418533325,
      "steering_std": 0.6904059648513794,
      "throttle_mean": 0.5844992399215698,
      "brake_mean": -0.3106096386909485
    }
  ]
}