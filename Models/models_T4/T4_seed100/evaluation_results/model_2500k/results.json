{
  "model": "model_2500k",
  "evaluation_date": "2026-01-12T20:01:59.481949",
  "num_episodes": 30,
  "seed": 100,
  "device": "cuda",
  "statistics": {
    "mean_reward": 820.8885225964498,
    "std_reward": 181.94322960400416,
    "min_reward": 115.9468438538259,
    "max_reward": 936.5999999999912,
    "median_reward": 887.1924434742584,
    "mean_length": 909.1666666666666,
    "std_length": 136.26764921367882,
    "win_rate": 36.666666666666664,
    "success_rate": 100.0,
    "steering_mean": -0.0734535373436908,
    "throttle_mean": 0.4170958658059438,
    "brake_mean": -0.5245908752083779
  },
  "episodes": [
    {
      "episode_num": 0,
      "total_reward": 924.8999999999871,
      "episode_length": 751,
      "avg_reward_per_step": 1.2315579227696234,
      "max_reward_step": 7.307407407407425,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.06885579228401184,
      "steering_std": 1.0975160598754883,
      "throttle_mean": 0.4219486713409424,
      "brake_mean": -0.5824519395828247
    },
    {
      "episode_num": 1,
      "total_reward": 480.8580858085658,
      "episode_length": 1000,
      "avg_reward_per_step": 0.4808580858085658,
      "max_reward_step": 6.500660066006617,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.07089398801326752,
      "steering_std": 0.9693918824195862,
      "throttle_mean": 0.4177078902721405,
      "brake_mean": -0.5341299772262573
    },
    {
      "episode_num": 2,
      "total_reward": 885.6630824372598,
      "episode_length": 1000,
      "avg_reward_per_step": 0.8856630824372599,
      "max_reward_step": 7.068458781362008,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.11722804605960846,
      "steering_std": 0.9678277969360352,
      "throttle_mean": 0.38913771510124207,
      "brake_mean": -0.4955890476703644
    },
    {
      "episode_num": 3,
      "total_reward": 892.8057553956627,
      "episode_length": 1000,
      "avg_reward_per_step": 0.8928057553956626,
      "max_reward_step": 7.094244604316547,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.05420291796326637,
      "steering_std": 0.9566440582275391,
      "throttle_mean": 0.2595779299736023,
      "brake_mean": -0.5405323505401611
    },
    {
      "episode_num": 4,
      "total_reward": 866.4429530201149,
      "episode_length": 1000,
      "avg_reward_per_step": 0.866442953020115,
      "max_reward_step": 6.611409395973169,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.04762735590338707,
      "steering_std": 0.9787738919258118,
      "throttle_mean": 0.5486981868743896,
      "brake_mean": -0.49727946519851685
    },
    {
      "episode_num": 5,
      "total_reward": 915.9999999999853,
      "episode_length": 840,
      "avg_reward_per_step": 1.090476190476173,
      "max_reward_step": 7.042857142857144,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.09139985591173172,
      "steering_std": 0.9497772455215454,
      "throttle_mean": 0.39268985390663147,
      "brake_mean": -0.49260085821151733
    },
    {
      "episode_num": 6,
      "total_reward": 904.4999999999789,
      "episode_length": 955,
      "avg_reward_per_step": 0.9471204188481454,
      "max_reward_step": 8.09672131147542,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.09088921546936035,
      "steering_std": 0.9175043106079102,
      "throttle_mean": 0.26251718401908875,
      "brake_mean": -0.5224115252494812
    },
    {
      "episode_num": 7,
      "total_reward": 639.0029325513008,
      "episode_length": 1000,
      "avg_reward_per_step": 0.6390029325513008,
      "max_reward_step": 5.765102639296188,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.08403051644563675,
      "steering_std": 1.0537837743759155,
      "throttle_mean": 0.4952419400215149,
      "brake_mean": -0.5712296962738037
    },
    {
      "episode_num": 8,
      "total_reward": 908.4999999999908,
      "episode_length": 915,
      "avg_reward_per_step": 0.9928961748633779,
      "max_reward_step": 7.120216606498275,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.07638067752122879,
      "steering_std": 0.9988589286804199,
      "throttle_mean": 0.3447851836681366,
      "brake_mean": -0.4919603765010834
    },
    {
      "episode_num": 9,
      "total_reward": 883.606557377033,
      "episode_length": 1000,
      "avg_reward_per_step": 0.883606557377033,
      "max_reward_step": 6.457377049180328,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.08607364445924759,
      "steering_std": 0.9271793961524963,
      "throttle_mean": 0.4209468960762024,
      "brake_mean": -0.5277006030082703
    },
    {
      "episode_num": 10,
      "total_reward": 889.2473118279396,
      "episode_length": 1000,
      "avg_reward_per_step": 0.8892473118279396,
      "max_reward_step": 7.068458781362008,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.05956883355975151,
      "steering_std": 0.9144719243049622,
      "throttle_mean": 0.5145646929740906,
      "brake_mean": -0.4750038981437683
    },
    {
      "episode_num": 11,
      "total_reward": 825.2873563218255,
      "episode_length": 1000,
      "avg_reward_per_step": 0.8252873563218256,
      "max_reward_step": 5.647126436781612,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.05598143860697746,
      "steering_std": 1.032981276512146,
      "throttle_mean": 0.4982319176197052,
      "brake_mean": -0.5516821146011353
    },
    {
      "episode_num": 12,
      "total_reward": 934.4999999999884,
      "episode_length": 655,
      "avg_reward_per_step": 1.4267175572518906,
      "max_reward_step": 7.172727272727273,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.029795195907354355,
      "steering_std": 1.0365592241287231,
      "throttle_mean": 0.4080684185028076,
      "brake_mean": -0.5621458888053894
    },
    {
      "episode_num": 13,
      "total_reward": 593.2907348242737,
      "episode_length": 1000,
      "avg_reward_per_step": 0.5932907348242737,
      "max_reward_step": 6.289776357827477,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.014333558268845081,
      "steering_std": 0.8524816036224365,
      "throttle_mean": 0.438917338848114,
      "brake_mean": -0.5490188002586365
    },
    {
      "episode_num": 14,
      "total_reward": 930.8999999999852,
      "episode_length": 691,
      "avg_reward_per_step": 1.3471780028943345,
      "max_reward_step": 6.942253521126761,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.09070596098899841,
      "steering_std": 1.0572562217712402,
      "throttle_mean": 0.4239533841609955,
      "brake_mean": -0.6117603182792664
    },
    {
      "episode_num": 15,
      "total_reward": 931.9999999999898,
      "episode_length": 680,
      "avg_reward_per_step": 1.3705882352941026,
      "max_reward_step": 6.868641114982578,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.07014578580856323,
      "steering_std": 0.9954566955566406,
      "throttle_mean": 0.5697576403617859,
      "brake_mean": -0.5341725945472717
    },
    {
      "episode_num": 16,
      "total_reward": 866.9966996699541,
      "episode_length": 1000,
      "avg_reward_per_step": 0.8669966996699541,
      "max_reward_step": 6.500660066006617,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.028959019109606743,
      "steering_std": 1.0148457288742065,
      "throttle_mean": 0.5314347147941589,
      "brake_mean": -0.5256167054176331
    },
    {
      "episode_num": 17,
      "total_reward": 876.2845849802244,
      "episode_length": 1000,
      "avg_reward_per_step": 0.8762845849802244,
      "max_reward_step": 7.805138339920949,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.10218150913715363,
      "steering_std": 0.9756985902786255,
      "throttle_mean": 0.40067562460899353,
      "brake_mean": -0.4920966923236847
    },
    {
      "episode_num": 18,
      "total_reward": 829.2929292929095,
      "episode_length": 1000,
      "avg_reward_per_step": 0.8292929292929095,
      "max_reward_step": 6.634006734006735,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.055348191410303116,
      "steering_std": 0.9709003567695618,
      "throttle_mean": 0.45931658148765564,
      "brake_mean": -0.5995447039604187
    },
    {
      "episode_num": 19,
      "total_reward": 115.9468438538259,
      "episode_length": 1000,
      "avg_reward_per_step": 0.11594684385382589,
      "max_reward_step": 6.544518272425279,
      "min_reward_step": -0.10000000000000142,
      "steering_mean": -0.11873400211334229,
      "steering_std": 0.6394951343536377,
      "throttle_mean": -0.1376434564590454,
      "brake_mean": -0.1883959323167801
    },
    {
      "episode_num": 20,
      "total_reward": 818.5185185184997,
      "episode_length": 1000,
      "avg_reward_per_step": 0.8185185185184998,
      "max_reward_step": 7.307407407407408,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.12105978280305862,
      "steering_std": 0.9913097023963928,
      "throttle_mean": 0.3818148672580719,
      "brake_mean": -0.47817355394363403
    },
    {
      "episode_num": 21,
      "total_reward": 879.2387543252469,
      "episode_length": 1000,
      "avg_reward_per_step": 0.8792387543252469,
      "max_reward_step": 6.820415224913518,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.03675007447600365,
      "steering_std": 0.9377116560935974,
      "throttle_mean": 0.5453073382377625,
      "brake_mean": -0.5000081658363342
    },
    {
      "episode_num": 22,
      "total_reward": 917.2999999999914,
      "episode_length": 827,
      "avg_reward_per_step": 1.10918984280531,
      "max_reward_step": 6.091950464396291,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.09081312268972397,
      "steering_std": 1.2466974258422852,
      "throttle_mean": 0.5460237264633179,
      "brake_mean": -0.5528711080551147
    },
    {
      "episode_num": 23,
      "total_reward": 875.1552795030863,
      "episode_length": 1000,
      "avg_reward_per_step": 0.8751552795030862,
      "max_reward_step": 6.111180124223603,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.12955158948898315,
      "steering_std": 1.093870997428894,
      "throttle_mean": 0.5090681314468384,
      "brake_mean": -0.480071485042572
    },
    {
      "episode_num": 24,
      "total_reward": 936.5999999999912,
      "episode_length": 634,
      "avg_reward_per_step": 1.477287066246043,
      "max_reward_step": 7.7125,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.08728279173374176,
      "steering_std": 1.0614913702011108,
      "throttle_mean": 0.4790808856487274,
      "brake_mean": -0.5742019414901733
    },
    {
      "episode_num": 25,
      "total_reward": 454.6448087431659,
      "episode_length": 1000,
      "avg_reward_per_step": 0.45464480874316593,
      "max_reward_step": 5.36448087431694,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.07089120149612427,
      "steering_std": 0.9374868869781494,
      "throttle_mean": 0.38901984691619873,
      "brake_mean": -0.5811619758605957
    },
    {
      "episode_num": 26,
      "total_reward": 893.1506849314853,
      "episode_length": 1000,
      "avg_reward_per_step": 0.8931506849314853,
      "max_reward_step": 6.749315068493151,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.051896851509809494,
      "steering_std": 0.95493483543396,
      "throttle_mean": 0.4363979399204254,
      "brake_mean": -0.5423027276992798
    },
    {
      "episode_num": 27,
      "total_reward": 932.0999999999873,
      "episode_length": 679,
      "avg_reward_per_step": 1.372754050073619,
      "max_reward_step": 7.042857142857144,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.04694533720612526,
      "steering_std": 1.1214900016784668,
      "throttle_mean": 0.4415684938430786,
      "brake_mean": -0.604745626449585
    },
    {
      "episode_num": 28,
      "total_reward": 888.721804511257,
      "episode_length": 1000,
      "avg_reward_per_step": 0.888721804511257,
      "max_reward_step": 7.418796992481212,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.10672178864479065,
      "steering_std": 0.9242744445800781,
      "throttle_mean": 0.2765689194202423,
      "brake_mean": -0.5139906406402588
    },
    {
      "episode_num": 29,
      "total_reward": 935.1999999999873,
      "episode_length": 648,
      "avg_reward_per_step": 1.4432098765431902,
      "max_reward_step": 7.09424460431655,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.04835807532072067,
      "steering_std": 1.0489501953125,
      "throttle_mean": 0.44749751687049866,
      "brake_mean": -0.5648755431175232
    }
  ]
}