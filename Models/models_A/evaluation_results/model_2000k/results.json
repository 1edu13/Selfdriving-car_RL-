{
  "model": "model_2000k",
  "evaluation_date": "2026-01-12T19:55:08.987409",
  "num_episodes": 30,
  "seed": 100,
  "device": "cuda",
  "statistics": {
    "mean_reward": 775.0579717199505,
    "std_reward": 231.95901415902256,
    "min_reward": 129.39068100358932,
    "max_reward": 933.9999999999872,
    "median_reward": 888.0069004631612,
    "mean_length": 881.6,
    "std_length": 140.35683097020964,
    "win_rate": 46.666666666666664,
    "success_rate": 100.0,
    "steering_mean": -0.061426678532734515,
    "throttle_mean": 0.47811982929706576,
    "brake_mean": -0.5458815862735112
  },
  "episodes": [
    {
      "episode_num": 0,
      "total_reward": 932.4999999999889,
      "episode_length": 675,
      "avg_reward_per_step": 1.3814814814814649,
      "max_reward_step": 7.307407407407408,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.14043615758419037,
      "steering_std": 0.9994242787361145,
      "throttle_mean": 0.3970057964324951,
      "brake_mean": -0.5677796602249146
    },
    {
      "episode_num": 1,
      "total_reward": 418.1518151815025,
      "episode_length": 1000,
      "avg_reward_per_step": 0.4181518151815025,
      "max_reward_step": 6.500660066006601,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.00416817469522357,
      "steering_std": 0.9009953141212463,
      "throttle_mean": 0.4218188226222992,
      "brake_mean": -0.5469882488250732
    },
    {
      "episode_num": 2,
      "total_reward": 129.39068100358932,
      "episode_length": 1000,
      "avg_reward_per_step": 0.12939068100358933,
      "max_reward_step": 7.068458781362008,
      "min_reward_step": -0.10000000000000142,
      "steering_mean": 0.02840580604970455,
      "steering_std": 0.8987295031547546,
      "throttle_mean": 0.5243129730224609,
      "brake_mean": -0.6223078966140747
    },
    {
      "episode_num": 3,
      "total_reward": 932.9999999999869,
      "episode_length": 670,
      "avg_reward_per_step": 1.3925373134328163,
      "max_reward_step": 7.094244604316547,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.0862898901104927,
      "steering_std": 0.9158326387405396,
      "throttle_mean": 0.4329286515712738,
      "brake_mean": -0.5476637482643127
    },
    {
      "episode_num": 4,
      "total_reward": 886.577181208034,
      "episode_length": 1000,
      "avg_reward_per_step": 0.886577181208034,
      "max_reward_step": 6.611409395973169,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.09593775868415833,
      "steering_std": 1.001767873764038,
      "throttle_mean": 0.5577313303947449,
      "brake_mean": -0.49799999594688416
    },
    {
      "episode_num": 5,
      "total_reward": 904.9999999999819,
      "episode_length": 950,
      "avg_reward_per_step": 0.9526315789473494,
      "max_reward_step": 7.042857142857144,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.1505855768918991,
      "steering_std": 0.8602680563926697,
      "throttle_mean": 0.34054452180862427,
      "brake_mean": -0.4946932792663574
    },
    {
      "episode_num": 6,
      "total_reward": 923.9999999999835,
      "episode_length": 760,
      "avg_reward_per_step": 1.2157894736841888,
      "max_reward_step": 8.09672131147541,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.0777282863855362,
      "steering_std": 1.0125821828842163,
      "throttle_mean": 0.5613386631011963,
      "brake_mean": -0.5550153255462646
    },
    {
      "episode_num": 7,
      "total_reward": 653.6656891495412,
      "episode_length": 1000,
      "avg_reward_per_step": 0.6536656891495413,
      "max_reward_step": 5.765102639296188,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": 0.009065595455467701,
      "steering_std": 0.9279117584228516,
      "throttle_mean": 0.3987962007522583,
      "brake_mean": -0.5947243571281433
    },
    {
      "episode_num": 8,
      "total_reward": 930.7999999999957,
      "episode_length": 692,
      "avg_reward_per_step": 1.3450867052023059,
      "max_reward_step": 7.120216606498195,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.11577919125556946,
      "steering_std": 1.0558202266693115,
      "throttle_mean": 0.5015446543693542,
      "brake_mean": -0.5027323365211487
    },
    {
      "episode_num": 9,
      "total_reward": 917.199999999988,
      "episode_length": 828,
      "avg_reward_per_step": 1.1077294685990193,
      "max_reward_step": 6.45737704918033,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.15963245928287506,
      "steering_std": 1.0984911918640137,
      "throttle_mean": 0.6437349915504456,
      "brake_mean": -0.5097963809967041
    },
    {
      "episode_num": 10,
      "total_reward": 931.0999999999898,
      "episode_length": 689,
      "avg_reward_per_step": 1.351378809869361,
      "max_reward_step": 7.068458781362008,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.05819622427225113,
      "steering_std": 0.9431197047233582,
      "throttle_mean": 0.503376305103302,
      "brake_mean": -0.5658633708953857
    },
    {
      "episode_num": 11,
      "total_reward": 256.3218390804446,
      "episode_length": 1000,
      "avg_reward_per_step": 0.2563218390804446,
      "max_reward_step": 5.647126436781612,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": 0.16602739691734314,
      "steering_std": 0.5994596481323242,
      "throttle_mean": 0.5394564270973206,
      "brake_mean": -0.5455416440963745
    },
    {
      "episode_num": 12,
      "total_reward": 929.8999999999876,
      "episode_length": 701,
      "avg_reward_per_step": 1.3265335235377855,
      "max_reward_step": 7.172727272727273,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.08533559739589691,
      "steering_std": 0.8921432495117188,
      "throttle_mean": 0.38724878430366516,
      "brake_mean": -0.5284730792045593
    },
    {
      "episode_num": 13,
      "total_reward": 874.4408945686755,
      "episode_length": 1000,
      "avg_reward_per_step": 0.8744408945686755,
      "max_reward_step": 6.289776357827492,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.10952214151620865,
      "steering_std": 0.981413722038269,
      "throttle_mean": 0.5862913727760315,
      "brake_mean": -0.4581165015697479
    },
    {
      "episode_num": 14,
      "total_reward": 889.4366197182885,
      "episode_length": 1000,
      "avg_reward_per_step": 0.8894366197182885,
      "max_reward_step": 6.942253521126761,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.09407144784927368,
      "steering_std": 0.9247984290122986,
      "throttle_mean": 0.45684361457824707,
      "brake_mean": -0.49150633811950684
    },
    {
      "episode_num": 15,
      "total_reward": 929.8999999999893,
      "episode_length": 701,
      "avg_reward_per_step": 1.3265335235377878,
      "max_reward_step": 6.868641114982578,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.1028185784816742,
      "steering_std": 0.9210360646247864,
      "throttle_mean": 0.5348540544509888,
      "brake_mean": -0.4996558129787445
    },
    {
      "episode_num": 16,
      "total_reward": 718.4818481848047,
      "episode_length": 1000,
      "avg_reward_per_step": 0.7184818481848047,
      "max_reward_step": 6.500660066006601,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.048101652413606644,
      "steering_std": 1.02994704246521,
      "throttle_mean": 0.5241196155548096,
      "brake_mean": -0.5787473320960999
    },
    {
      "episode_num": 17,
      "total_reward": 921.1999999999923,
      "episode_length": 788,
      "avg_reward_per_step": 1.169035532994914,
      "max_reward_step": 7.805138339920973,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.15439549088478088,
      "steering_std": 0.8902250528335571,
      "throttle_mean": 0.38455578684806824,
      "brake_mean": -0.48086726665496826
    },
    {
      "episode_num": 18,
      "total_reward": 738.3838383838191,
      "episode_length": 1000,
      "avg_reward_per_step": 0.7383838383838192,
      "max_reward_step": 6.634006734006735,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.02677883207798004,
      "steering_std": 0.9917935729026794,
      "throttle_mean": 0.4047313332557678,
      "brake_mean": -0.6225473880767822
    },
    {
      "episode_num": 19,
      "total_reward": 850.166112956799,
      "episode_length": 1000,
      "avg_reward_per_step": 0.850166112956799,
      "max_reward_step": 6.544518272425307,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.173577219247818,
      "steering_std": 0.9191926717758179,
      "throttle_mean": 0.44669100642204285,
      "brake_mean": -0.43859151005744934
    },
    {
      "episode_num": 20,
      "total_reward": 855.5555555555368,
      "episode_length": 1000,
      "avg_reward_per_step": 0.8555555555555368,
      "max_reward_step": 7.307407407407408,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.07190988212823868,
      "steering_std": 0.917876124382019,
      "throttle_mean": 0.5289673805236816,
      "brake_mean": -0.519367516040802
    },
    {
      "episode_num": 21,
      "total_reward": 929.0999999999941,
      "episode_length": 709,
      "avg_reward_per_step": 1.31043723554301,
      "max_reward_step": 6.8204152249134955,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.06863462179899216,
      "steering_std": 0.9691332578659058,
      "throttle_mean": 0.45156213641166687,
      "brake_mean": -0.5657990574836731
    },
    {
      "episode_num": 22,
      "total_reward": 237.46130030958716,
      "episode_length": 1000,
      "avg_reward_per_step": 0.23746130030958715,
      "max_reward_step": 6.091950464396286,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": 0.011949779465794563,
      "steering_std": 0.8996196985244751,
      "throttle_mean": 0.44684502482414246,
      "brake_mean": -0.6423105597496033
    },
    {
      "episode_num": 23,
      "total_reward": 440.37267080743584,
      "episode_length": 1000,
      "avg_reward_per_step": 0.44037267080743586,
      "max_reward_step": 6.111180124223603,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": 0.01184238400310278,
      "steering_std": 1.022899866104126,
      "throttle_mean": 0.514936625957489,
      "brake_mean": -0.5951948761940002
    },
    {
      "episode_num": 24,
      "total_reward": 802.3437499999832,
      "episode_length": 1000,
      "avg_reward_per_step": 0.8023437499999831,
      "max_reward_step": 7.7125,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.025762313976883888,
      "steering_std": 0.9178013205528259,
      "throttle_mean": 0.5132883191108704,
      "brake_mean": -0.594100832939148
    },
    {
      "episode_num": 25,
      "total_reward": 686.8852459016218,
      "episode_length": 1000,
      "avg_reward_per_step": 0.6868852459016218,
      "max_reward_step": 8.096721311475335,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": 0.019225848838686943,
      "steering_std": 1.066320776939392,
      "throttle_mean": 0.45230528712272644,
      "brake_mean": -0.6383488178253174
    },
    {
      "episode_num": 26,
      "total_reward": 858.904109589021,
      "episode_length": 1000,
      "avg_reward_per_step": 0.858904109589021,
      "max_reward_step": 6.749315068493161,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.022540856152772903,
      "steering_std": 0.9470284581184387,
      "throttle_mean": 0.5277818441390991,
      "brake_mean": -0.619540274143219
    },
    {
      "episode_num": 27,
      "total_reward": 929.0999999999867,
      "episode_length": 709,
      "avg_reward_per_step": 1.3104372355429996,
      "max_reward_step": 7.042857142857144,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.09188396483659744,
      "steering_std": 1.0811173915863037,
      "throttle_mean": 0.49742287397384644,
      "brake_mean": -0.5309979319572449
    },
    {
      "episode_num": 28,
      "total_reward": 908.3999999999805,
      "episode_length": 916,
      "avg_reward_per_step": 0.9917030567685376,
      "max_reward_step": 7.418796992481203,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.054068103432655334,
      "steering_std": 0.867139995098114,
      "throttle_mean": 0.40574002265930176,
      "brake_mean": -0.4852236211299896
    },
    {
      "episode_num": 29,
      "total_reward": 933.9999999999872,
      "episode_length": 660,
      "avg_reward_per_step": 1.4151515151514957,
      "max_reward_step": 7.094244604316547,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.07116274535655975,
      "steering_std": 0.9618057012557983,
      "throttle_mean": 0.45682045817375183,
      "brake_mean": -0.535952627658844
    }
  ]
}