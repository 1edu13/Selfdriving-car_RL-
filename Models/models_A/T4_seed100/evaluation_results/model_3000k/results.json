{
  "model": "model_3000k",
  "evaluation_date": "2026-01-12T20:09:21.455316",
  "num_episodes": 30,
  "seed": 100,
  "device": "cuda",
  "statistics": {
    "mean_reward": 807.9927527133552,
    "std_reward": 140.3624482018567,
    "min_reward": 411.55115511549593,
    "max_reward": 937.699999999989,
    "median_reward": 868.6614344887521,
    "mean_length": 968.1333333333333,
    "std_length": 79.57207773808321,
    "win_rate": 23.333333333333332,
    "success_rate": 100.0,
    "steering_mean": -0.09050434955085317,
    "throttle_mean": 0.3807361076275508,
    "brake_mean": -0.5008905875186126
  },
  "episodes": [
    {
      "episode_num": 0,
      "total_reward": 870.3703703703517,
      "episode_length": 1000,
      "avg_reward_per_step": 0.8703703703703517,
      "max_reward_step": 7.307407407407425,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.09359122067689896,
      "steering_std": 0.988393247127533,
      "throttle_mean": 0.4235958158969879,
      "brake_mean": -0.5246237516403198
    },
    {
      "episode_num": 1,
      "total_reward": 411.55115511549593,
      "episode_length": 1000,
      "avg_reward_per_step": 0.41155115511549595,
      "max_reward_step": 6.500660066006617,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": 0.015146438963711262,
      "steering_std": 0.7985873818397522,
      "throttle_mean": -0.2443782389163971,
      "brake_mean": 0.10849679261445999
    },
    {
      "episode_num": 2,
      "total_reward": 864.1577060931738,
      "episode_length": 1000,
      "avg_reward_per_step": 0.8641577060931739,
      "max_reward_step": 7.068458781362008,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.08374226838350296,
      "steering_std": 0.937660813331604,
      "throttle_mean": 0.31934210658073425,
      "brake_mean": -0.48907262086868286
    },
    {
      "episode_num": 3,
      "total_reward": 867.6258992805548,
      "episode_length": 1000,
      "avg_reward_per_step": 0.8676258992805548,
      "max_reward_step": 7.094244604316547,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.12437600642442703,
      "steering_std": 0.9600580930709839,
      "throttle_mean": 0.2697092890739441,
      "brake_mean": -0.5225617289543152
    },
    {
      "episode_num": 4,
      "total_reward": 832.88590604025,
      "episode_length": 1000,
      "avg_reward_per_step": 0.83288590604025,
      "max_reward_step": 6.611409395973155,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.07003644853830338,
      "steering_std": 0.9400602579116821,
      "throttle_mean": 0.5007246732711792,
      "brake_mean": -0.5209314227104187
    },
    {
      "episode_num": 5,
      "total_reward": 900.1999999999911,
      "episode_length": 998,
      "avg_reward_per_step": 0.9020040080160231,
      "max_reward_step": 7.042857142857144,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.1308584213256836,
      "steering_std": 0.9486223459243774,
      "throttle_mean": 0.2929891347885132,
      "brake_mean": -0.49999603629112244
    },
    {
      "episode_num": 6,
      "total_reward": 707.3770491803068,
      "episode_length": 1000,
      "avg_reward_per_step": 0.7073770491803069,
      "max_reward_step": 12.195081967213014,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.08887942135334015,
      "steering_std": 0.9922263622283936,
      "throttle_mean": 0.5018544793128967,
      "brake_mean": -0.5384529829025269
    },
    {
      "episode_num": 7,
      "total_reward": 850.1466275659599,
      "episode_length": 1000,
      "avg_reward_per_step": 0.8501466275659598,
      "max_reward_step": 5.765102639296188,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.13516181707382202,
      "steering_std": 1.0764819383621216,
      "throttle_mean": 0.34860554337501526,
      "brake_mean": -0.572207510471344
    },
    {
      "episode_num": 8,
      "total_reward": 909.7999999999906,
      "episode_length": 902,
      "avg_reward_per_step": 1.0086474501108544,
      "max_reward_step": 7.120216606498275,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.09255470335483551,
      "steering_std": 1.122117280960083,
      "throttle_mean": 0.3917618989944458,
      "brake_mean": -0.4963296055793762
    },
    {
      "episode_num": 9,
      "total_reward": 877.0491803278526,
      "episode_length": 1000,
      "avg_reward_per_step": 0.8770491803278526,
      "max_reward_step": 6.457377049180328,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.12651324272155762,
      "steering_std": 1.0919992923736572,
      "throttle_mean": 0.39097827672958374,
      "brake_mean": -0.5032148361206055
    },
    {
      "episode_num": 10,
      "total_reward": 874.9103942652155,
      "episode_length": 1000,
      "avg_reward_per_step": 0.8749103942652154,
      "max_reward_step": 7.068458781362008,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.05931456759572029,
      "steering_std": 1.0253503322601318,
      "throttle_mean": 0.28808191418647766,
      "brake_mean": -0.5118941068649292
    },
    {
      "episode_num": 11,
      "total_reward": 445.97701149423784,
      "episode_length": 1000,
      "avg_reward_per_step": 0.44597701149423785,
      "max_reward_step": 5.647126436781612,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.13774167001247406,
      "steering_std": 0.8912965655326843,
      "throttle_mean": 0.13270893692970276,
      "brake_mean": -0.46430355310440063
    },
    {
      "episode_num": 12,
      "total_reward": 937.699999999989,
      "episode_length": 623,
      "avg_reward_per_step": 1.5051364365970932,
      "max_reward_step": 7.172727272727273,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.08894824236631393,
      "steering_std": 1.1248973608016968,
      "throttle_mean": 0.3747527003288269,
      "brake_mean": -0.6077143549919128
    },
    {
      "episode_num": 13,
      "total_reward": 920.8999999999901,
      "episode_length": 791,
      "avg_reward_per_step": 1.1642225031605438,
      "max_reward_step": 6.289776357827492,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.06354311108589172,
      "steering_std": 1.1209094524383545,
      "throttle_mean": 0.5324095487594604,
      "brake_mean": -0.5631707906723022
    },
    {
      "episode_num": 14,
      "total_reward": 738.0281690140645,
      "episode_length": 1000,
      "avg_reward_per_step": 0.7380281690140644,
      "max_reward_step": 6.942253521126761,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.03276131674647331,
      "steering_std": 0.9346086382865906,
      "throttle_mean": 0.3411577641963959,
      "brake_mean": -0.5248820781707764
    },
    {
      "episode_num": 15,
      "total_reward": 908.6999999999844,
      "episode_length": 913,
      "avg_reward_per_step": 0.9952902519167408,
      "max_reward_step": 6.868641114982578,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.009420054033398628,
      "steering_std": 1.021592378616333,
      "throttle_mean": 0.590998113155365,
      "brake_mean": -0.5375770926475525
    },
    {
      "episode_num": 16,
      "total_reward": 837.2937293729238,
      "episode_length": 1000,
      "avg_reward_per_step": 0.8372937293729239,
      "max_reward_step": 6.500660066006617,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.05709085240960121,
      "steering_std": 1.0911896228790283,
      "throttle_mean": 0.5354651212692261,
      "brake_mean": -0.5295248627662659
    },
    {
      "episode_num": 17,
      "total_reward": 536.3636363636213,
      "episode_length": 1000,
      "avg_reward_per_step": 0.5363636363636213,
      "max_reward_step": 7.805138339920973,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.09662579745054245,
      "steering_std": 0.8464658856391907,
      "throttle_mean": 0.29586726427078247,
      "brake_mean": -0.43973833322525024
    },
    {
      "episode_num": 18,
      "total_reward": 869.6969696969494,
      "episode_length": 1000,
      "avg_reward_per_step": 0.8696969696969494,
      "max_reward_step": 10.001010101010024,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.13462704420089722,
      "steering_std": 1.0030838251113892,
      "throttle_mean": 0.5675114989280701,
      "brake_mean": -0.5542840957641602
    },
    {
      "episode_num": 19,
      "total_reward": 810.2990033222475,
      "episode_length": 1000,
      "avg_reward_per_step": 0.8102990033222475,
      "max_reward_step": 6.5445182724252495,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.11232616007328033,
      "steering_std": 1.046143889427185,
      "throttle_mean": 0.5089156627655029,
      "brake_mean": -0.507685661315918
    },
    {
      "episode_num": 20,
      "total_reward": 866.6666666666475,
      "episode_length": 1000,
      "avg_reward_per_step": 0.8666666666666475,
      "max_reward_step": 7.307407407407408,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.0809633806347847,
      "steering_std": 1.1050926446914673,
      "throttle_mean": 0.5018139481544495,
      "brake_mean": -0.5506300926208496
    },
    {
      "episode_num": 21,
      "total_reward": 875.77854671279,
      "episode_length": 1000,
      "avg_reward_per_step": 0.87577854671279,
      "max_reward_step": 6.8204152249134955,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.12812432646751404,
      "steering_std": 1.0578713417053223,
      "throttle_mean": 0.45798879861831665,
      "brake_mean": -0.5046355128288269
    },
    {
      "episode_num": 22,
      "total_reward": 875.2321981424021,
      "episode_length": 1000,
      "avg_reward_per_step": 0.8752321981424022,
      "max_reward_step": 6.091950464396291,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.13950477540493011,
      "steering_std": 1.0893677473068237,
      "throttle_mean": 0.49712714552879333,
      "brake_mean": -0.5776033997535706
    },
    {
      "episode_num": 23,
      "total_reward": 890.683229813645,
      "episode_length": 1000,
      "avg_reward_per_step": 0.890683229813645,
      "max_reward_step": 6.111180124223603,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.1578855663537979,
      "steering_std": 1.1268281936645508,
      "throttle_mean": 0.5306234359741211,
      "brake_mean": -0.49183523654937744
    },
    {
      "episode_num": 24,
      "total_reward": 880.4687499999827,
      "episode_length": 1000,
      "avg_reward_per_step": 0.8804687499999827,
      "max_reward_step": 7.7125,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.09466651827096939,
      "steering_std": 0.9298449754714966,
      "throttle_mean": 0.39089512825012207,
      "brake_mean": -0.47895362973213196
    },
    {
      "episode_num": 25,
      "total_reward": 651.3661202185615,
      "episode_length": 1000,
      "avg_reward_per_step": 0.6513661202185614,
      "max_reward_step": 5.364480874316968,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.09219679236412048,
      "steering_std": 1.033551573753357,
      "throttle_mean": 0.2401602864265442,
      "brake_mean": -0.5418801307678223
    },
    {
      "episode_num": 26,
      "total_reward": 567.8082191780653,
      "episode_length": 1000,
      "avg_reward_per_step": 0.5678082191780653,
      "max_reward_step": 6.749315068493161,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.04349662736058235,
      "steering_std": 0.8928182125091553,
      "throttle_mean": 0.3744944930076599,
      "brake_mean": -0.567072331905365
    },
    {
      "episode_num": 27,
      "total_reward": 907.2999999999814,
      "episode_length": 927,
      "avg_reward_per_step": 0.9787486515641655,
      "max_reward_step": 7.042857142857144,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.11309563368558884,
      "steering_std": 1.0823391675949097,
      "throttle_mean": 0.3911847770214081,
      "brake_mean": -0.5221198201179504
    },
    {
      "episode_num": 28,
      "total_reward": 910.9999999999809,
      "episode_length": 890,
      "avg_reward_per_step": 1.023595505617956,
      "max_reward_step": 7.418796992481203,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.08136260509490967,
      "steering_std": 1.0423191785812378,
      "throttle_mean": 0.36262086033821106,
      "brake_mean": -0.504611611366272
    },
    {
      "episode_num": 29,
      "total_reward": 842.4460431654472,
      "episode_length": 1000,
      "avg_reward_per_step": 0.8424460431654472,
      "max_reward_step": 7.094244604316547,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.06086833402514458,
      "steering_std": 0.9752227067947388,
      "throttle_mean": 0.3121228516101837,
      "brake_mean": -0.4877072274684906
    }
  ]
}