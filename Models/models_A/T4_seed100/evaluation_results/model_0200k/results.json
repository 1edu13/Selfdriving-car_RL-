{
  "model": "model_0200k",
  "evaluation_date": "2026-01-12T19:26:40.826378",
  "num_episodes": 30,
  "seed": 100,
  "device": "cuda",
  "statistics": {
    "mean_reward": 207.61582609378996,
    "std_reward": 136.68401656862443,
    "min_reward": -47.20496894410018,
    "max_reward": 492.4657534246422,
    "median_reward": 215.48542337827186,
    "mean_length": 1000.0,
    "std_length": 0.0,
    "win_rate": 0.0,
    "success_rate": 93.33333333333333,
    "steering_mean": -0.49977131051321827,
    "throttle_mean": 0.5416297813256582,
    "brake_mean": -0.6886526207129161
  },
  "episodes": [
    {
      "episode_num": 0,
      "total_reward": 44.44444444444824,
      "episode_length": 1000,
      "avg_reward_per_step": 0.044444444444448235,
      "max_reward_step": 7.307407407407408,
      "min_reward_step": -0.10000000000000142,
      "steering_mean": 0.2531646490097046,
      "steering_std": 0.4810492694377899,
      "throttle_mean": 0.7366845011711121,
      "brake_mean": -0.46805158257484436
    },
    {
      "episode_num": 1,
      "total_reward": -4.290429042903803,
      "episode_length": 1000,
      "avg_reward_per_step": -0.004290429042903803,
      "max_reward_step": 6.500660066006601,
      "min_reward_step": -0.10000000000000142,
      "steering_mean": -0.8703073859214783,
      "steering_std": 0.6209495067596436,
      "throttle_mean": 0.4859445095062256,
      "brake_mean": -0.7297303676605225
    },
    {
      "episode_num": 2,
      "total_reward": 79.2114695340552,
      "episode_length": 1000,
      "avg_reward_per_step": 0.0792114695340552,
      "max_reward_step": 7.068458781362008,
      "min_reward_step": -0.10000000000000142,
      "steering_mean": -0.879511833190918,
      "steering_std": 0.5500104427337646,
      "throttle_mean": 0.38512250781059265,
      "brake_mean": -0.7998185753822327
    },
    {
      "episode_num": 3,
      "total_reward": 281.2949640287601,
      "episode_length": 1000,
      "avg_reward_per_step": 0.2812949640287601,
      "max_reward_step": 7.094244604316547,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.6813899874687195,
      "steering_std": 0.7335662841796875,
      "throttle_mean": 0.6285156607627869,
      "brake_mean": -0.7214780449867249
    },
    {
      "episode_num": 4,
      "total_reward": 27.516778523492427,
      "episode_length": 1000,
      "avg_reward_per_step": 0.027516778523492425,
      "max_reward_step": 6.611409395973155,
      "min_reward_step": -0.10000000000000142,
      "steering_mean": -0.8486483693122864,
      "steering_std": 0.5942135453224182,
      "throttle_mean": 0.4599992036819458,
      "brake_mean": -0.6864913105964661
    },
    {
      "episode_num": 5,
      "total_reward": 50.00000000000401,
      "episode_length": 1000,
      "avg_reward_per_step": 0.050000000000004007,
      "max_reward_step": 7.042857142857144,
      "min_reward_step": -0.10000000000000142,
      "steering_mean": -0.9287263751029968,
      "steering_std": 0.5727188587188721,
      "throttle_mean": 0.42886823415756226,
      "brake_mean": -0.7586434483528137
    },
    {
      "episode_num": 6,
      "total_reward": 383.606557377031,
      "episode_length": 1000,
      "avg_reward_per_step": 0.383606557377031,
      "max_reward_step": 8.09672131147541,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.39949625730514526,
      "steering_std": 0.7683433890342712,
      "throttle_mean": 0.5083167552947998,
      "brake_mean": -0.6870770454406738
    },
    {
      "episode_num": 7,
      "total_reward": 137.53665689150083,
      "episode_length": 1000,
      "avg_reward_per_step": 0.13753665689150082,
      "max_reward_step": 5.765102639296202,
      "min_reward_step": -0.10000000000000142,
      "steering_mean": -0.6452013254165649,
      "steering_std": 0.7414655685424805,
      "throttle_mean": 0.45060181617736816,
      "brake_mean": -0.704131007194519
    },
    {
      "episode_num": 8,
      "total_reward": 307.942238267131,
      "episode_length": 1000,
      "avg_reward_per_step": 0.307942238267131,
      "max_reward_step": 7.120216606498195,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.7867965698242188,
      "steering_std": 0.5973384380340576,
      "throttle_mean": 0.47902795672416687,
      "brake_mean": -0.75140380859375
    },
    {
      "episode_num": 9,
      "total_reward": 313.1147540983446,
      "episode_length": 1000,
      "avg_reward_per_step": 0.31311475409834455,
      "max_reward_step": 6.457377049180328,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.7428756356239319,
      "steering_std": 0.5858835577964783,
      "throttle_mean": 0.5578885674476624,
      "brake_mean": -0.7891583442687988
    },
    {
      "episode_num": 10,
      "total_reward": 211.82795698924332,
      "episode_length": 1000,
      "avg_reward_per_step": 0.2118279569892433,
      "max_reward_step": 7.068458781362008,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.8074897527694702,
      "steering_std": 0.5990496873855591,
      "throttle_mean": 0.4420205354690552,
      "brake_mean": -0.743948757648468
    },
    {
      "episode_num": 11,
      "total_reward": 216.09195402298474,
      "episode_length": 1000,
      "avg_reward_per_step": 0.21609195402298473,
      "max_reward_step": 5.647126436781609,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.5742834806442261,
      "steering_std": 0.8391077518463135,
      "throttle_mean": 0.5029573440551758,
      "brake_mean": -0.647077739238739
    },
    {
      "episode_num": 12,
      "total_reward": 321.81818181816436,
      "episode_length": 1000,
      "avg_reward_per_step": 0.32181818181816435,
      "max_reward_step": 7.172727272727273,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.8497821688652039,
      "steering_std": 0.6712821125984192,
      "throttle_mean": 0.442554771900177,
      "brake_mean": -0.7737911343574524
    },
    {
      "episode_num": 13,
      "total_reward": 53.354632587863826,
      "episode_length": 1000,
      "avg_reward_per_step": 0.053354632587863826,
      "max_reward_step": 6.289776357827477,
      "min_reward_step": -0.10000000000000142,
      "steering_mean": -0.9333511590957642,
      "steering_std": 0.5179032683372498,
      "throttle_mean": 0.700208306312561,
      "brake_mean": -0.7512683272361755
    },
    {
      "episode_num": 14,
      "total_reward": 290.8450704225193,
      "episode_length": 1000,
      "avg_reward_per_step": 0.29084507042251934,
      "max_reward_step": 6.942253521126761,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": 0.194896399974823,
      "steering_std": 0.40800759196281433,
      "throttle_mean": 0.6171008348464966,
      "brake_mean": -0.584181547164917
    },
    {
      "episode_num": 15,
      "total_reward": 231.01045296167013,
      "episode_length": 1000,
      "avg_reward_per_step": 0.23101045296167014,
      "max_reward_step": 6.868641114982578,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.24327991902828217,
      "steering_std": 0.7622979283332825,
      "throttle_mean": 0.48963725566864014,
      "brake_mean": -0.670404851436615
    },
    {
      "episode_num": 16,
      "total_reward": 200.33003300330083,
      "episode_length": 1000,
      "avg_reward_per_step": 0.20033003300330082,
      "max_reward_step": 6.500660066006617,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": 0.08351615816354752,
      "steering_std": 0.6883679628372192,
      "throttle_mean": 0.6112422943115234,
      "brake_mean": -0.5787277817726135
    },
    {
      "episode_num": 17,
      "total_reward": 81.81818181818679,
      "episode_length": 1000,
      "avg_reward_per_step": 0.08181818181818679,
      "max_reward_step": 7.805138339920949,
      "min_reward_step": -0.10000000000000142,
      "steering_mean": -0.8637039661407471,
      "steering_std": 0.5273917317390442,
      "throttle_mean": 0.468048095703125,
      "brake_mean": -0.7674116492271423
    },
    {
      "episode_num": 18,
      "total_reward": 327.60942760941083,
      "episode_length": 1000,
      "avg_reward_per_step": 0.3276094276094108,
      "max_reward_step": 6.634006734006735,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": 0.12722553312778473,
      "steering_std": 0.564469575881958,
      "throttle_mean": 0.6747727990150452,
      "brake_mean": -0.5822020769119263
    },
    {
      "episode_num": 19,
      "total_reward": 66.11295681063629,
      "episode_length": 1000,
      "avg_reward_per_step": 0.0661129568106363,
      "max_reward_step": 6.5445182724252495,
      "min_reward_step": -0.10000000000000142,
      "steering_mean": -0.9397763609886169,
      "steering_std": 0.5092442035675049,
      "throttle_mean": 0.7121300101280212,
      "brake_mean": -0.7566664218902588
    },
    {
      "episode_num": 20,
      "total_reward": 399.99999999998244,
      "episode_length": 1000,
      "avg_reward_per_step": 0.3999999999999824,
      "max_reward_step": 7.307407407407408,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.1572893261909485,
      "steering_std": 0.7096828818321228,
      "throttle_mean": 0.5108442902565002,
      "brake_mean": -0.6654618978500366
    },
    {
      "episode_num": 21,
      "total_reward": 214.87889273355898,
      "episode_length": 1000,
      "avg_reward_per_step": 0.21487889273355898,
      "max_reward_step": 6.8204152249134955,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.805661141872406,
      "steering_std": 0.5660372376441956,
      "throttle_mean": 0.5278433561325073,
      "brake_mean": -0.7244353890419006
    },
    {
      "episode_num": 22,
      "total_reward": 191.021671826628,
      "episode_length": 1000,
      "avg_reward_per_step": 0.191021671826628,
      "max_reward_step": 6.091950464396286,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.6090473532676697,
      "steering_std": 0.7728773355484009,
      "throttle_mean": 0.47381919622421265,
      "brake_mean": -0.7006932497024536
    },
    {
      "episode_num": 23,
      "total_reward": -47.20496894410018,
      "episode_length": 1000,
      "avg_reward_per_step": -0.04720496894410018,
      "max_reward_step": 6.111180124223603,
      "min_reward_step": -0.10000000000000142,
      "steering_mean": 0.37620440125465393,
      "steering_std": 0.4468242824077606,
      "throttle_mean": 0.6662116646766663,
      "brake_mean": -0.4671463668346405
    },
    {
      "episode_num": 24,
      "total_reward": 64.06250000000506,
      "episode_length": 1000,
      "avg_reward_per_step": 0.06406250000000506,
      "max_reward_step": 7.7125,
      "min_reward_step": -0.10000000000000142,
      "steering_mean": -0.8072529435157776,
      "steering_std": 0.707828938961029,
      "throttle_mean": 0.48418763279914856,
      "brake_mean": -0.7195537090301514
    },
    {
      "episode_num": 25,
      "total_reward": 309.8360655737618,
      "episode_length": 1000,
      "avg_reward_per_step": 0.3098360655737618,
      "max_reward_step": 5.364480874316968,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.0274197980761528,
      "steering_std": 0.7359107732772827,
      "throttle_mean": 0.5808233618736267,
      "brake_mean": -0.643640398979187
    },
    {
      "episode_num": 26,
      "total_reward": 492.4657534246422,
      "episode_length": 1000,
      "avg_reward_per_step": 0.49246575342464216,
      "max_reward_step": 6.749315068493161,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.03154981881380081,
      "steering_std": 0.6685850024223328,
      "throttle_mean": 0.48150694370269775,
      "brake_mean": -0.631871223449707
    },
    {
      "episode_num": 27,
      "total_reward": 310.714285714269,
      "episode_length": 1000,
      "avg_reward_per_step": 0.310714285714269,
      "max_reward_step": 7.042857142857144,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.767325222492218,
      "steering_std": 0.6271278858184814,
      "throttle_mean": 0.6561648845672607,
      "brake_mean": -0.7860050201416016
    },
    {
      "episode_num": 28,
      "total_reward": 339.8496240601328,
      "episode_length": 1000,
      "avg_reward_per_step": 0.3398496240601328,
      "max_reward_step": 7.418796992481203,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.7875109910964966,
      "steering_std": 0.6288118362426758,
      "throttle_mean": 0.4990089237689972,
      "brake_mean": -0.7523621916770935
    },
    {
      "episode_num": 29,
      "total_reward": 331.65467625897554,
      "episode_length": 1000,
      "avg_reward_per_step": 0.33165467625897554,
      "max_reward_step": 7.094244604316547,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.04046931490302086,
      "steering_std": 0.6600272059440613,
      "throttle_mean": 0.5868412256240845,
      "brake_mean": -0.6167453527450562
    }
  ]
}