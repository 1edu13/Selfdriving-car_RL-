{
  "model": "model_0500k",
  "evaluation_date": "2026-01-12T22:17:35.874165",
  "num_episodes": 30,
  "seed": 42,
  "device": "cuda",
  "statistics": {
    "mean_reward": 318.39342757950106,
    "std_reward": 176.2801410283129,
    "min_reward": 50.17064846416802,
    "max_reward": 843.8943894389308,
    "median_reward": 284.4785108130176,
    "mean_length": 1000.0,
    "std_length": 0.0,
    "win_rate": 0.0,
    "success_rate": 100.0,
    "steering_mean": 0.010685253577927748,
    "throttle_mean": 0.8505280174314975,
    "brake_mean": -0.4687891776363055
  },
  "episodes": [
    {
      "episode_num": 0,
      "total_reward": 87.27915194346787,
      "episode_length": 1000,
      "avg_reward_per_step": 0.08727915194346787,
      "max_reward_step": 6.967137809187279,
      "min_reward_step": -0.10000000000000142,
      "steering_mean": -0.05416169762611389,
      "steering_std": 1.1754201650619507,
      "throttle_mean": 0.977603018283844,
      "brake_mean": -0.5277572274208069
    },
    {
      "episode_num": 1,
      "total_reward": 843.8943894389308,
      "episode_length": 1000,
      "avg_reward_per_step": 0.8438943894389308,
      "max_reward_step": 6.500660066006617,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.1730678677558899,
      "steering_std": 1.1574043035507202,
      "throttle_mean": 0.8454282879829407,
      "brake_mean": -0.6474668979644775
    },
    {
      "episode_num": 2,
      "total_reward": 358.4527220630222,
      "episode_length": 1000,
      "avg_reward_per_step": 0.3584527220630222,
      "max_reward_step": 5.630659025787966,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.06787164509296417,
      "steering_std": 1.0621272325515747,
      "throttle_mean": 0.849628746509552,
      "brake_mean": -0.5276204943656921
    },
    {
      "episode_num": 3,
      "total_reward": 231.2101910827929,
      "episode_length": 1000,
      "avg_reward_per_step": 0.2312101910827929,
      "max_reward_step": 6.269426751592357,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.23915816843509674,
      "steering_std": 0.8929502964019775,
      "throttle_mean": 0.8854972720146179,
      "brake_mean": -0.4936426877975464
    },
    {
      "episode_num": 4,
      "total_reward": 279.084967320245,
      "episode_length": 1000,
      "avg_reward_per_step": 0.279084967320245,
      "max_reward_step": 6.435947712418301,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": 0.19774974882602692,
      "steering_std": 1.1425138711929321,
      "throttle_mean": 0.7714848518371582,
      "brake_mean": -0.5450544357299805
    },
    {
      "episode_num": 5,
      "total_reward": 50.17064846416802,
      "episode_length": 1000,
      "avg_reward_per_step": 0.050170648464168015,
      "max_reward_step": 6.725938566552902,
      "min_reward_step": -0.10000000000000142,
      "steering_mean": 0.22074884176254272,
      "steering_std": 0.7304061651229858,
      "throttle_mean": 0.9047725200653076,
      "brake_mean": -0.3277674913406372
    },
    {
      "episode_num": 6,
      "total_reward": 243.065693430644,
      "episode_length": 1000,
      "avg_reward_per_step": 0.243065693430644,
      "max_reward_step": 7.199270072992701,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.2784270942211151,
      "steering_std": 1.0491679906845093,
      "throttle_mean": 0.8317082524299622,
      "brake_mean": -0.43998995423316956
    },
    {
      "episode_num": 7,
      "total_reward": 542.2018348623703,
      "episode_length": 1000,
      "avg_reward_per_step": 0.5422018348623703,
      "max_reward_step": 6.016207951070337,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": 0.03999407961964607,
      "steering_std": 0.9228718280792236,
      "throttle_mean": 0.7512643933296204,
      "brake_mean": -0.5636313557624817
    },
    {
      "episode_num": 8,
      "total_reward": 494.5017182130422,
      "episode_length": 1000,
      "avg_reward_per_step": 0.4945017182130422,
      "max_reward_step": 6.772852233676986,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": 0.08325963467359543,
      "steering_std": 0.9853482842445374,
      "throttle_mean": 0.7269595861434937,
      "brake_mean": -0.6526690125465393
    },
    {
      "episode_num": 9,
      "total_reward": 280.4713804713637,
      "episode_length": 1000,
      "avg_reward_per_step": 0.2804713804713637,
      "max_reward_step": 6.634006734006735,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.18580004572868347,
      "steering_std": 1.0825979709625244,
      "throttle_mean": 1.081836223602295,
      "brake_mean": -0.565152108669281
    },
    {
      "episode_num": 10,
      "total_reward": 213.33333333332925,
      "episode_length": 1000,
      "avg_reward_per_step": 0.21333333333332924,
      "max_reward_step": 6.566666666666667,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.25906530022621155,
      "steering_std": 0.7866597175598145,
      "throttle_mean": 0.07807367295026779,
      "brake_mean": -0.227835550904274
    },
    {
      "episode_num": 11,
      "total_reward": 67.857142857148,
      "episode_length": 1000,
      "avg_reward_per_step": 0.067857142857148,
      "max_reward_step": 7.042857142857144,
      "min_reward_step": -0.10000000000000142,
      "steering_mean": -0.1413164585828781,
      "steering_std": 0.8516453504562378,
      "throttle_mean": 0.8395943641662598,
      "brake_mean": -0.3288670778274536
    },
    {
      "episode_num": 12,
      "total_reward": 278.37837837836196,
      "episode_length": 1000,
      "avg_reward_per_step": 0.27837837837836193,
      "max_reward_step": 6.656756756756757,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.13010744750499725,
      "steering_std": 0.9793903827667236,
      "throttle_mean": 0.8352592587471008,
      "brake_mean": -0.5993613004684448
    },
    {
      "episode_num": 13,
      "total_reward": 507.7170418006257,
      "episode_length": 1000,
      "avg_reward_per_step": 0.5077170418006257,
      "max_reward_step": 6.330868167202572,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": 0.10532411932945251,
      "steering_std": 0.9934169054031372,
      "throttle_mean": 0.8211345672607422,
      "brake_mean": -0.5116620063781738
    },
    {
      "episode_num": 14,
      "total_reward": 180.3738317757062,
      "episode_length": 1000,
      "avg_reward_per_step": 0.1803738317757062,
      "max_reward_step": 9.24579439252338,
      "min_reward_step": -0.10000000000000142,
      "steering_mean": 0.21946807205677032,
      "steering_std": 0.7935608625411987,
      "throttle_mean": 0.8218737840652466,
      "brake_mean": -0.33072248101234436
    },
    {
      "episode_num": 15,
      "total_reward": 268.9655172413618,
      "episode_length": 1000,
      "avg_reward_per_step": 0.2689655172413618,
      "max_reward_step": 6.796551724137931,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": 0.04479939863085747,
      "steering_std": 0.8843864798545837,
      "throttle_mean": 0.9372155666351318,
      "brake_mean": -0.37172284722328186
    },
    {
      "episode_num": 16,
      "total_reward": 68.38487972509097,
      "episode_length": 1000,
      "avg_reward_per_step": 0.06838487972509097,
      "max_reward_step": 6.772852233676976,
      "min_reward_step": -0.10000000000000142,
      "steering_mean": 0.15011464059352875,
      "steering_std": 1.0383813381195068,
      "throttle_mean": 0.9077386856079102,
      "brake_mean": -0.3981800377368927
    },
    {
      "episode_num": 17,
      "total_reward": 350.51194539247393,
      "episode_length": 1000,
      "avg_reward_per_step": 0.35051194539247393,
      "max_reward_step": 6.725938566552902,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.11107055842876434,
      "steering_std": 1.155550479888916,
      "throttle_mean": 0.7931632399559021,
      "brake_mean": -0.5403950810432434
    },
    {
      "episode_num": 18,
      "total_reward": 293.44262295080324,
      "episode_length": 1000,
      "avg_reward_per_step": 0.29344262295080326,
      "max_reward_step": 6.457377049180328,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": 0.1600530743598938,
      "steering_std": 0.8059556484222412,
      "throttle_mean": 0.7409898638725281,
      "brake_mean": -0.3765777349472046
    },
    {
      "episode_num": 19,
      "total_reward": 532.2580645161144,
      "episode_length": 1000,
      "avg_reward_per_step": 0.5322580645161143,
      "max_reward_step": 6.351612903225806,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": 0.03969329223036766,
      "steering_std": 1.0699222087860107,
      "throttle_mean": 0.8133053779602051,
      "brake_mean": -0.5106202363967896
    },
    {
      "episode_num": 20,
      "total_reward": 56.93430656934772,
      "episode_length": 1000,
      "avg_reward_per_step": 0.05693430656934772,
      "max_reward_step": 7.199270072992701,
      "min_reward_step": -0.10000000000000142,
      "steering_mean": 0.12411236763000488,
      "steering_std": 0.8762744665145874,
      "throttle_mean": 0.7725452780723572,
      "brake_mean": -0.25106289982795715
    },
    {
      "episode_num": 21,
      "total_reward": 364.6840148698716,
      "episode_length": 1000,
      "avg_reward_per_step": 0.36468401486987156,
      "max_reward_step": 7.334944237918216,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": 0.081011101603508,
      "steering_std": 0.8249202370643616,
      "throttle_mean": 0.8918764591217041,
      "brake_mean": -0.5183543562889099
    },
    {
      "episode_num": 22,
      "total_reward": 284.34163701066615,
      "episode_length": 1000,
      "avg_reward_per_step": 0.28434163701066617,
      "max_reward_step": 7.017437722419929,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": 0.13992837071418762,
      "steering_std": 0.9854598641395569,
      "throttle_mean": 1.5631965398788452,
      "brake_mean": -0.16711315512657166
    },
    {
      "episode_num": 23,
      "total_reward": 362.0938628158669,
      "episode_length": 1000,
      "avg_reward_per_step": 0.36209386281586686,
      "max_reward_step": 7.120216606498195,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": 0.058477554470300674,
      "steering_std": 1.0828070640563965,
      "throttle_mean": 1.0931860208511353,
      "brake_mean": -0.5326734781265259
    },
    {
      "episode_num": 24,
      "total_reward": 302.1352313167092,
      "episode_length": 1000,
      "avg_reward_per_step": 0.3021352313167092,
      "max_reward_step": 7.017437722419929,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.017174014821648598,
      "steering_std": 1.2698739767074585,
      "throttle_mean": 0.7823730707168579,
      "brake_mean": -0.5937442779541016
    },
    {
      "episode_num": 25,
      "total_reward": 274.99999999998425,
      "episode_length": 1000,
      "avg_reward_per_step": 0.27499999999998426,
      "max_reward_step": 6.310256410256411,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": 0.1664944738149643,
      "steering_std": 0.8073412179946899,
      "throttle_mean": 0.8264393210411072,
      "brake_mean": -0.3628198206424713
    },
    {
      "episode_num": 26,
      "total_reward": 284.615384615369,
      "episode_length": 1000,
      "avg_reward_per_step": 0.284615384615369,
      "max_reward_step": 6.310256410256411,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": 0.12520554661750793,
      "steering_std": 1.0773561000823975,
      "throttle_mean": 0.9187904596328735,
      "brake_mean": -0.5519025325775146
    },
    {
      "episode_num": 27,
      "total_reward": 341.07744107742406,
      "episode_length": 1000,
      "avg_reward_per_step": 0.34107744107742405,
      "max_reward_step": 6.634006734006735,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": 0.16139544546604156,
      "steering_std": 0.9599238634109497,
      "throttle_mean": 0.8443430066108704,
      "brake_mean": -0.4734949469566345
    },
    {
      "episode_num": 28,
      "total_reward": 561.1570247933728,
      "episode_length": 1000,
      "avg_reward_per_step": 0.5611570247933728,
      "max_reward_step": 8.164462809917355,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": 0.1165039986371994,
      "steering_std": 0.9648597240447998,
      "throttle_mean": 0.7724589109420776,
      "brake_mean": -0.4476217031478882
    },
    {
      "episode_num": 29,
      "total_reward": 548.208469055359,
      "episode_length": 1000,
      "avg_reward_per_step": 0.548208469055359,
      "max_reward_step": 6.414657980456027,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.25655585527420044,
      "steering_std": 1.2016944885253906,
      "throttle_mean": 0.8360999226570129,
      "brake_mean": -0.678192138671875
    }
  ]
}