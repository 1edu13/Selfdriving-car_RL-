{
  "model": "model_0500k",
  "evaluation_date": "2026-01-14T11:24:03.633657",
  "num_episodes": 30,
  "seed": 100,
  "device": "cuda",
  "statistics": {
    "mean_reward": 258.1449658433302,
    "std_reward": 123.4048136379317,
    "min_reward": 55.313738019170685,
    "max_reward": 509.0704225352097,
    "median_reward": 263.2982730531097,
    "mean_length": 361.1,
    "std_length": 130.82312486712738,
    "win_rate": 0.0,
    "success_rate": 100.0,
    "steering_mean": -0.08320262574901184,
    "throttle_mean": 0.216400920599699,
    "brake_mean": -0.8114884739120801
  },
  "episodes": [
    {
      "episode_num": 0,
      "total_reward": 103.77407407407468,
      "episode_length": 255,
      "avg_reward_per_step": 0.40695715323166537,
      "max_reward_step": 7.307407407407408,
      "min_reward_step": -0.8999999999999944,
      "steering_mean": -0.15715797245502472,
      "steering_std": 0.9551354646682739,
      "throttle_mean": 0.3581094443798065,
      "brake_mean": -0.9632981419563293
    },
    {
      "episode_num": 1,
      "total_reward": 220.12904290428907,
      "episode_length": 295,
      "avg_reward_per_step": 0.7462001454382681,
      "max_reward_step": 6.500660066006601,
      "min_reward_step": -0.9000000000000228,
      "steering_mean": -0.0033219289034605026,
      "steering_std": 1.0701831579208374,
      "throttle_mean": 0.2535170912742615,
      "brake_mean": -0.7973929047584534
    },
    {
      "episode_num": 2,
      "total_reward": 154.30681003584294,
      "episode_length": 460,
      "avg_reward_per_step": 0.33544958703444117,
      "max_reward_step": 7.068458781362008,
      "min_reward_step": -0.8999999999999944,
      "steering_mean": -0.10847822576761246,
      "steering_std": 0.8411301970481873,
      "throttle_mean": 0.05104827880859375,
      "brake_mean": -0.8765774965286255
    },
    {
      "episode_num": 3,
      "total_reward": 474.35395683452725,
      "episode_length": 424,
      "avg_reward_per_step": 1.1187593321569038,
      "max_reward_step": 7.094244604316547,
      "min_reward_step": -0.9000000000000228,
      "steering_mean": -0.2099120169878006,
      "steering_std": 1.0284582376480103,
      "throttle_mean": 0.22215871512889862,
      "brake_mean": -0.8197206258773804
    },
    {
      "episode_num": 4,
      "total_reward": 76.76241610738352,
      "episode_length": 272,
      "avg_reward_per_step": 0.28221476510067467,
      "max_reward_step": 6.611409395973155,
      "min_reward_step": -0.8999999999999944,
      "steering_mean": 0.029889926314353943,
      "steering_std": 0.9834715127944946,
      "throttle_mean": 0.396763414144516,
      "brake_mean": -0.8706366419792175
    },
    {
      "episode_num": 5,
      "total_reward": 85.8571428571437,
      "episode_length": 302,
      "avg_reward_per_step": 0.28429517502365464,
      "max_reward_step": 7.042857142857144,
      "min_reward_step": -0.8999999999999944,
      "steering_mean": 0.21963223814964294,
      "steering_std": 1.069326400756836,
      "throttle_mean": -0.21639597415924072,
      "brake_mean": -0.5415629148483276
    },
    {
      "episode_num": 6,
      "total_reward": 387.9147540983564,
      "episode_length": 344,
      "avg_reward_per_step": 1.127659168890571,
      "max_reward_step": 8.09672131147541,
      "min_reward_step": -0.9000000000000228,
      "steering_mean": 0.04896413907408714,
      "steering_std": 0.896984338760376,
      "throttle_mean": 0.476332426071167,
      "brake_mean": -0.8214629292488098
    },
    {
      "episode_num": 7,
      "total_reward": 270.93167155424976,
      "episode_length": 415,
      "avg_reward_per_step": 0.6528474013355416,
      "max_reward_step": 5.765102639296188,
      "min_reward_step": -0.9000000000000228,
      "steering_mean": 0.03848272189497948,
      "steering_std": 0.8030399680137634,
      "throttle_mean": 0.13363128900527954,
      "brake_mean": -0.7996524572372437
    },
    {
      "episode_num": 8,
      "total_reward": 335.652346570394,
      "episode_length": 351,
      "avg_reward_per_step": 0.9562744916535442,
      "max_reward_step": 7.120216606498195,
      "min_reward_step": -0.9000000000000228,
      "steering_mean": -0.07772165536880493,
      "steering_std": 1.055280327796936,
      "throttle_mean": 0.09920086711645126,
      "brake_mean": -0.9375532269477844
    },
    {
      "episode_num": 9,
      "total_reward": 335.414754098358,
      "episode_length": 369,
      "avg_reward_per_step": 0.9089830734372846,
      "max_reward_step": 6.457377049180328,
      "min_reward_step": -0.9000000000000228,
      "steering_mean": -0.19930310547351837,
      "steering_std": 0.9485892057418823,
      "throttle_mean": 0.15343724191188812,
      "brake_mean": -0.9442996382713318
    },
    {
      "episode_num": 10,
      "total_reward": 255.6648745519696,
      "episode_length": 297,
      "avg_reward_per_step": 0.8608244934409751,
      "max_reward_step": 7.068458781362008,
      "min_reward_step": -0.9000000000000228,
      "steering_mean": -0.27186813950538635,
      "steering_std": 1.1794459819793701,
      "throttle_mean": 0.3116071820259094,
      "brake_mean": -0.8520580530166626
    },
    {
      "episode_num": 11,
      "total_reward": 288.1160919540213,
      "episode_length": 389,
      "avg_reward_per_step": 0.7406583340720341,
      "max_reward_step": 5.647126436781609,
      "min_reward_step": -0.9000000000000228,
      "steering_mean": -0.01194722019135952,
      "steering_std": 0.8416444063186646,
      "throttle_mean": 0.07337312400341034,
      "brake_mean": -0.8591734766960144
    },
    {
      "episode_num": 12,
      "total_reward": 413.60909090908694,
      "episode_length": 365,
      "avg_reward_per_step": 1.133175591531745,
      "max_reward_step": 7.172727272727273,
      "min_reward_step": -0.9000000000000228,
      "steering_mean": -0.10066409409046173,
      "steering_std": 0.8495159149169922,
      "throttle_mean": 0.30942580103874207,
      "brake_mean": -1.034206748008728
    },
    {
      "episode_num": 13,
      "total_reward": 55.313738019170685,
      "episode_length": 324,
      "avg_reward_per_step": 0.1707214136394157,
      "max_reward_step": 6.289776357827477,
      "min_reward_step": -0.8999999999999944,
      "steering_mean": -0.06465130299329758,
      "steering_std": 0.7366682291030884,
      "throttle_mean": 0.1766853630542755,
      "brake_mean": -0.7930096387863159
    },
    {
      "episode_num": 14,
      "total_reward": 509.0704225352097,
      "episode_length": 452,
      "avg_reward_per_step": 1.1262619967593135,
      "max_reward_step": 6.942253521126761,
      "min_reward_step": -0.9000000000000228,
      "steering_mean": -0.08790554106235504,
      "steering_std": 0.8819091320037842,
      "throttle_mean": 0.1402643918991089,
      "brake_mean": -0.8536310791969299
    },
    {
      "episode_num": 15,
      "total_reward": 357.8400696864078,
      "episode_length": 369,
      "avg_reward_per_step": 0.9697562864130292,
      "max_reward_step": 6.868641114982578,
      "min_reward_step": -0.9000000000000228,
      "steering_mean": -0.29224270582199097,
      "steering_std": 1.2055513858795166,
      "throttle_mean": 0.3064929246902466,
      "brake_mean": -0.8672568202018738
    },
    {
      "episode_num": 16,
      "total_reward": 229.33003300329887,
      "episode_length": 302,
      "avg_reward_per_step": 0.7593709702095989,
      "max_reward_step": 6.500660066006601,
      "min_reward_step": -0.9000000000000228,
      "steering_mean": -0.10075384378433228,
      "steering_std": 0.8876777291297913,
      "throttle_mean": 0.3900371193885803,
      "brake_mean": -0.7361226081848145
    },
    {
      "episode_num": 17,
      "total_reward": 84.68616600790975,
      "episode_length": 1000,
      "avg_reward_per_step": 0.08468616600790975,
      "max_reward_step": 7.805138339920949,
      "min_reward_step": -0.8999999999999944,
      "steering_mean": -0.10619575530290604,
      "steering_std": 0.3911302089691162,
      "throttle_mean": -0.16044896841049194,
      "brake_mean": -0.05118311941623688
    },
    {
      "episode_num": 18,
      "total_reward": 377.31245791245397,
      "episode_length": 398,
      "avg_reward_per_step": 0.9480212510363165,
      "max_reward_step": 6.634006734006735,
      "min_reward_step": -0.9000000000000228,
      "steering_mean": -0.09057415276765823,
      "steering_std": 0.9152458906173706,
      "throttle_mean": 0.23778335750102997,
      "brake_mean": -0.8937903046607971
    },
    {
      "episode_num": 19,
      "total_reward": 109.55747508305687,
      "episode_length": 224,
      "avg_reward_per_step": 0.4890958709065039,
      "max_reward_step": 6.5445182724252495,
      "min_reward_step": -0.8999999999999944,
      "steering_mean": -0.1367509663105011,
      "steering_std": 0.753241777420044,
      "throttle_mean": 0.0881485790014267,
      "brake_mean": -0.7037163376808167
    },
    {
      "episode_num": 20,
      "total_reward": 308.5814814814788,
      "episode_length": 321,
      "avg_reward_per_step": 0.9613130264220524,
      "max_reward_step": 7.307407407407408,
      "min_reward_step": -0.9000000000000228,
      "steering_mean": 0.04194299876689911,
      "steering_std": 0.977564811706543,
      "throttle_mean": 0.38378027081489563,
      "brake_mean": -0.732821524143219
    },
    {
      "episode_num": 21,
      "total_reward": 250.99930795847587,
      "episode_length": 300,
      "avg_reward_per_step": 0.8366643598615863,
      "max_reward_step": 6.8204152249134955,
      "min_reward_step": -0.9000000000000228,
      "steering_mean": -0.17133355140686035,
      "steering_std": 1.083483338356018,
      "throttle_mean": 0.296744167804718,
      "brake_mean": -0.7908461689949036
    },
    {
      "episode_num": 22,
      "total_reward": 231.70557275541734,
      "episode_length": 309,
      "avg_reward_per_step": 0.7498562225094412,
      "max_reward_step": 6.091950464396286,
      "min_reward_step": -0.9000000000000228,
      "steering_mean": -0.0926591232419014,
      "steering_std": 0.9646889567375183,
      "throttle_mean": 0.1519932597875595,
      "brake_mean": -0.9083941578865051
    },
    {
      "episode_num": 23,
      "total_reward": 204.90869565217398,
      "episode_length": 305,
      "avg_reward_per_step": 0.6718317890235213,
      "max_reward_step": 6.111180124223603,
      "min_reward_step": -0.9000000000000228,
      "steering_mean": -0.021450577303767204,
      "steering_std": 0.9234321713447571,
      "throttle_mean": 0.29638510942459106,
      "brake_mean": -0.9275798797607422
    },
    {
      "episode_num": 24,
      "total_reward": 82.41875000000074,
      "episode_length": 304,
      "avg_reward_per_step": 0.27111430921052876,
      "max_reward_step": 7.7125,
      "min_reward_step": -0.8999999999999944,
      "steering_mean": -0.11859440803527832,
      "steering_std": 0.847652792930603,
      "throttle_mean": 0.23043374717235565,
      "brake_mean": -0.698498547077179
    },
    {
      "episode_num": 25,
      "total_reward": 166.37267759562894,
      "episode_length": 278,
      "avg_reward_per_step": 0.598462869049025,
      "max_reward_step": 5.36448087431694,
      "min_reward_step": -0.8999999999999944,
      "steering_mean": -0.07460515946149826,
      "steering_std": 0.8982335329055786,
      "throttle_mean": 0.386905312538147,
      "brake_mean": -0.9143893718719482
    },
    {
      "episode_num": 26,
      "total_reward": 354.10684931506574,
      "episode_length": 366,
      "avg_reward_per_step": 0.9675050527734037,
      "max_reward_step": 6.749315068493151,
      "min_reward_step": -0.9000000000000228,
      "steering_mean": -0.050328947603702545,
      "steering_std": 0.812701940536499,
      "throttle_mean": 0.17232124507427216,
      "brake_mean": -0.7809643149375916
    },
    {
      "episode_num": 27,
      "total_reward": 341.6571428571398,
      "episode_length": 354,
      "avg_reward_per_step": 0.9651331719128242,
      "max_reward_step": 7.042857142857144,
      "min_reward_step": -0.9000000000000228,
      "steering_mean": -0.1370561420917511,
      "steering_std": 0.8348103165626526,
      "throttle_mean": 0.2624855935573578,
      "brake_mean": -0.8503631949424744
    },
    {
      "episode_num": 28,
      "total_reward": 366.3090225563871,
      "episode_length": 365,
      "avg_reward_per_step": 1.0035863631681838,
      "max_reward_step": 7.418796992481203,
      "min_reward_step": -0.9000000000000228,
      "steering_mean": -0.13140620291233063,
      "steering_std": 0.9932301640510559,
      "throttle_mean": 0.13590960204601288,
      "brake_mean": -0.9120728969573975
    },
    {
      "episode_num": 29,
      "total_reward": 311.6920863309327,
      "episode_length": 324,
      "avg_reward_per_step": 0.9620126121325083,
      "max_reward_step": 7.094244604316547,
      "min_reward_step": -0.9000000000000228,
      "steering_mean": -0.05810805782675743,
      "steering_std": 0.8945775628089905,
      "throttle_mean": 0.37389764189720154,
      "brake_mean": -0.8124189972877502
    }
  ]
}