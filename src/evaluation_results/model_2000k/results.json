{
  "model": "model_2000k",
  "evaluation_date": "2026-01-12T22:39:15.972439",
  "num_episodes": 30,
  "seed": 42,
  "device": "cuda",
  "statistics": {
    "mean_reward": 774.5684376661543,
    "std_reward": 222.55723144376222,
    "min_reward": 235.50488599347526,
    "max_reward": 941.2999999999956,
    "median_reward": 893.3641938768062,
    "mean_length": 897.3666666666667,
    "std_length": 138.06242147022564,
    "win_rate": 43.333333333333336,
    "success_rate": 100.0,
    "steering_mean": -0.05346866631880402,
    "throttle_mean": 0.472017506758372,
    "brake_mean": -0.5353590746720632
  },
  "episodes": [
    {
      "episode_num": 0,
      "total_reward": 889.3992932862006,
      "episode_length": 1000,
      "avg_reward_per_step": 0.8893992932862006,
      "max_reward_step": 6.967137809187279,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.12407293915748596,
      "steering_std": 0.8833081126213074,
      "throttle_mean": 0.35650309920310974,
      "brake_mean": -0.48328110575675964
    },
    {
      "episode_num": 1,
      "total_reward": 924.499999999993,
      "episode_length": 755,
      "avg_reward_per_step": 1.2245033112582688,
      "max_reward_step": 6.500660066006601,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.1332617998123169,
      "steering_std": 1.0529075860977173,
      "throttle_mean": 0.5161067843437195,
      "brake_mean": -0.5488335490226746
    },
    {
      "episode_num": 2,
      "total_reward": 581.9484240687516,
      "episode_length": 1000,
      "avg_reward_per_step": 0.5819484240687516,
      "max_reward_step": 5.630659025787966,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.012583923526108265,
      "steering_std": 0.8375656008720398,
      "throttle_mean": 0.4204643666744232,
      "brake_mean": -0.5617128610610962
    },
    {
      "episode_num": 3,
      "total_reward": 890.4458598725886,
      "episode_length": 1000,
      "avg_reward_per_step": 0.8904458598725886,
      "max_reward_step": 6.269426751592357,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.09222082793712616,
      "steering_std": 0.9843674898147583,
      "throttle_mean": 0.48721662163734436,
      "brake_mean": -0.4818727374076843
    },
    {
      "episode_num": 4,
      "total_reward": 749.673202614358,
      "episode_length": 1000,
      "avg_reward_per_step": 0.749673202614358,
      "max_reward_step": 6.435947712418304,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": 0.027686739340424538,
      "steering_std": 0.9278223514556885,
      "throttle_mean": 0.4733472764492035,
      "brake_mean": -0.5805364847183228
    },
    {
      "episode_num": 5,
      "total_reward": 671.3310580204704,
      "episode_length": 1000,
      "avg_reward_per_step": 0.6713310580204704,
      "max_reward_step": 6.725938566552912,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.01494552195072174,
      "steering_std": 0.8127046227455139,
      "throttle_mean": 0.4962025582790375,
      "brake_mean": -0.570126473903656
    },
    {
      "episode_num": 6,
      "total_reward": 935.2999999999868,
      "episode_length": 647,
      "avg_reward_per_step": 1.4455950540958065,
      "max_reward_step": 7.199270072992701,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.03348223492503166,
      "steering_std": 0.9176061153411865,
      "throttle_mean": 0.33902764320373535,
      "brake_mean": -0.5346433520317078
    },
    {
      "episode_num": 7,
      "total_reward": 288.37920489295084,
      "episode_length": 1000,
      "avg_reward_per_step": 0.2883792048929508,
      "max_reward_step": 6.016207951070337,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": 0.13634146749973297,
      "steering_std": 0.6550226211547852,
      "throttle_mean": 0.5566258430480957,
      "brake_mean": -0.5200201272964478
    },
    {
      "episode_num": 8,
      "total_reward": 914.2999999999822,
      "episode_length": 857,
      "avg_reward_per_step": 1.0668611435239,
      "max_reward_step": 6.772852233676976,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.06365056335926056,
      "steering_std": 0.905326783657074,
      "throttle_mean": 0.4947512149810791,
      "brake_mean": -0.5188105702400208
    },
    {
      "episode_num": 9,
      "total_reward": 925.6999999999857,
      "episode_length": 743,
      "avg_reward_per_step": 1.245895020188406,
      "max_reward_step": 6.634006734006735,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.09545733779668808,
      "steering_std": 1.0376839637756348,
      "throttle_mean": 0.7161168456077576,
      "brake_mean": -0.4888598620891571
    },
    {
      "episode_num": 10,
      "total_reward": 279.9999999999834,
      "episode_length": 1000,
      "avg_reward_per_step": 0.27999999999998343,
      "max_reward_step": 6.566666666666667,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": 0.17002572119235992,
      "steering_std": 0.579808235168457,
      "throttle_mean": 0.6640446782112122,
      "brake_mean": -0.634952962398529
    },
    {
      "episode_num": 11,
      "total_reward": 931.3999999999877,
      "episode_length": 686,
      "avg_reward_per_step": 1.357725947521848,
      "max_reward_step": 7.042857142857144,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.14342978596687317,
      "steering_std": 0.9250181317329407,
      "throttle_mean": 0.4086643159389496,
      "brake_mean": -0.5283202528953552
    },
    {
      "episode_num": 12,
      "total_reward": 927.4999999999837,
      "episode_length": 725,
      "avg_reward_per_step": 1.2793103448275638,
      "max_reward_step": 6.656756756756757,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.1030471995472908,
      "steering_std": 1.0645745992660522,
      "throttle_mean": 0.4423390030860901,
      "brake_mean": -0.540725588798523
    },
    {
      "episode_num": 13,
      "total_reward": 917.599999999986,
      "episode_length": 824,
      "avg_reward_per_step": 1.113592233009692,
      "max_reward_step": 6.330868167202572,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.11729656904935837,
      "steering_std": 1.0556139945983887,
      "throttle_mean": 0.5615485310554504,
      "brake_mean": -0.48290014266967773
    },
    {
      "episode_num": 14,
      "total_reward": 485.6697819314479,
      "episode_length": 1000,
      "avg_reward_per_step": 0.48566978193144794,
      "max_reward_step": 6.1305295950155765,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": 0.10517425090074539,
      "steering_std": 0.7023741006851196,
      "throttle_mean": 0.4843750596046448,
      "brake_mean": -0.5924140810966492
    },
    {
      "episode_num": 15,
      "total_reward": 904.1999999999814,
      "episode_length": 958,
      "avg_reward_per_step": 0.9438413361168908,
      "max_reward_step": 6.7965517241379345,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.12332828342914581,
      "steering_std": 0.8815237879753113,
      "throttle_mean": 0.4834909737110138,
      "brake_mean": -0.4504237771034241
    },
    {
      "episode_num": 16,
      "total_reward": 332.9896907216433,
      "episode_length": 1000,
      "avg_reward_per_step": 0.3329896907216433,
      "max_reward_step": 10.209278350515433,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": 0.04097253456711769,
      "steering_std": 0.9200739860534668,
      "throttle_mean": 0.41403406858444214,
      "brake_mean": -0.5389778017997742
    },
    {
      "episode_num": 17,
      "total_reward": 719.1126279863275,
      "episode_length": 1000,
      "avg_reward_per_step": 0.7191126279863276,
      "max_reward_step": 6.725938566552902,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": 0.05342797189950943,
      "steering_std": 0.9506386518478394,
      "throttle_mean": 0.38858819007873535,
      "brake_mean": -0.6587238907814026
    },
    {
      "episode_num": 18,
      "total_reward": 922.499999999989,
      "episode_length": 775,
      "avg_reward_per_step": 1.190322580645147,
      "max_reward_step": 6.457377049180328,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.17291194200515747,
      "steering_std": 1.1472641229629517,
      "throttle_mean": 0.4954347312450409,
      "brake_mean": -0.506820797920227
    },
    {
      "episode_num": 19,
      "total_reward": 880.6451612903104,
      "episode_length": 1000,
      "avg_reward_per_step": 0.8806451612903105,
      "max_reward_step": 6.351612903225828,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.06892767548561096,
      "steering_std": 0.8623619079589844,
      "throttle_mean": 0.3901676535606384,
      "brake_mean": -0.5042764544487
    },
    {
      "episode_num": 20,
      "total_reward": 878.1021897810017,
      "episode_length": 1000,
      "avg_reward_per_step": 0.8781021897810017,
      "max_reward_step": 7.199270072992732,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.05058171972632408,
      "steering_std": 0.6812901496887207,
      "throttle_mean": 0.3241538107395172,
      "brake_mean": -0.4233364760875702
    },
    {
      "episode_num": 21,
      "total_reward": 896.2825278810238,
      "episode_length": 1000,
      "avg_reward_per_step": 0.8962825278810238,
      "max_reward_step": 7.334944237918216,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.10912413150072098,
      "steering_std": 0.848095715045929,
      "throttle_mean": 0.465949684381485,
      "brake_mean": -0.4429025948047638
    },
    {
      "episode_num": 22,
      "total_reward": 931.4999999999909,
      "episode_length": 685,
      "avg_reward_per_step": 1.359854014598527,
      "max_reward_step": 7.017437722419929,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.09899857640266418,
      "steering_std": 0.9725543856620789,
      "throttle_mean": 0.4362771511077881,
      "brake_mean": -0.5642079710960388
    },
    {
      "episode_num": 23,
      "total_reward": 929.7999999999954,
      "episode_length": 702,
      "avg_reward_per_step": 1.324501424501418,
      "max_reward_step": 7.120216606498195,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.21043439209461212,
      "steering_std": 1.1167460680007935,
      "throttle_mean": 0.4944024682044983,
      "brake_mean": -0.5136491060256958
    },
    {
      "episode_num": 24,
      "total_reward": 864.4128113878842,
      "episode_length": 1000,
      "avg_reward_per_step": 0.8644128113878842,
      "max_reward_step": 7.017437722419929,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.034239500761032104,
      "steering_std": 0.9865787625312805,
      "throttle_mean": 0.47557249665260315,
      "brake_mean": -0.5860113501548767
    },
    {
      "episode_num": 25,
      "total_reward": 896.7948717948535,
      "episode_length": 1000,
      "avg_reward_per_step": 0.8967948717948535,
      "max_reward_step": 6.310256410256411,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.08283296972513199,
      "steering_std": 1.0326042175292969,
      "throttle_mean": 0.5383813977241516,
      "brake_mean": -0.5063391327857971
    },
    {
      "episode_num": 26,
      "total_reward": 688.4615384615222,
      "episode_length": 1000,
      "avg_reward_per_step": 0.6884615384615222,
      "max_reward_step": 6.310256410256411,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.06866012513637543,
      "steering_std": 0.9327794909477234,
      "throttle_mean": 0.42861902713775635,
      "brake_mean": -0.5718944072723389
    },
    {
      "episode_num": 27,
      "total_reward": 902.2999999999804,
      "episode_length": 977,
      "avg_reward_per_step": 0.9235414534288439,
      "max_reward_step": 6.634006734006735,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.11309553682804108,
      "steering_std": 0.9028645157814026,
      "throttle_mean": 0.4132744073867798,
      "brake_mean": -0.5182936787605286
    },
    {
      "episode_num": 28,
      "total_reward": 941.2999999999956,
      "episode_length": 587,
      "avg_reward_per_step": 1.603577512776824,
      "max_reward_step": 8.164462809917355,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.11837716400623322,
      "steering_std": 1.0044517517089844,
      "throttle_mean": 0.5626160502433777,
      "brake_mean": -0.5560886859893799
    },
    {
      "episode_num": 29,
      "total_reward": 235.50488599347526,
      "episode_length": 1000,
      "avg_reward_per_step": 0.23550488599347524,
      "max_reward_step": 6.414657980456027,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": 0.04727204516530037,
      "steering_std": 0.8544331192970276,
      "throttle_mean": 0.43222925066947937,
      "brake_mean": -0.6508159637451172
    }
  ]
}