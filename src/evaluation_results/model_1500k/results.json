{
  "model": "model_1500k",
  "evaluation_date": "2026-01-12T19:48:22.566175",
  "num_episodes": 30,
  "seed": 100,
  "device": "cuda",
  "statistics": {
    "mean_reward": 752.0545156366458,
    "std_reward": 251.58736546881264,
    "min_reward": 89.3687707641248,
    "max_reward": 932.999999999987,
    "median_reward": 880.609682265608,
    "mean_length": 902.3,
    "std_length": 132.84204906579845,
    "win_rate": 33.33333333333333,
    "success_rate": 100.0,
    "steering_mean": -0.06809908132224034,
    "throttle_mean": 0.5797455946604411,
    "brake_mean": -0.4384154121081034
  },
  "episodes": [
    {
      "episode_num": 0,
      "total_reward": 930.9999999999887,
      "episode_length": 690,
      "avg_reward_per_step": 1.3492753623188243,
      "max_reward_step": 7.307407407407408,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.050791721791028976,
      "steering_std": 0.901761531829834,
      "throttle_mean": 0.48316690325737,
      "brake_mean": -0.43565869331359863
    },
    {
      "episode_num": 1,
      "total_reward": 741.5841584158283,
      "episode_length": 1000,
      "avg_reward_per_step": 0.7415841584158283,
      "max_reward_step": 6.500660066006617,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.07243035733699799,
      "steering_std": 0.975074827671051,
      "throttle_mean": 0.5319691896438599,
      "brake_mean": -0.5217611193656921
    },
    {
      "episode_num": 2,
      "total_reward": 122.22222222222732,
      "episode_length": 1000,
      "avg_reward_per_step": 0.12222222222222731,
      "max_reward_step": 7.068458781362011,
      "min_reward_step": -0.10000000000000142,
      "steering_mean": -0.08270573616027832,
      "steering_std": 0.6971897482872009,
      "throttle_mean": 0.5421770215034485,
      "brake_mean": -0.39411959052085876
    },
    {
      "episode_num": 3,
      "total_reward": 896.4028776978212,
      "episode_length": 1000,
      "avg_reward_per_step": 0.8964028776978211,
      "max_reward_step": 7.0942446043165575,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.07895460724830627,
      "steering_std": 0.8646745681762695,
      "throttle_mean": 0.6293421387672424,
      "brake_mean": -0.38027331233024597
    },
    {
      "episode_num": 4,
      "total_reward": 889.9328859060208,
      "episode_length": 1000,
      "avg_reward_per_step": 0.8899328859060208,
      "max_reward_step": 6.611409395973155,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.06491278111934662,
      "steering_std": 0.909544050693512,
      "throttle_mean": 0.4063306152820587,
      "brake_mean": -0.48350775241851807
    },
    {
      "episode_num": 5,
      "total_reward": 924.6999999999867,
      "episode_length": 753,
      "avg_reward_per_step": 1.2280212483399557,
      "max_reward_step": 7.042857142857144,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.044739771634340286,
      "steering_std": 0.8500720858573914,
      "throttle_mean": 0.5805009007453918,
      "brake_mean": -0.429680198431015
    },
    {
      "episode_num": 6,
      "total_reward": 699.1803278688317,
      "episode_length": 1000,
      "avg_reward_per_step": 0.6991803278688317,
      "max_reward_step": 8.09672131147541,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.05994207039475441,
      "steering_std": 0.8269813656806946,
      "throttle_mean": 0.5698035955429077,
      "brake_mean": -0.455434650182724
    },
    {
      "episode_num": 7,
      "total_reward": 551.0263929618626,
      "episode_length": 1000,
      "avg_reward_per_step": 0.5510263929618626,
      "max_reward_step": 5.765102639296202,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": 0.013468959368765354,
      "steering_std": 0.9535665512084961,
      "throttle_mean": 0.513679563999176,
      "brake_mean": -0.5452544093132019
    },
    {
      "episode_num": 8,
      "total_reward": 889.1696750902413,
      "episode_length": 1000,
      "avg_reward_per_step": 0.8891696750902413,
      "max_reward_step": 7.120216606498197,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.08500200510025024,
      "steering_std": 0.9693530201911926,
      "throttle_mean": 0.5541543364524841,
      "brake_mean": -0.3717656433582306
    },
    {
      "episode_num": 9,
      "total_reward": 919.1999999999883,
      "episode_length": 808,
      "avg_reward_per_step": 1.137623762376223,
      "max_reward_step": 6.457377049180328,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.11451787501573563,
      "steering_std": 1.078415870666504,
      "throttle_mean": 0.7224500179290771,
      "brake_mean": -0.3969821035861969
    },
    {
      "episode_num": 10,
      "total_reward": 929.9999999999897,
      "episode_length": 700,
      "avg_reward_per_step": 1.3285714285714139,
      "max_reward_step": 7.068458781362008,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.02406211942434311,
      "steering_std": 0.9660767912864685,
      "throttle_mean": 0.5503872632980347,
      "brake_mean": -0.3902991712093353
    },
    {
      "episode_num": 11,
      "total_reward": 183.81609195401143,
      "episode_length": 841,
      "avg_reward_per_step": 0.2185684803258162,
      "max_reward_step": 5.647126436781633,
      "min_reward_step": -100.0,
      "steering_mean": 0.0015551627147942781,
      "steering_std": 1.0344551801681519,
      "throttle_mean": 0.3410806655883789,
      "brake_mean": -0.6880074143409729
    },
    {
      "episode_num": 12,
      "total_reward": 932.2999999999882,
      "episode_length": 677,
      "avg_reward_per_step": 1.3771048744460683,
      "max_reward_step": 7.172727272727286,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.05085701867938042,
      "steering_std": 0.8615133762359619,
      "throttle_mean": 0.7154157757759094,
      "brake_mean": -0.41061216592788696
    },
    {
      "episode_num": 13,
      "total_reward": 625.2396166134112,
      "episode_length": 1000,
      "avg_reward_per_step": 0.6252396166134112,
      "max_reward_step": 6.289776357827477,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.11551830917596817,
      "steering_std": 0.8584449887275696,
      "throttle_mean": 0.47192302346229553,
      "brake_mean": -0.4462408125400543
    },
    {
      "episode_num": 14,
      "total_reward": 926.0999999999848,
      "episode_length": 739,
      "avg_reward_per_step": 1.25317997293638,
      "max_reward_step": 6.942253521126761,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.06659501045942307,
      "steering_std": 0.924583375453949,
      "throttle_mean": 0.569673478603363,
      "brake_mean": -0.43447253108024597
    },
    {
      "episode_num": 15,
      "total_reward": 927.999999999989,
      "episode_length": 720,
      "avg_reward_per_step": 1.2888888888888737,
      "max_reward_step": 6.868641114982578,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.041688475757837296,
      "steering_std": 0.984627366065979,
      "throttle_mean": 0.7854776978492737,
      "brake_mean": -0.43074196577072144
    },
    {
      "episode_num": 16,
      "total_reward": 860.3960396039474,
      "episode_length": 1000,
      "avg_reward_per_step": 0.8603960396039474,
      "max_reward_step": 6.500660066006617,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.06954430043697357,
      "steering_std": 0.9456451535224915,
      "throttle_mean": 0.6861933469772339,
      "brake_mean": -0.43858203291893005
    },
    {
      "episode_num": 17,
      "total_reward": 932.2999999999945,
      "episode_length": 677,
      "avg_reward_per_step": 1.3771048744460777,
      "max_reward_step": 7.805138339920949,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.1256120800971985,
      "steering_std": 0.8698526620864868,
      "throttle_mean": 0.6144551634788513,
      "brake_mean": -0.4118947982788086
    },
    {
      "episode_num": 18,
      "total_reward": 866.3299663299465,
      "episode_length": 1000,
      "avg_reward_per_step": 0.8663299663299465,
      "max_reward_step": 6.634006734006739,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.06325085461139679,
      "steering_std": 0.9533722400665283,
      "throttle_mean": 0.5372390151023865,
      "brake_mean": -0.4320227801799774
    },
    {
      "episode_num": 19,
      "total_reward": 89.3687707641248,
      "episode_length": 1000,
      "avg_reward_per_step": 0.0893687707641248,
      "max_reward_step": 6.544518272425279,
      "min_reward_step": -0.10000000000000142,
      "steering_mean": -0.12299918383359909,
      "steering_std": 0.5657580494880676,
      "throttle_mean": 0.7462281584739685,
      "brake_mean": -0.4231824278831482
    },
    {
      "episode_num": 20,
      "total_reward": 814.8148148147961,
      "episode_length": 1000,
      "avg_reward_per_step": 0.8148148148147961,
      "max_reward_step": 7.307407407407425,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.0621844157576561,
      "steering_std": 0.8898424506187439,
      "throttle_mean": 0.5642554759979248,
      "brake_mean": -0.3948657214641571
    },
    {
      "episode_num": 21,
      "total_reward": 920.5999999999925,
      "episode_length": 794,
      "avg_reward_per_step": 1.1594458438287059,
      "max_reward_step": 6.820415224913518,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.060826145112514496,
      "steering_std": 0.9720040559768677,
      "throttle_mean": 0.6337535381317139,
      "brake_mean": -0.409928560256958
    },
    {
      "episode_num": 22,
      "total_reward": 893.8080495355912,
      "episode_length": 1000,
      "avg_reward_per_step": 0.8938080495355912,
      "max_reward_step": 6.091950464396291,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.11059974879026413,
      "steering_std": 1.0167787075042725,
      "throttle_mean": 0.6809927821159363,
      "brake_mean": -0.3948917090892792
    },
    {
      "episode_num": 23,
      "total_reward": 872.0496894409746,
      "episode_length": 1000,
      "avg_reward_per_step": 0.8720496894409746,
      "max_reward_step": 6.111180124223603,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.10091347247362137,
      "steering_std": 0.9451965689659119,
      "throttle_mean": 0.5553250908851624,
      "brake_mean": -0.42013275623321533
    },
    {
      "episode_num": 24,
      "total_reward": 829.6874999999832,
      "episode_length": 1000,
      "avg_reward_per_step": 0.8296874999999831,
      "max_reward_step": 7.7125,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.05045948922634125,
      "steering_std": 0.8333985805511475,
      "throttle_mean": 0.388736754655838,
      "brake_mean": -0.4740554392337799
    },
    {
      "episode_num": 25,
      "total_reward": 490.163934426217,
      "episode_length": 1000,
      "avg_reward_per_step": 0.490163934426217,
      "max_reward_step": 5.364480874316968,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.0343596413731575,
      "steering_std": 1.012678623199463,
      "throttle_mean": 0.5679727792739868,
      "brake_mean": -0.550828218460083
    },
    {
      "episode_num": 26,
      "total_reward": 358.9041095890252,
      "episode_length": 1000,
      "avg_reward_per_step": 0.3589041095890252,
      "max_reward_step": 6.749315068493161,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.15411201119422913,
      "steering_std": 0.6784210801124573,
      "throttle_mean": 0.5587390661239624,
      "brake_mean": -0.3495943248271942
    },
    {
      "episode_num": 27,
      "total_reward": 717.8571428571238,
      "episode_length": 1000,
      "avg_reward_per_step": 0.7178571428571238,
      "max_reward_step": 7.042857142857144,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.07313789427280426,
      "steering_std": 0.8676076531410217,
      "throttle_mean": 0.5378196835517883,
      "brake_mean": -0.4483170211315155
    },
    {
      "episode_num": 28,
      "total_reward": 892.4812030074974,
      "episode_length": 1000,
      "avg_reward_per_step": 0.8924812030074973,
      "max_reward_step": 7.418796992481219,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.08772757649421692,
      "steering_std": 0.9599834680557251,
      "throttle_mean": 0.6676469445228577,
      "brake_mean": -0.3555219769477844
    },
    {
      "episode_num": 29,
      "total_reward": 932.999999999987,
      "episode_length": 670,
      "avg_reward_per_step": 1.3925373134328165,
      "max_reward_step": 7.094244604316547,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": 0.010448111221194267,
      "steering_std": 0.8994441628456116,
      "throttle_mean": 0.6854778528213501,
      "brake_mean": -0.4338330626487732
    }
  ]
}