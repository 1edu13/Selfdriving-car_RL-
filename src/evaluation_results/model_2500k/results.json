{
  "model": "model_2500k",
  "evaluation_date": "2026-01-14T11:44:20.572107",
  "num_episodes": 30,
  "seed": 100,
  "device": "cuda",
  "statistics": {
    "mean_reward": 845.9034730943181,
    "std_reward": 144.28493363838103,
    "min_reward": 259.60372670807175,
    "max_reward": 935.9999999999865,
    "median_reward": 905.2499999999907,
    "mean_length": 746.1666666666666,
    "std_length": 171.4897632189423,
    "win_rate": 53.333333333333336,
    "success_rate": 100.0,
    "steering_mean": -0.05081878754620751,
    "throttle_mean": -0.33447242329518,
    "brake_mean": -1.2727962692578634
  },
  "episodes": [
    {
      "episode_num": 0,
      "total_reward": 932.0999999999894,
      "episode_length": 679,
      "avg_reward_per_step": 1.3727540500736222,
      "max_reward_step": 7.307407407407408,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.0911526158452034,
      "steering_std": 1.41538405418396,
      "throttle_mean": -0.22400502860546112,
      "brake_mean": -1.173927664756775
    },
    {
      "episode_num": 1,
      "total_reward": 849.998679867974,
      "episode_length": 1000,
      "avg_reward_per_step": 0.8499986798679741,
      "max_reward_step": 6.500660066006617,
      "min_reward_step": -0.9000000000000228,
      "steering_mean": -0.07697610557079315,
      "steering_std": 1.6676971912384033,
      "throttle_mean": -0.45388147234916687,
      "brake_mean": -1.3613983392715454
    },
    {
      "episode_num": 2,
      "total_reward": 806.4946236559015,
      "episode_length": 1000,
      "avg_reward_per_step": 0.8064946236559015,
      "max_reward_step": 7.068458781362008,
      "min_reward_step": -0.9000000000000228,
      "steering_mean": -0.09147178381681442,
      "steering_std": 1.598615288734436,
      "throttle_mean": -0.43952780961990356,
      "brake_mean": -1.0930962562561035
    },
    {
      "episode_num": 3,
      "total_reward": 920.3999999999867,
      "episode_length": 692,
      "avg_reward_per_step": 1.330057803468189,
      "max_reward_step": 7.094244604316547,
      "min_reward_step": -0.9000000000000228,
      "steering_mean": -0.07430955022573471,
      "steering_std": 1.6973276138305664,
      "throttle_mean": -0.28238585591316223,
      "brake_mean": -1.2935439348220825
    },
    {
      "episode_num": 4,
      "total_reward": 902.1999999999873,
      "episode_length": 738,
      "avg_reward_per_step": 1.2224932249322322,
      "max_reward_step": 6.611409395973155,
      "min_reward_step": -0.9000000000000228,
      "steering_mean": -0.12362641841173172,
      "steering_std": 1.4707351922988892,
      "throttle_mean": -0.3930641710758209,
      "brake_mean": -1.2256711721420288
    },
    {
      "episode_num": 5,
      "total_reward": 919.2999999999878,
      "episode_length": 687,
      "avg_reward_per_step": 1.3381368267830973,
      "max_reward_step": 7.042857142857144,
      "min_reward_step": -0.9000000000000228,
      "steering_mean": -0.08538354933261871,
      "steering_std": 1.3784854412078857,
      "throttle_mean": -0.3702845871448517,
      "brake_mean": -1.1421257257461548
    },
    {
      "episode_num": 6,
      "total_reward": 656.7983606557312,
      "episode_length": 493,
      "avg_reward_per_step": 1.33224819605625,
      "max_reward_step": 8.09672131147541,
      "min_reward_step": -0.9000000000000228,
      "steering_mean": -0.09017223119735718,
      "steering_std": 1.5181447267532349,
      "throttle_mean": -0.8310983777046204,
      "brake_mean": -1.176085352897644
    },
    {
      "episode_num": 7,
      "total_reward": 896.699999999979,
      "episode_length": 913,
      "avg_reward_per_step": 0.9821467688937339,
      "max_reward_step": 5.765102639296188,
      "min_reward_step": -0.9000000000000228,
      "steering_mean": -0.020614836364984512,
      "steering_std": 1.6988435983657837,
      "throttle_mean": 0.038385555148124695,
      "brake_mean": -1.2903714179992676
    },
    {
      "episode_num": 8,
      "total_reward": 926.7999999999959,
      "episode_length": 684,
      "avg_reward_per_step": 1.354970760233912,
      "max_reward_step": 7.120216606498195,
      "min_reward_step": -0.9000000000000228,
      "steering_mean": -0.11647511273622513,
      "steering_std": 1.8726943731307983,
      "throttle_mean": -0.27532798051834106,
      "brake_mean": -1.3084335327148438
    },
    {
      "episode_num": 9,
      "total_reward": 920.2999999999895,
      "episode_length": 757,
      "avg_reward_per_step": 1.2157199471598277,
      "max_reward_step": 6.457377049180328,
      "min_reward_step": -0.9000000000000228,
      "steering_mean": 0.052075475454330444,
      "steering_std": 1.6669129133224487,
      "throttle_mean": -0.40533748269081116,
      "brake_mean": -1.2865303754806519
    },
    {
      "episode_num": 10,
      "total_reward": 931.8999999999897,
      "episode_length": 681,
      "avg_reward_per_step": 1.3684287812040965,
      "max_reward_step": 7.068458781362008,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.009281049482524395,
      "steering_std": 1.7022099494934082,
      "throttle_mean": -0.2305031418800354,
      "brake_mean": -1.2552496194839478
    },
    {
      "episode_num": 11,
      "total_reward": 887.0528735632049,
      "episode_length": 1000,
      "avg_reward_per_step": 0.887052873563205,
      "max_reward_step": 5.647126436781609,
      "min_reward_step": -0.9000000000000228,
      "steering_mean": -0.04085357487201691,
      "steering_std": 1.7328871488571167,
      "throttle_mean": -0.26342159509658813,
      "brake_mean": -1.2989654541015625
    },
    {
      "episode_num": 12,
      "total_reward": 935.3999999999885,
      "episode_length": 646,
      "avg_reward_per_step": 1.4479876160990535,
      "max_reward_step": 7.172727272727273,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.0322895422577858,
      "steering_std": 1.5060935020446777,
      "throttle_mean": -0.43212777376174927,
      "brake_mean": -1.332741141319275
    },
    {
      "episode_num": 13,
      "total_reward": 914.8999999999911,
      "episode_length": 835,
      "avg_reward_per_step": 1.0956886227544804,
      "max_reward_step": 6.289776357827477,
      "min_reward_step": -0.9000000000000228,
      "steering_mean": -0.1099339947104454,
      "steering_std": 1.5334888696670532,
      "throttle_mean": -0.48727068305015564,
      "brake_mean": -1.2701672315597534
    },
    {
      "episode_num": 14,
      "total_reward": 928.3999999999859,
      "episode_length": 668,
      "avg_reward_per_step": 1.389820359281416,
      "max_reward_step": 6.942253521126761,
      "min_reward_step": -0.9000000000000228,
      "steering_mean": -0.08731899410486221,
      "steering_std": 1.6291441917419434,
      "throttle_mean": -0.44805625081062317,
      "brake_mean": -1.308884620666504
    },
    {
      "episode_num": 15,
      "total_reward": 924.0999999999899,
      "episode_length": 671,
      "avg_reward_per_step": 1.3771982116244261,
      "max_reward_step": 6.86864111498258,
      "min_reward_step": -0.9000000000000015,
      "steering_mean": -0.08797753602266312,
      "steering_std": 1.6428993940353394,
      "throttle_mean": -0.5220547318458557,
      "brake_mean": -1.3058305978775024
    },
    {
      "episode_num": 16,
      "total_reward": 860.3986798679753,
      "episode_length": 1000,
      "avg_reward_per_step": 0.8603986798679752,
      "max_reward_step": 6.500660066006601,
      "min_reward_step": -0.9000000000000228,
      "steering_mean": -0.07776711881160736,
      "steering_std": 1.7009923458099365,
      "throttle_mean": -0.44521862268447876,
      "brake_mean": -1.3768322467803955
    },
    {
      "episode_num": 17,
      "total_reward": 731.2446640316182,
      "episode_length": 603,
      "avg_reward_per_step": 1.21267771812872,
      "max_reward_step": 7.805138339920949,
      "min_reward_step": -0.9000000000000228,
      "steering_mean": 0.11040616035461426,
      "steering_std": 1.4382286071777344,
      "throttle_mean": -0.49205711483955383,
      "brake_mean": -1.21309494972229
    },
    {
      "episode_num": 18,
      "total_reward": 541.4966329966279,
      "episode_length": 507,
      "avg_reward_per_step": 1.0680406962458144,
      "max_reward_step": 6.634006734006735,
      "min_reward_step": -0.9000000000000228,
      "steering_mean": 0.039796099066734314,
      "steering_std": 1.6877245903015137,
      "throttle_mean": -0.3228088617324829,
      "brake_mean": -1.2493664026260376
    },
    {
      "episode_num": 19,
      "total_reward": 899.9999999999939,
      "episode_length": 816,
      "avg_reward_per_step": 1.1029411764705808,
      "max_reward_step": 6.5445182724252495,
      "min_reward_step": -0.9000000000000228,
      "steering_mean": -0.11522315442562103,
      "steering_std": 1.5211868286132812,
      "throttle_mean": -0.4349817633628845,
      "brake_mean": -1.1311779022216797
    },
    {
      "episode_num": 20,
      "total_reward": 773.422222222206,
      "episode_length": 1000,
      "avg_reward_per_step": 0.7734222222222059,
      "max_reward_step": 7.307407407407408,
      "min_reward_step": -0.9000000000000228,
      "steering_mean": -0.1604081392288208,
      "steering_std": 1.513246774673462,
      "throttle_mean": -0.5773994326591492,
      "brake_mean": -1.3850144147872925
    },
    {
      "episode_num": 21,
      "total_reward": 908.2999999999939,
      "episode_length": 717,
      "avg_reward_per_step": 1.2668061366806052,
      "max_reward_step": 6.8204152249134955,
      "min_reward_step": -0.9000000000000228,
      "steering_mean": -0.0972433015704155,
      "steering_std": 1.7382190227508545,
      "throttle_mean": -0.24765034019947052,
      "brake_mean": -1.3739732503890991
    },
    {
      "episode_num": 22,
      "total_reward": 885.9120743033928,
      "episode_length": 1000,
      "avg_reward_per_step": 0.8859120743033928,
      "max_reward_step": 6.091950464396286,
      "min_reward_step": -0.9000000000000228,
      "steering_mean": -0.15978264808654785,
      "steering_std": 1.6222953796386719,
      "throttle_mean": 0.11454953253269196,
      "brake_mean": -1.421112298965454
    },
    {
      "episode_num": 23,
      "total_reward": 259.60372670807175,
      "episode_length": 350,
      "avg_reward_per_step": 0.7417249334516336,
      "max_reward_step": 6.111180124223603,
      "min_reward_step": -0.9000000000000228,
      "steering_mean": 0.3993557393550873,
      "steering_std": 1.9777746200561523,
      "throttle_mean": 0.49449777603149414,
      "brake_mean": -1.262037992477417
    },
    {
      "episode_num": 24,
      "total_reward": 930.4999999999918,
      "episode_length": 631,
      "avg_reward_per_step": 1.4746434231378633,
      "max_reward_step": 7.7125,
      "min_reward_step": -0.9000000000000228,
      "steering_mean": -0.16516315937042236,
      "steering_std": 1.3849765062332153,
      "throttle_mean": -0.52005535364151,
      "brake_mean": -1.2178066968917847
    },
    {
      "episode_num": 25,
      "total_reward": 837.53879781419,
      "episode_length": 1000,
      "avg_reward_per_step": 0.83753879781419,
      "max_reward_step": 5.36448087431694,
      "min_reward_step": -0.9000000000000228,
      "steering_mean": -0.1492183804512024,
      "steering_std": 1.930346965789795,
      "throttle_mean": -0.4420066773891449,
      "brake_mean": -1.2761356830596924
    },
    {
      "episode_num": 26,
      "total_reward": 929.2999999999854,
      "episode_length": 699,
      "avg_reward_per_step": 1.3294706723891065,
      "max_reward_step": 6.749315068493151,
      "min_reward_step": -0.9000000000000228,
      "steering_mean": 0.02277572825551033,
      "steering_std": 1.5675228834152222,
      "throttle_mean": -0.21504220366477966,
      "brake_mean": -1.3285306692123413
    },
    {
      "episode_num": 27,
      "total_reward": 695.642857142849,
      "episode_length": 627,
      "avg_reward_per_step": 1.1094782410571755,
      "max_reward_step": 7.042857142857144,
      "min_reward_step": -0.9000000000000228,
      "steering_mean": -0.04136800765991211,
      "steering_std": 1.675750494003296,
      "throttle_mean": -0.30945613980293274,
      "brake_mean": -1.069653868675232
    },
    {
      "episode_num": 28,
      "total_reward": 935.9999999999865,
      "episode_length": 640,
      "avg_reward_per_step": 1.4624999999999788,
      "max_reward_step": 7.418796992481203,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": 0.015589317306876183,
      "steering_std": 1.636917233467102,
      "throttle_mean": -0.22824306786060333,
      "brake_mean": -1.387315034866333
    },
    {
      "episode_num": 29,
      "total_reward": 934.8999999999874,
      "episode_length": 651,
      "avg_reward_per_step": 1.4360983102918392,
      "max_reward_step": 7.094244604316547,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.060551341623067856,
      "steering_std": 1.6476390361785889,
      "throttle_mean": -0.3883390426635742,
      "brake_mean": -1.36881422996521
    }
  ]
}