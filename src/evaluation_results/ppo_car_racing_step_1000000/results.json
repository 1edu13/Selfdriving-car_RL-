{
  "model": "ppo_car_racing_step_1064960",
  "evaluation_date": "2026-01-11T19:01:48.927203",
  "num_episodes": 30,
  "seed": 100,
  "device": "cuda",
  "statistics": {
    "mean_reward": 603.8156021680254,
    "std_reward": 192.06684930768319,
    "min_reward": 176.36363636363916,
    "max_reward": 884.4720496894217,
    "median_reward": 608.5936229999179,
    "mean_length": 1000.0,
    "std_length": 0.0,
    "win_rate": 0.0,
    "success_rate": 100.0,
    "steering_mean": 0.08298237406027814,
    "throttle_mean": 0.49606723710894585,
    "brake_mean": -0.6529010824859143
  },
  "episodes": [
    {
      "episode_num": 0,
      "total_reward": 588.8888888888716,
      "episode_length": 1000,
      "avg_reward_per_step": 0.5888888888888716,
      "max_reward_step": 7.307407407407408,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.00498577393591404,
      "steering_std": 1.1099199056625366,
      "throttle_mean": 0.4146227240562439,
      "brake_mean": -0.6855582594871521
    },
    {
      "episode_num": 1,
      "total_reward": 622.7722772277084,
      "episode_length": 1000,
      "avg_reward_per_step": 0.6227722772277084,
      "max_reward_step": 6.500660066006617,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": 0.3098428249359131,
      "steering_std": 1.3325566053390503,
      "throttle_mean": 0.341702938079834,
      "brake_mean": -0.7640109062194824
    },
    {
      "episode_num": 2,
      "total_reward": 778.1362007168347,
      "episode_length": 1000,
      "avg_reward_per_step": 0.7781362007168346,
      "max_reward_step": 7.068458781362008,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": 0.07355178147554398,
      "steering_std": 1.4811108112335205,
      "throttle_mean": 0.5407886505126953,
      "brake_mean": -0.62067711353302
    },
    {
      "episode_num": 3,
      "total_reward": 615.8273381294772,
      "episode_length": 1000,
      "avg_reward_per_step": 0.6158273381294772,
      "max_reward_step": 7.094244604316547,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": 0.17122551798820496,
      "steering_std": 1.2003848552703857,
      "throttle_mean": 0.3423535227775574,
      "brake_mean": -0.7494106888771057
    },
    {
      "episode_num": 4,
      "total_reward": 614.7651006711305,
      "episode_length": 1000,
      "avg_reward_per_step": 0.6147651006711305,
      "max_reward_step": 6.611409395973155,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.011454744264483452,
      "steering_std": 1.2266584634780884,
      "throttle_mean": 0.5260738134384155,
      "brake_mean": -0.6919502019882202
    },
    {
      "episode_num": 5,
      "total_reward": 599.999999999983,
      "episode_length": 1000,
      "avg_reward_per_step": 0.599999999999983,
      "max_reward_step": 7.042857142857144,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": 0.12838506698608398,
      "steering_std": 1.0940444469451904,
      "throttle_mean": 0.4417650103569031,
      "brake_mean": -0.6841424703598022
    },
    {
      "episode_num": 6,
      "total_reward": 842.6229508196503,
      "episode_length": 1000,
      "avg_reward_per_step": 0.8426229508196503,
      "max_reward_step": 8.09672131147541,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.4311376214027405,
      "steering_std": 1.2846375703811646,
      "throttle_mean": 0.30982619524002075,
      "brake_mean": -0.5246163606643677
    },
    {
      "episode_num": 7,
      "total_reward": 460.11730205277377,
      "episode_length": 1000,
      "avg_reward_per_step": 0.4601173020527738,
      "max_reward_step": 5.765102639296188,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": 0.5355410575866699,
      "steering_std": 1.3688050508499146,
      "throttle_mean": 0.5397925972938538,
      "brake_mean": -0.6381602883338928
    },
    {
      "episode_num": 8,
      "total_reward": 853.0685920577492,
      "episode_length": 1000,
      "avg_reward_per_step": 0.8530685920577492,
      "max_reward_step": 7.120216606498195,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.03219950944185257,
      "steering_std": 1.4627184867858887,
      "throttle_mean": 0.6076694130897522,
      "brake_mean": -0.7908555269241333
    },
    {
      "episode_num": 9,
      "total_reward": 575.4098360655577,
      "episode_length": 1000,
      "avg_reward_per_step": 0.5754098360655576,
      "max_reward_step": 6.457377049180328,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": 0.22907991707324982,
      "steering_std": 1.3930604457855225,
      "throttle_mean": 0.6209574937820435,
      "brake_mean": -0.694265604019165
    },
    {
      "episode_num": 10,
      "total_reward": 871.3261648745346,
      "episode_length": 1000,
      "avg_reward_per_step": 0.8713261648745346,
      "max_reward_step": 7.068458781362008,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": 0.09031122177839279,
      "steering_std": 1.174702525138855,
      "throttle_mean": 0.37804388999938965,
      "brake_mean": -0.7705987691879272
    },
    {
      "episode_num": 11,
      "total_reward": 241.9540229884946,
      "episode_length": 1000,
      "avg_reward_per_step": 0.24195402298849458,
      "max_reward_step": 5.647126436781609,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": 1.6627800464630127,
      "steering_std": 1.5467473268508911,
      "throttle_mean": 1.4245432615280151,
      "brake_mean": -0.4820527136325836
    },
    {
      "episode_num": 12,
      "total_reward": 176.36363636363916,
      "episode_length": 1000,
      "avg_reward_per_step": 0.17636363636363916,
      "max_reward_step": 7.172727272727273,
      "min_reward_step": -0.10000000000000142,
      "steering_mean": 0.23306463658809662,
      "steering_std": 1.405417799949646,
      "throttle_mean": 0.3840482234954834,
      "brake_mean": -0.774091899394989
    },
    {
      "episode_num": 13,
      "total_reward": 545.3674121405611,
      "episode_length": 1000,
      "avg_reward_per_step": 0.5453674121405611,
      "max_reward_step": 6.289776357827477,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": 0.16209161281585693,
      "steering_std": 1.3488941192626953,
      "throttle_mean": 0.5395446419715881,
      "brake_mean": -0.7287732362747192
    },
    {
      "episode_num": 14,
      "total_reward": 495.07042253519455,
      "episode_length": 1000,
      "avg_reward_per_step": 0.49507042253519457,
      "max_reward_step": 6.942253521126761,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.8133476376533508,
      "steering_std": 0.9745580554008484,
      "throttle_mean": 0.37004554271698,
      "brake_mean": -0.4289456605911255
    },
    {
      "episode_num": 15,
      "total_reward": 788.5017421602612,
      "episode_length": 1000,
      "avg_reward_per_step": 0.7885017421602611,
      "max_reward_step": 6.868641114982578,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": 0.1354217380285263,
      "steering_std": 1.2513761520385742,
      "throttle_mean": 0.43670788407325745,
      "brake_mean": -0.7063758969306946
    },
    {
      "episode_num": 16,
      "total_reward": 873.5973597359605,
      "episode_length": 1000,
      "avg_reward_per_step": 0.8735973597359605,
      "max_reward_step": 6.500660066006617,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": 0.02549148164689541,
      "steering_std": 1.2201054096221924,
      "throttle_mean": 0.6474769115447998,
      "brake_mean": -0.7347440123558044
    },
    {
      "episode_num": 17,
      "total_reward": 540.3162055335827,
      "episode_length": 1000,
      "avg_reward_per_step": 0.5403162055335826,
      "max_reward_step": 7.805138339920949,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": 0.07091076672077179,
      "steering_std": 1.2609385251998901,
      "throttle_mean": 0.6523085236549377,
      "brake_mean": -0.7267426252365112
    },
    {
      "episode_num": 18,
      "total_reward": 368.01346801345056,
      "episode_length": 1000,
      "avg_reward_per_step": 0.3680134680134506,
      "max_reward_step": 6.634006734006735,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.3504493534564972,
      "steering_std": 1.0117560625076294,
      "throttle_mean": 0.23656216263771057,
      "brake_mean": -0.2334350347518921
    },
    {
      "episode_num": 19,
      "total_reward": 747.1760797342068,
      "episode_length": 1000,
      "avg_reward_per_step": 0.7471760797342069,
      "max_reward_step": 6.5445182724252495,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": 0.29739439487457275,
      "steering_std": 1.2965731620788574,
      "throttle_mean": 0.6995159983634949,
      "brake_mean": -0.6611961126327515
    },
    {
      "episode_num": 20,
      "total_reward": 785.1851851851662,
      "episode_length": 1000,
      "avg_reward_per_step": 0.7851851851851662,
      "max_reward_step": 7.307407407407408,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.042454250156879425,
      "steering_std": 1.344277262687683,
      "throttle_mean": 0.4508856236934662,
      "brake_mean": -0.6911724209785461
    },
    {
      "episode_num": 21,
      "total_reward": 602.4221453287051,
      "episode_length": 1000,
      "avg_reward_per_step": 0.6024221453287052,
      "max_reward_step": 6.820415224913496,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": 0.0925937294960022,
      "steering_std": 1.1738704442977905,
      "throttle_mean": 0.511056661605835,
      "brake_mean": -0.6792569160461426
    },
    {
      "episode_num": 22,
      "total_reward": 228.17337461299533,
      "episode_length": 1000,
      "avg_reward_per_step": 0.22817337461299533,
      "max_reward_step": 6.091950464396286,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.6071581840515137,
      "steering_std": 1.1078063249588013,
      "throttle_mean": 0.07524523884057999,
      "brake_mean": -0.07915288954973221
    },
    {
      "episode_num": 23,
      "total_reward": 884.4720496894217,
      "episode_length": 1000,
      "avg_reward_per_step": 0.8844720496894217,
      "max_reward_step": 6.111180124223603,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.10510673373937607,
      "steering_std": 1.26016366481781,
      "throttle_mean": 0.580049991607666,
      "brake_mean": -0.7520793676376343
    },
    {
      "episode_num": 24,
      "total_reward": 427.3437499999906,
      "episode_length": 1000,
      "avg_reward_per_step": 0.42734374999999064,
      "max_reward_step": 7.7125,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": 0.3190518915653229,
      "steering_std": 1.479705810546875,
      "throttle_mean": 0.456360787153244,
      "brake_mean": -0.6594749689102173
    },
    {
      "episode_num": 25,
      "total_reward": 451.9125683060077,
      "episode_length": 1000,
      "avg_reward_per_step": 0.4519125683060077,
      "max_reward_step": 5.36448087431694,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": 0.028109969571232796,
      "steering_std": 1.3945924043655396,
      "throttle_mean": 0.5093754529953003,
      "brake_mean": -0.7931774854660034
    },
    {
      "episode_num": 26,
      "total_reward": 619.1780821917635,
      "episode_length": 1000,
      "avg_reward_per_step": 0.6191780821917634,
      "max_reward_step": 6.749315068493161,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": 0.09235459566116333,
      "steering_std": 1.2313112020492554,
      "throttle_mean": 0.5396905541419983,
      "brake_mean": -0.7913017868995667
    },
    {
      "episode_num": 27,
      "total_reward": 496.42857142855314,
      "episode_length": 1000,
      "avg_reward_per_step": 0.4964285714285531,
      "max_reward_step": 7.042857142857144,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": 0.14247122406959534,
      "steering_std": 1.3116625547409058,
      "throttle_mean": 0.3646249771118164,
      "brake_mean": -0.5467873811721802
    },
    {
      "episode_num": 28,
      "total_reward": 764.6616541353177,
      "episode_length": 1000,
      "avg_reward_per_step": 0.7646616541353177,
      "max_reward_step": 7.418796992481203,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": 0.08384616672992706,
      "steering_std": 1.40088951587677,
      "throttle_mean": 0.6341937780380249,
      "brake_mean": -0.7425773739814758
    },
    {
      "episode_num": 29,
      "total_reward": 655.3956834532182,
      "episode_length": 1000,
      "avg_reward_per_step": 0.6553956834532182,
      "max_reward_step": 7.09424460431655,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": 0.004245387855917215,
      "steering_std": 1.0317013263702393,
      "throttle_mean": 0.30618464946746826,
      "brake_mean": -0.7614485025405884
    }
  ]
}