{
  "model": "ppo_car_racing_step_491520",
  "evaluation_date": "2026-01-11T18:54:13.049165",
  "num_episodes": 30,
  "seed": 100,
  "device": "cuda",
  "statistics": {
    "mean_reward": 252.21803578980675,
    "std_reward": 171.68901365694444,
    "min_reward": 4.693140794224906,
    "max_reward": 721.917808219159,
    "median_reward": 273.8963130891191,
    "mean_length": 1000.0,
    "std_length": 0.0,
    "win_rate": 0.0,
    "success_rate": 100.0,
    "steering_mean": 0.33884679336721696,
    "throttle_mean": 0.21865386925637723,
    "brake_mean": -0.09387142527848483
  },
  "episodes": [
    {
      "episode_num": 0,
      "total_reward": 48.148148148152224,
      "episode_length": 1000,
      "avg_reward_per_step": 0.04814814814815222,
      "max_reward_step": 7.307407407407408,
      "min_reward_step": -0.10000000000000142,
      "steering_mean": 0.65949946641922,
      "steering_std": 1.4405137300491333,
      "throttle_mean": 0.4880853295326233,
      "brake_mean": 0.1774880439043045
    },
    {
      "episode_num": 1,
      "total_reward": 190.42904290429203,
      "episode_length": 1000,
      "avg_reward_per_step": 0.19042904290429202,
      "max_reward_step": 6.500660066006601,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": 0.8525957465171814,
      "steering_std": 1.0933878421783447,
      "throttle_mean": 0.3336813449859619,
      "brake_mean": -0.17899669706821442
    },
    {
      "episode_num": 2,
      "total_reward": 79.21146953405525,
      "episode_length": 1000,
      "avg_reward_per_step": 0.07921146953405525,
      "max_reward_step": 7.068458781362008,
      "min_reward_step": -0.10000000000000142,
      "steering_mean": 1.1362202167510986,
      "steering_std": 1.536974310874939,
      "throttle_mean": 1.0522712469100952,
      "brake_mean": 0.3853963315486908
    },
    {
      "episode_num": 3,
      "total_reward": 457.55395683451377,
      "episode_length": 1000,
      "avg_reward_per_step": 0.4575539568345138,
      "max_reward_step": 7.094244604316547,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": 1.439010739326477,
      "steering_std": 1.4233148097991943,
      "throttle_mean": 1.3609739542007446,
      "brake_mean": 0.1943208873271942
    },
    {
      "episode_num": 4,
      "total_reward": 20.80536912751886,
      "episode_length": 1000,
      "avg_reward_per_step": 0.020805369127518857,
      "max_reward_step": 6.611409395973169,
      "min_reward_step": -0.10000000000000142,
      "steering_mean": -5.8044209480285645,
      "steering_std": 6.207092761993408,
      "throttle_mean": -4.320082664489746,
      "brake_mean": 1.7848927974700928
    },
    {
      "episode_num": 5,
      "total_reward": 64.28571428571942,
      "episode_length": 1000,
      "avg_reward_per_step": 0.06428571428571943,
      "max_reward_step": 7.042857142857144,
      "min_reward_step": -0.10000000000000142,
      "steering_mean": 1.4483141899108887,
      "steering_std": 0.9869415163993835,
      "throttle_mean": -0.035284750163555145,
      "brake_mean": 0.07898901402950287
    },
    {
      "episode_num": 6,
      "total_reward": 391.80327868850577,
      "episode_length": 1000,
      "avg_reward_per_step": 0.3918032786885058,
      "max_reward_step": 8.09672131147541,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": 0.012577096931636333,
      "steering_std": 1.058016300201416,
      "throttle_mean": 0.6528010368347168,
      "brake_mean": -0.8135307431221008
    },
    {
      "episode_num": 7,
      "total_reward": 386.8035190615707,
      "episode_length": 1000,
      "avg_reward_per_step": 0.3868035190615707,
      "max_reward_step": 5.765102639296188,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.05226334556937218,
      "steering_std": 1.1922768354415894,
      "throttle_mean": 0.5784481167793274,
      "brake_mean": -0.8319048285484314
    },
    {
      "episode_num": 8,
      "total_reward": 4.693140794224906,
      "episode_length": 1000,
      "avg_reward_per_step": 0.004693140794224906,
      "max_reward_step": 7.120216606498195,
      "min_reward_step": -0.10000000000000142,
      "steering_mean": 1.0095123052597046,
      "steering_std": 0.6405177712440491,
      "throttle_mean": 0.10423450917005539,
      "brake_mean": 0.5680326223373413
    },
    {
      "episode_num": 9,
      "total_reward": 309.8360655737538,
      "episode_length": 1000,
      "avg_reward_per_step": 0.30983606557375376,
      "max_reward_step": 6.457377049180328,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": 0.32201242446899414,
      "steering_std": 1.347245454788208,
      "throttle_mean": 0.7348999977111816,
      "brake_mean": -0.33027201890945435
    },
    {
      "episode_num": 10,
      "total_reward": 229.74910394264245,
      "episode_length": 1000,
      "avg_reward_per_step": 0.22974910394264245,
      "max_reward_step": 7.068458781362008,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": 0.6703444719314575,
      "steering_std": 1.08934485912323,
      "throttle_mean": 0.39007723331451416,
      "brake_mean": -0.06462550163269043
    },
    {
      "episode_num": 11,
      "total_reward": 287.9310344827443,
      "episode_length": 1000,
      "avg_reward_per_step": 0.28793103448274426,
      "max_reward_step": 5.647126436781609,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": 0.39411500096321106,
      "steering_std": 1.088760495185852,
      "throttle_mean": 0.5689778327941895,
      "brake_mean": -0.5980139374732971
    },
    {
      "episode_num": 12,
      "total_reward": 329.0909090908913,
      "episode_length": 1000,
      "avg_reward_per_step": 0.3290909090908913,
      "max_reward_step": 7.172727272727273,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": 1.2523248195648193,
      "steering_std": 1.2907336950302124,
      "throttle_mean": 0.23909354209899902,
      "brake_mean": -0.06370527297258377
    },
    {
      "episode_num": 13,
      "total_reward": 53.354632587863826,
      "episode_length": 1000,
      "avg_reward_per_step": 0.053354632587863826,
      "max_reward_step": 6.289776357827477,
      "min_reward_step": -0.10000000000000142,
      "steering_mean": 0.9808728694915771,
      "steering_std": 0.9862359166145325,
      "throttle_mean": 0.188900426030159,
      "brake_mean": 0.13807427883148193
    },
    {
      "episode_num": 14,
      "total_reward": 301.40845070420914,
      "episode_length": 1000,
      "avg_reward_per_step": 0.30140845070420913,
      "max_reward_step": 6.942253521126761,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": 1.0721477270126343,
      "steering_std": 0.8125858306884766,
      "throttle_mean": 0.21323950588703156,
      "brake_mean": -0.021944457665085793
    },
    {
      "episode_num": 15,
      "total_reward": 182.22996515679944,
      "episode_length": 1000,
      "avg_reward_per_step": 0.18222996515679943,
      "max_reward_step": 10.352961672473867,
      "min_reward_step": -0.10000000000000142,
      "steering_mean": -0.986282229423523,
      "steering_std": 1.2585052251815796,
      "throttle_mean": 0.6181057095527649,
      "brake_mean": -0.8326615691184998
    },
    {
      "episode_num": 16,
      "total_reward": 213.5313531353087,
      "episode_length": 1000,
      "avg_reward_per_step": 0.21353135313530872,
      "max_reward_step": 6.500660066006617,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": 0.09778773784637451,
      "steering_std": 0.495477557182312,
      "throttle_mean": 0.11481127887964249,
      "brake_mean": 0.8253083229064941
    },
    {
      "episode_num": 17,
      "total_reward": 81.81818181818684,
      "episode_length": 1000,
      "avg_reward_per_step": 0.08181818181818684,
      "max_reward_step": 7.805138339920949,
      "min_reward_step": -0.10000000000000142,
      "steering_mean": 0.7863351702690125,
      "steering_std": 1.2251439094543457,
      "throttle_mean": 0.1298961490392685,
      "brake_mean": 0.023951079696416855
    },
    {
      "episode_num": 18,
      "total_reward": 428.61952861951056,
      "episode_length": 1000,
      "avg_reward_per_step": 0.4286195286195106,
      "max_reward_step": 6.634006734006735,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": 0.21190457046031952,
      "steering_std": 1.0563558340072632,
      "throttle_mean": 0.5190500020980835,
      "brake_mean": -0.64352947473526
    },
    {
      "episode_num": 19,
      "total_reward": 69.43521594684896,
      "episode_length": 1000,
      "avg_reward_per_step": 0.06943521594684895,
      "max_reward_step": 6.5445182724252495,
      "min_reward_step": -0.10000000000000142,
      "steering_mean": 1.151981234550476,
      "steering_std": 0.9386779069900513,
      "throttle_mean": 0.03334178775548935,
      "brake_mean": -0.14318548142910004
    },
    {
      "episode_num": 20,
      "total_reward": 374.07407407405657,
      "episode_length": 1000,
      "avg_reward_per_step": 0.3740740740740566,
      "max_reward_step": 7.307407407407408,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.029781538993120193,
      "steering_std": 1.2670650482177734,
      "throttle_mean": 0.2771095633506775,
      "brake_mean": -0.42304909229278564
    },
    {
      "episode_num": 21,
      "total_reward": 259.86159169549387,
      "episode_length": 1000,
      "avg_reward_per_step": 0.2598615916954939,
      "max_reward_step": 6.8204152249134955,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": 0.7163124680519104,
      "steering_std": 1.2371991872787476,
      "throttle_mean": 0.6955898404121399,
      "brake_mean": -0.33527466654777527
    },
    {
      "episode_num": 22,
      "total_reward": 299.3808049535471,
      "episode_length": 1000,
      "avg_reward_per_step": 0.29938080495354713,
      "max_reward_step": 6.091950464396286,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": 0.611103892326355,
      "steering_std": 1.280379056930542,
      "throttle_mean": 0.5389246940612793,
      "brake_mean": -0.16442760825157166
    },
    {
      "episode_num": 23,
      "total_reward": 226.08695652173185,
      "episode_length": 1000,
      "avg_reward_per_step": 0.22608695652173186,
      "max_reward_step": 6.111180124223603,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": 0.37930619716644287,
      "steering_std": 0.9304471611976624,
      "throttle_mean": -0.034811004996299744,
      "brake_mean": -0.15872664749622345
    },
    {
      "episode_num": 24,
      "total_reward": 341.4062499999906,
      "episode_length": 1000,
      "avg_reward_per_step": 0.34140624999999064,
      "max_reward_step": 7.712500000000006,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": 0.811126708984375,
      "steering_std": 1.4260237216949463,
      "throttle_mean": 0.347636342048645,
      "brake_mean": -0.3556118905544281
    },
    {
      "episode_num": 25,
      "total_reward": 287.97814207649395,
      "episode_length": 1000,
      "avg_reward_per_step": 0.28797814207649397,
      "max_reward_step": 5.36448087431694,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.2092755138874054,
      "steering_std": 1.125206708908081,
      "throttle_mean": -0.38771912455558777,
      "brake_mean": -0.14100512862205505
    },
    {
      "episode_num": 26,
      "total_reward": 721.917808219159,
      "episode_length": 1000,
      "avg_reward_per_step": 0.7219178082191591,
      "max_reward_step": 6.749315068493151,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.052190810441970825,
      "steering_std": 0.920359194278717,
      "throttle_mean": 0.5664252638816833,
      "brake_mean": -0.8486894369125366
    },
    {
      "episode_num": 27,
      "total_reward": 310.71428571426827,
      "episode_length": 1000,
      "avg_reward_per_step": 0.3107142857142683,
      "max_reward_step": 7.042857142857144,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": 0.5607441067695618,
      "steering_std": 1.1479319334030151,
      "throttle_mean": 0.4383580982685089,
      "brake_mean": -0.21313658356666565
    },
    {
      "episode_num": 28,
      "total_reward": 16.541353383460468,
      "episode_length": 1000,
      "avg_reward_per_step": 0.016541353383460466,
      "max_reward_step": 7.418796992481203,
      "min_reward_step": -0.10000000000000142,
      "steering_mean": 0.7886412739753723,
      "steering_std": 0.5531102418899536,
      "throttle_mean": 0.03627629950642586,
      "brake_mean": 0.7487807273864746
    },
    {
      "episode_num": 29,
      "total_reward": 597.8417266186867,
      "episode_length": 1000,
      "avg_reward_per_step": 0.5978417266186867,
      "max_reward_step": 7.094244604316547,
      "min_reward_step": -0.10000000000002274,
      "steering_mean": -0.06517224758863449,
      "steering_std": 0.9762699604034424,
      "throttle_mean": 0.11630451679229736,
      "brake_mean": -0.5790858268737793
    }
  ]
}