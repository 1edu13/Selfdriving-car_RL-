{
  "model": "model_1000k",
  "evaluation_date": "2026-01-14T11:28:09.962108",
  "num_episodes": 30,
  "seed": 100,
  "device": "cuda",
  "statistics": {
    "mean_reward": 421.07921772847016,
    "std_reward": 215.24043040315536,
    "min_reward": 101.63799283154188,
    "max_reward": 845.0636363636266,
    "median_reward": 372.6694571283567,
    "mean_length": 523.0666666666667,
    "std_length": 169.08714387031978,
    "win_rate": 0.0,
    "success_rate": 100.0,
    "steering_mean": -0.0324160309547248,
    "throttle_mean": -0.2758012150724729,
    "brake_mean": -0.8572992960611979
  },
  "episodes": [
    {
      "episode_num": 0,
      "total_reward": 729.2407407407339,
      "episode_length": 619,
      "avg_reward_per_step": 1.1780948961885847,
      "max_reward_step": 7.307407407407408,
      "min_reward_step": -0.9000000000000228,
      "steering_mean": -0.07173418253660202,
      "steering_std": 0.8293530941009521,
      "throttle_mean": -0.2972975969314575,
      "brake_mean": -0.8752458095550537
    },
    {
      "episode_num": 1,
      "total_reward": 220.82937293729248,
      "episode_length": 321,
      "avg_reward_per_step": 0.6879419717672662,
      "max_reward_step": 6.500660066006601,
      "min_reward_step": -0.9000000000000228,
      "steering_mean": -0.09975305199623108,
      "steering_std": 1.1892669200897217,
      "throttle_mean": -0.15381567180156708,
      "brake_mean": -0.7911638617515564
    },
    {
      "episode_num": 2,
      "total_reward": 101.63799283154188,
      "episode_length": 346,
      "avg_reward_per_step": 0.2937514243686182,
      "max_reward_step": 7.068458781362008,
      "min_reward_step": -0.8999999999999944,
      "steering_mean": 0.014996071346104145,
      "steering_std": 0.8683608174324036,
      "throttle_mean": -0.3263111710548401,
      "brake_mean": -0.737988293170929
    },
    {
      "episode_num": 3,
      "total_reward": 473.1280575539507,
      "episode_length": 512,
      "avg_reward_per_step": 0.92407823741006,
      "max_reward_step": 7.094244604316547,
      "min_reward_step": -0.9000000000000228,
      "steering_mean": -0.12706443667411804,
      "steering_std": 1.0394150018692017,
      "throttle_mean": -0.3109903335571289,
      "brake_mean": -0.9141870141029358
    },
    {
      "episode_num": 4,
      "total_reward": 480.136912751674,
      "episode_length": 548,
      "avg_reward_per_step": 0.8761622495468504,
      "max_reward_step": 6.611409395973155,
      "min_reward_step": -0.9000000000000228,
      "steering_mean": -0.052805595099925995,
      "steering_std": 1.0287338495254517,
      "throttle_mean": -0.16662068665027618,
      "brake_mean": -0.8250678777694702
    },
    {
      "episode_num": 5,
      "total_reward": 194.84285714285664,
      "episode_length": 549,
      "avg_reward_per_step": 0.35490502211813596,
      "max_reward_step": 7.042857142857144,
      "min_reward_step": -0.9000000000000228,
      "steering_mean": 0.0017931925831362605,
      "steering_std": 0.84344083070755,
      "throttle_mean": -0.31016305088996887,
      "brake_mean": -0.7122998237609863
    },
    {
      "episode_num": 6,
      "total_reward": 570.6196721311427,
      "episode_length": 542,
      "avg_reward_per_step": 1.0528038231201895,
      "max_reward_step": 8.09672131147541,
      "min_reward_step": -0.9000000000000228,
      "steering_mean": -0.03817499428987503,
      "steering_std": 0.9589627981185913,
      "throttle_mean": -0.27158108353614807,
      "brake_mean": -0.9745185971260071
    },
    {
      "episode_num": 7,
      "total_reward": 229.18299120234474,
      "episode_length": 366,
      "avg_reward_per_step": 0.6261830360719801,
      "max_reward_step": 5.765102639296202,
      "min_reward_step": -0.9000000000000228,
      "steering_mean": 0.0280348751693964,
      "steering_std": 1.1839847564697266,
      "throttle_mean": -0.16367310285568237,
      "brake_mean": -0.7992133498191833
    },
    {
      "episode_num": 8,
      "total_reward": 319.511913357398,
      "episode_length": 368,
      "avg_reward_per_step": 0.8682388949929293,
      "max_reward_step": 7.120216606498195,
      "min_reward_step": -0.9000000000000228,
      "steering_mean": 0.016210926696658134,
      "steering_std": 1.1605348587036133,
      "throttle_mean": -0.15039412677288055,
      "brake_mean": -0.8869320154190063
    },
    {
      "episode_num": 9,
      "total_reward": 331.61475409835793,
      "episode_length": 407,
      "avg_reward_per_step": 0.8147782655979311,
      "max_reward_step": 6.457377049180328,
      "min_reward_step": -0.9000000000000228,
      "steering_mean": -0.07068931311368942,
      "steering_std": 1.1546924114227295,
      "throttle_mean": -0.20627537369728088,
      "brake_mean": -0.9466712474822998
    },
    {
      "episode_num": 10,
      "total_reward": 256.6387096774165,
      "episode_length": 358,
      "avg_reward_per_step": 0.7168679041268617,
      "max_reward_step": 7.068458781362008,
      "min_reward_step": -0.9000000000000228,
      "steering_mean": -0.08642050623893738,
      "steering_std": 1.1722066402435303,
      "throttle_mean": -0.3142724931240082,
      "brake_mean": -0.7375867366790771
    },
    {
      "episode_num": 11,
      "total_reward": 255.64597701148875,
      "episode_length": 548,
      "avg_reward_per_step": 0.46650725732023496,
      "max_reward_step": 5.647126436781609,
      "min_reward_step": -0.9000000000000228,
      "steering_mean": 0.08447747677564621,
      "steering_std": 1.2177190780639648,
      "throttle_mean": -0.4065243899822235,
      "brake_mean": -0.9052755832672119
    },
    {
      "episode_num": 12,
      "total_reward": 845.0636363636266,
      "episode_length": 705,
      "avg_reward_per_step": 1.1986718246292576,
      "max_reward_step": 7.172727272727273,
      "min_reward_step": -0.9000000000000228,
      "steering_mean": -0.08402553200721741,
      "steering_std": 1.03192138671875,
      "throttle_mean": -0.29243266582489014,
      "brake_mean": -0.9979913830757141
    },
    {
      "episode_num": 13,
      "total_reward": 277.1610223642157,
      "episode_length": 454,
      "avg_reward_per_step": 0.6104868334013561,
      "max_reward_step": 6.289776357827477,
      "min_reward_step": -0.9000000000000228,
      "steering_mean": -0.10063294321298599,
      "steering_std": 0.9497931599617004,
      "throttle_mean": -0.1603369414806366,
      "brake_mean": -0.7931559681892395
    },
    {
      "episode_num": 14,
      "total_reward": 508.0915492957724,
      "episode_length": 497,
      "avg_reward_per_step": 1.0223170005951154,
      "max_reward_step": 6.942253521126761,
      "min_reward_step": -0.9000000000000228,
      "steering_mean": -0.048024244606494904,
      "steering_std": 1.0977673530578613,
      "throttle_mean": -0.21344982087612152,
      "brake_mean": -0.9829953908920288
    },
    {
      "episode_num": 15,
      "total_reward": 713.4682926829207,
      "episode_length": 654,
      "avg_reward_per_step": 1.0909301111359644,
      "max_reward_step": 6.868641114982578,
      "min_reward_step": -0.9000000000000228,
      "steering_mean": 0.004169082269072533,
      "steering_std": 1.144903302192688,
      "throttle_mean": -0.28229838609695435,
      "brake_mean": -0.8624237775802612
    },
    {
      "episode_num": 16,
      "total_reward": 623.6762376237602,
      "episode_length": 675,
      "avg_reward_per_step": 0.9239647964796448,
      "max_reward_step": 6.500660066006617,
      "min_reward_step": -0.9000000000000228,
      "steering_mean": -0.02589956484735012,
      "steering_std": 1.2383465766906738,
      "throttle_mean": -0.40492263436317444,
      "brake_mean": -0.8675218820571899
    },
    {
      "episode_num": 17,
      "total_reward": 117.83873517786577,
      "episode_length": 292,
      "avg_reward_per_step": 0.403557312252965,
      "max_reward_step": 7.805138339920949,
      "min_reward_step": -0.8999999999999944,
      "steering_mean": 0.018516162410378456,
      "steering_std": 0.8591563701629639,
      "throttle_mean": -0.3640575706958771,
      "brake_mean": -0.7100353240966797
    },
    {
      "episode_num": 18,
      "total_reward": 497.59360269359723,
      "episode_length": 523,
      "avg_reward_per_step": 0.9514218024734172,
      "max_reward_step": 6.634006734006735,
      "min_reward_step": -0.9000000000000228,
      "steering_mean": -0.012693848460912704,
      "steering_std": 1.2440425157546997,
      "throttle_mean": -0.3633061647415161,
      "brake_mean": -0.9100706577301025
    },
    {
      "episode_num": 19,
      "total_reward": 192.10398671096334,
      "episode_length": 675,
      "avg_reward_per_step": 0.2845984988310568,
      "max_reward_step": 6.5445182724252495,
      "min_reward_step": -0.9000000000000228,
      "steering_mean": 0.013857954181730747,
      "steering_std": 0.8629022240638733,
      "throttle_mean": -0.27075377106666565,
      "brake_mean": -0.789531946182251
    },
    {
      "episode_num": 20,
      "total_reward": 396.0074074074015,
      "episode_length": 450,
      "avg_reward_per_step": 0.8800164609053367,
      "max_reward_step": 7.307407407407408,
      "min_reward_step": -0.9000000000000228,
      "steering_mean": -0.04023296758532524,
      "steering_std": 1.0761533975601196,
      "throttle_mean": -0.3314363956451416,
      "brake_mean": -0.899040162563324
    },
    {
      "episode_num": 21,
      "total_reward": 442.011764705879,
      "episode_length": 466,
      "avg_reward_per_step": 0.9485231002272081,
      "max_reward_step": 6.8204152249134955,
      "min_reward_step": -0.9000000000000228,
      "steering_mean": -0.020137451589107513,
      "steering_std": 1.3317129611968994,
      "throttle_mean": -0.36595451831817627,
      "brake_mean": -0.901992917060852
    },
    {
      "episode_num": 22,
      "total_reward": 212.02972136222968,
      "episode_length": 320,
      "avg_reward_per_step": 0.6625928792569677,
      "max_reward_step": 6.091950464396286,
      "min_reward_step": -0.9000000000000228,
      "steering_mean": -0.05016244575381279,
      "steering_std": 1.1214770078659058,
      "throttle_mean": -0.11994896829128265,
      "brake_mean": -0.9300724864006042
    },
    {
      "episode_num": 23,
      "total_reward": 147.65279503105614,
      "episode_length": 343,
      "avg_reward_per_step": 0.43047462108179635,
      "max_reward_step": 6.111180124223603,
      "min_reward_step": -0.8999999999999944,
      "steering_mean": -0.055372655391693115,
      "steering_std": 1.096208930015564,
      "throttle_mean": -0.3206622898578644,
      "brake_mean": -0.7661860585212708
    },
    {
      "episode_num": 24,
      "total_reward": 725.4062499999867,
      "episode_length": 1000,
      "avg_reward_per_step": 0.7254062499999867,
      "max_reward_step": 7.7125,
      "min_reward_step": -0.9000000000000228,
      "steering_mean": -0.06556317955255508,
      "steering_std": 0.8561620712280273,
      "throttle_mean": -0.28395095467567444,
      "brake_mean": -0.8346738815307617
    },
    {
      "episode_num": 25,
      "total_reward": 597.4759562841443,
      "episode_length": 765,
      "avg_reward_per_step": 0.7810143219400579,
      "max_reward_step": 5.36448087431694,
      "min_reward_step": -0.9000000000000228,
      "steering_mean": 0.022093838080763817,
      "steering_std": 1.147862195968628,
      "throttle_mean": -0.36561256647109985,
      "brake_mean": -0.9383176565170288
    },
    {
      "episode_num": 26,
      "total_reward": 349.331506849312,
      "episode_length": 408,
      "avg_reward_per_step": 0.8562046736502745,
      "max_reward_step": 6.749315068493151,
      "min_reward_step": -0.9000000000000228,
      "steering_mean": 0.021177804097533226,
      "steering_std": 1.1850146055221558,
      "throttle_mean": -0.2359427511692047,
      "brake_mean": -0.8467779159545898
    },
    {
      "episode_num": 27,
      "total_reward": 322.0428571428525,
      "episode_length": 429,
      "avg_reward_per_step": 0.7506826506826398,
      "max_reward_step": 7.042857142857144,
      "min_reward_step": -0.9000000000000228,
      "steering_mean": -0.04126369580626488,
      "steering_std": 0.9877370595932007,
      "throttle_mean": -0.20797643065452576,
      "brake_mean": -0.825197160243988
    },
    {
      "episode_num": 28,
      "total_reward": 716.1308270676549,
      "episode_length": 850,
      "avg_reward_per_step": 0.8425068553737116,
      "max_reward_step": 7.418796992481203,
      "min_reward_step": -0.9000000000000228,
      "steering_mean": -0.028589803725481033,
      "steering_std": 0.9932376146316528,
      "throttle_mean": -0.32622161507606506,
      "brake_mean": -0.8249322175979614
    },
    {
      "episode_num": 29,
      "total_reward": 786.2604316546674,
      "episode_length": 702,
      "avg_reward_per_step": 1.1200291049211786,
      "max_reward_step": 7.094244604316547,
      "min_reward_step": -0.9000000000000228,
      "steering_mean": -0.07856789976358414,
      "steering_std": 1.0794055461883545,
      "throttle_mean": -0.2868529260158539,
      "brake_mean": -0.9319118857383728
    }
  ]
}